{
  "commitSha": "7c291d0737d1798109a51b127e86ac3b4464ec5a",
  "newTestTargets": [
    {
      "functionName": "delete_file_object",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "delete_file_object",
          "lines": [
            {
              "startLine": 240,
              "endLine": 245
            },
            {
              "startLine": 247,
              "endLine": 248
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "delete_file_object",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 240,
              "endLine": 245
            },
            {
              "startLine": 247,
              "endLine": 248
            }
          ]
        },
        "uncoveredFnBody": "def delete_file_object(file_object: Union[Submission, Reply]) -> None:\n    path = Storage.get_default().path(file_object.source.filesystem_id, file_object.filename) # Untested\n    try: # Untested\n        Storage.get_default().move_to_shredder(path) # Untested\n    except ValueError as e: # Untested\n        current_app.logger.error(\"could not queue file for deletion: %s\", e) # Untested\n        raise # Untested\n    finally:\n        db.session.delete(file_object)\n        db.session.commit()",
        "callGraphToTestedFunction": [
          "delete_file_object"
        ]
      }
    },
    {
      "functionName": "set_name",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "set_name",
          "lines": [
            {
              "startLine": 424,
              "endLine": 429
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "set_name",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 424,
              "endLine": 429
            }
          ]
        },
        "uncoveredFnBody": "def set_name(user: Journalist, first_name: Optional[str], last_name: Optional[str]) -> None:\n    try: # Untested\n        user.set_name(first_name, last_name) # Untested\n        db.session.commit() # Untested\n        flash(gettext(\"Name updated.\"), \"success\") # Untested\n    except FirstOrLastNameError as e: # Untested\n        flash(gettext(\"Name not updated: {message}\").format(message=e), \"error\") # Untested",
        "callGraphToTestedFunction": [
          "set_name"
        ]
      }
    },
    {
      "functionName": "create_uid_email",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/_util.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/_util.py",
          "functionName": "create_uid_email",
          "lines": [
            {
              "startLine": 184,
              "endLine": 184
            },
            {
              "startLine": 186,
              "endLine": 189
            },
            {
              "startLine": 191,
              "endLine": 192
            },
            {
              "startLine": 194,
              "endLine": 194
            },
            {
              "startLine": 198,
              "endLine": 198
            },
            {
              "startLine": 200,
              "endLine": 200
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/_util.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "create_uid_email",
          "filePath": "pretty_bad_protocol/_util.py",
          "uncoveredLines": [
            {
              "startLine": 184,
              "endLine": 184
            },
            {
              "startLine": 186,
              "endLine": 189
            },
            {
              "startLine": 191,
              "endLine": 192
            },
            {
              "startLine": 194,
              "endLine": 194
            },
            {
              "startLine": 198,
              "endLine": 198
            },
            {
              "startLine": 200,
              "endLine": 200
            }
          ]
        },
        "uncoveredFnBody": "def create_uid_email(username=None, hostname=None):  # type: ignore[no-untyped-def]\n    \"\"\"Create an email address suitable for a UID on a GnuPG key.\n\n    :param str username: The username portion of an email address.  If None,\n                         defaults to the username of the running Python\n                         process.\n\n    :param str hostname: The FQDN portion of an email address. If None, the\n                         hostname is obtained from gethostname(2).\n\n    :rtype: str\n    :returns: A string formatted as <username>@<hostname>.\n    \"\"\"\n    if hostname:\n        hostname = hostname.replace(\" \", \"_\")\n    if not username:\n        try: # Untested\n            username = os.environ[\"LOGNAME\"] # Untested\n        except KeyError: # Untested\n            username = os.environ[\"USERNAME\"] # Untested\n\n        if not hostname:\n            hostname = gethostname()\n\n        uid = \"{}@{}\".format(username.replace(\" \", \"_\"), hostname)\n    else:\n        username = username.replace(\" \", \"_\")\n        if (not hostname) and (username.find(\"@\") == 0):\n            uid = f\"{username}@{gethostname()}\"\n        elif hostname:\n            uid = f\"{username}@{hostname}\"\n        else:\n            uid = username\n\n    return uid",
        "callGraphToTestedFunction": [
          "create_uid_email"
        ]
      }
    },
    {
      "functionName": "make_blueprint",
      "replayTestFileNames": [],
      "file": "journalist_app/col.py",
      "callGraph": [
        {
          "file": "journalist_app/col.py",
          "functionName": "make_blueprint",
          "lines": [
            {
              "startLine": 40,
              "endLine": 40
            },
            {
              "startLine": 42,
              "endLine": 46
            },
            {
              "startLine": 48,
              "endLine": 52
            },
            {
              "startLine": 54,
              "endLine": 58
            },
            {
              "startLine": 60,
              "endLine": 60
            },
            {
              "startLine": 64,
              "endLine": 65
            },
            {
              "startLine": 67,
              "endLine": 72
            },
            {
              "startLine": 74,
              "endLine": 74
            },
            {
              "startLine": 89,
              "endLine": 89
            },
            {
              "startLine": 91,
              "endLine": 93
            },
            {
              "startLine": 101,
              "endLine": 102
            },
            {
              "startLine": 112,
              "endLine": 112
            },
            {
              "startLine": 115,
              "endLine": 116
            },
            {
              "startLine": 118,
              "endLine": 119
            },
            {
              "startLine": 121,
              "endLine": 122
            },
            {
              "startLine": 124,
              "endLine": 125
            },
            {
              "startLine": 131,
              "endLine": 132
            },
            {
              "startLine": 134,
              "endLine": 136
            },
            {
              "startLine": 143,
              "endLine": 144
            },
            {
              "startLine": 147,
              "endLine": 154
            },
            {
              "startLine": 156,
              "endLine": 159
            },
            {
              "startLine": 161,
              "endLine": 161
            },
            {
              "startLine": 166,
              "endLine": 166
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/col.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "make_blueprint",
          "filePath": "journalist_app/col.py",
          "uncoveredLines": [
            {
              "startLine": 40,
              "endLine": 40
            },
            {
              "startLine": 42,
              "endLine": 46
            },
            {
              "startLine": 48,
              "endLine": 52
            },
            {
              "startLine": 54,
              "endLine": 58
            },
            {
              "startLine": 60,
              "endLine": 60
            },
            {
              "startLine": 64,
              "endLine": 65
            },
            {
              "startLine": 67,
              "endLine": 72
            },
            {
              "startLine": 74,
              "endLine": 74
            },
            {
              "startLine": 89,
              "endLine": 89
            },
            {
              "startLine": 91,
              "endLine": 93
            },
            {
              "startLine": 101,
              "endLine": 102
            },
            {
              "startLine": 112,
              "endLine": 112
            },
            {
              "startLine": 115,
              "endLine": 116
            },
            {
              "startLine": 118,
              "endLine": 119
            },
            {
              "startLine": 121,
              "endLine": 122
            },
            {
              "startLine": 124,
              "endLine": 125
            },
            {
              "startLine": 131,
              "endLine": 132
            },
            {
              "startLine": 134,
              "endLine": 136
            },
            {
              "startLine": 143,
              "endLine": 144
            },
            {
              "startLine": 147,
              "endLine": 154
            },
            {
              "startLine": 156,
              "endLine": 159
            },
            {
              "startLine": 161,
              "endLine": 161
            },
            {
              "startLine": 166,
              "endLine": 166
            }
          ]
        },
        "uncoveredFnBody": "def make_blueprint() -> Blueprint:\n    view = Blueprint(\"col\", __name__)\n\n    @view.route(\"/add_star/<filesystem_id>\", methods=(\"POST\",))\n    def add_star(filesystem_id: str) -> werkzeug.Response:\n        make_star_true(filesystem_id)\n        db.session.commit()\n        return redirect(url_for(\"main.index\"))\n\n    @view.route(\"/remove_star/<filesystem_id>\", methods=(\"POST\",))\n    def remove_star(filesystem_id: str) -> werkzeug.Response:\n        make_star_false(filesystem_id)\n        db.session.commit()\n        return redirect(url_for(\"main.index\"))\n\n    @view.route(\"/<filesystem_id>\")\n    def col(filesystem_id: str) -> str:\n        form = ReplyForm()\n        source = get_source(filesystem_id)\n        has_key = source.public_key is not None\n\n        return render_template(\n            \"col.html\", filesystem_id=filesystem_id, source=source, has_key=has_key, form=form\n        )\n\n    @view.route(\"/delete/<filesystem_id>\", methods=(\"POST\",))\n    def delete_single(filesystem_id: str) -> werkzeug.Response:\n        \"\"\"deleting a single collection from its /col page\"\"\"\n        source = get_source(filesystem_id)\n        try:\n            delete_collection(filesystem_id)\n        except GpgKeyNotFoundError as e:\n            current_app.logger.error(\"error deleting collection: %s\", e)\n            abort(500)\n\n        flash(\n            Markup(\n                \"<b>{}</b> {}\".format(\n                    # Translators: Precedes a message confirming the success of an operation.\n                    escape(gettext(\"Success!\")),\n                    escape(\n                        gettext(\"The account and data for the source {} have been deleted.\").format(\n                            source.journalist_designation\n                        )\n                    ),\n                )\n            ),\n            \"success\",\n        )\n\n        return redirect(url_for(\"main.index\"))\n\n    @view.route(\"/process\", methods=(\"POST\",))\n    def process() -> werkzeug.Response:\n        actions = {\n            \"download-unread\": col_download_unread,\n            \"download-all\": col_download_all,\n            \"star\": col_star,\n            \"un-star\": col_un_star,\n            \"delete\": col_delete,\n            \"delete-data\": col_delete_data,\n        }\n        if \"cols_selected\" not in request.form:\n            flash(\n                Markup(\n                    \"<b>{}</b> {}\".format(\n                        # Translators: Error shown when a user has not selected items to act on.\n                        escape(gettext(\"Nothing Selected\")),\n                        escape(gettext(\"You must select one or more items.\")),\n                    )\n                ),\n                \"error\",\n            )\n            return redirect(url_for(\"main.index\"))\n\n        # getlist is cgi.FieldStorage.getlist\n        cols_selected = request.form.getlist(\"cols_selected\")\n        action = request.form[\"action\"]\n\n        if action not in actions:\n            return abort(500)\n\n        method = actions[action]\n        return method(cols_selected)\n\n    @view.route(\"/<filesystem_id>/<fn>\")\n    def download_single_file(filesystem_id: str, fn: str) -> werkzeug.Response:\n        \"\"\"\n        Marks the file being download (the file being downloaded is either a submission message,\n        submission file attachment, or journalist reply) as seen by the current logged-in user and\n        send the file to a client to be saved or opened.\n        \"\"\"\n        if \"..\" in fn or fn.startswith(\"/\"):\n            abort(404)\n\n        file = Storage.get_default().path(filesystem_id, fn)\n        if not Path(file).is_file():\n            flash(\n                gettext(\n                    \"Your download failed because the file could not be found. An admin can find \"\n                    + \"more information in the system and monitoring logs.\"\n                ),\n                \"error\",\n            )\n            current_app.logger.error(f\"File {file} not found\")\n            return redirect(url_for(\"col.col\", filesystem_id=filesystem_id))\n\n        # mark as seen by the current user\n        try: # Untested\n            journalist = session.get_user() # Untested\n            if fn.endswith(\"reply.gpg\"): # Untested\n                reply = Reply.query.filter(Reply.filename == fn).one() # Untested\n                mark_seen([reply], journalist) # Untested\n            elif fn.endswith((\"-doc.gz.gpg\", \"doc.zip.gpg\")): # Untested\n                submitted_file = Submission.query.filter(Submission.filename == fn).one() # Untested\n                mark_seen([submitted_file], journalist) # Untested\n            else:\n                message = Submission.query.filter(Submission.filename == fn).one()\n                mark_seen([message], journalist)\n        except NoResultFound as e:\n            current_app.logger.error(f\"Could not mark {fn} as seen: {e}\")\n\n        return send_file(\n            Storage.get_default().path(filesystem_id, fn),\n            mimetype=\"application/pgp-encrypted\",\n        )\n\n    return view",
        "callGraphToTestedFunction": [
          "make_blueprint"
        ]
      }
    },
    {
      "functionName": "serve_file_with_etag",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "serve_file_with_etag",
          "lines": [
            {
              "startLine": 568,
              "endLine": 570
            },
            {
              "startLine": 578,
              "endLine": 579
            },
            {
              "startLine": 581,
              "endLine": 584
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "serve_file_with_etag",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 568,
              "endLine": 570
            },
            {
              "startLine": 578,
              "endLine": 579
            },
            {
              "startLine": 581,
              "endLine": 584
            }
          ]
        },
        "uncoveredFnBody": "def serve_file_with_etag(db_obj: Union[Reply, Submission]) -> flask.Response:\n    file_path = Storage.get_default().path(db_obj.source.filesystem_id, db_obj.filename)\n    add_range_headers = not current_app.config[\"USE_X_SENDFILE\"]\n    response = send_file(\n        file_path,\n        mimetype=\"application/pgp-encrypted\",\n        as_attachment=True,\n        etag=False,\n        conditional=add_range_headers,\n    )  # Disable Flask default ETag\n\n    if not db_obj.checksum:\n        add_checksum_for_file(db.session, db_obj, file_path)\n\n    response.direct_passthrough = False # Untested\n    response.headers[\"Etag\"] = db_obj.checksum # Untested\n    response.headers[\"Accept-Ranges\"] = \"bytes\" # Untested\n    return response # Untested",
        "callGraphToTestedFunction": [
          "serve_file_with_etag"
        ]
      }
    },
    {
      "functionName": "admin_required",
      "replayTestFileNames": [],
      "file": "journalist_app/decorators.py",
      "callGraph": [
        {
          "file": "journalist_app/decorators.py",
          "functionName": "admin_required",
          "lines": [
            {
              "startLine": 10,
              "endLine": 15
            },
            {
              "startLine": 17,
              "endLine": 17
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/decorators.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "admin_required",
          "filePath": "journalist_app/decorators.py",
          "uncoveredLines": [
            {
              "startLine": 10,
              "endLine": 15
            },
            {
              "startLine": 17,
              "endLine": 17
            }
          ]
        },
        "uncoveredFnBody": "def admin_required(func: Callable) -> Callable:\n    @wraps(func) # Untested\n    def wrapper(*args: Any, **kwargs: Any) -> Any: # Untested\n        if session.logged_in() and session.get_user().is_admin: # Untested\n            return func(*args, **kwargs) # Untested\n        flash(gettext(\"Only admins can access this page.\"), \"notification\") # Untested\n        return redirect(url_for(\"main.index\")) # Untested\n\n    return wrapper",
        "callGraphToTestedFunction": [
          "admin_required"
        ]
      }
    },
    {
      "functionName": "purge_deleted_sources",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "purge_deleted_sources",
          "lines": [
            {
              "startLine": 413,
              "endLine": 420
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "purge_deleted_sources",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 413,
              "endLine": 420
            }
          ]
        },
        "uncoveredFnBody": "def purge_deleted_sources() -> None:\n    \"\"\"\n    Deletes all Sources with a non-null `deleted_at` attribute.\n    \"\"\"\n    sources = Source.query.filter(Source.deleted_at.isnot(None)).order_by(Source.deleted_at).all() # Untested\n    if sources: # Untested\n        current_app.logger.info(\"Purging deleted sources (%s)\", len(sources)) # Untested\n    for source in sources: # Untested\n        try: # Untested\n            delete_collection(source.filesystem_id) # Untested\n        except Exception as e: # Untested\n            current_app.logger.error(\"Error deleting source %s: %s\", source.uuid, e) # Untested",
        "callGraphToTestedFunction": [
          "purge_deleted_sources"
        ]
      }
    },
    {
      "functionName": "verify_2fa_token",
      "replayTestFileNames": [],
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "verify_2fa_token",
          "lines": [
            {
              "startLine": 609,
              "endLine": 610
            },
            {
              "startLine": 613,
              "endLine": 613
            },
            {
              "startLine": 616,
              "endLine": 617
            },
            {
              "startLine": 619,
              "endLine": 619
            },
            {
              "startLine": 621,
              "endLine": 621
            },
            {
              "startLine": 624,
              "endLine": 626
            },
            {
              "startLine": 628,
              "endLine": 628
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "verify_2fa_token",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 609,
              "endLine": 610
            },
            {
              "startLine": 613,
              "endLine": 613
            },
            {
              "startLine": 616,
              "endLine": 617
            },
            {
              "startLine": 619,
              "endLine": 619
            },
            {
              "startLine": 621,
              "endLine": 621
            },
            {
              "startLine": 624,
              "endLine": 626
            },
            {
              "startLine": 628,
              "endLine": 628
            }
          ]
        },
        "uncoveredFnBody": "class Journalist(db.Model):\n    __tablename__ = \"journalists\"\n    id = Column(Integer, primary_key=True)\n    uuid = Column(String(36), unique=True, nullable=False)\n    username = Column(String(255), nullable=False, unique=True)\n    first_name = Column(String(255), nullable=True)\n    last_name = Column(String(255), nullable=True)\n    pw_salt = Column(LargeBinary(32), nullable=True)\n    pw_hash = Column(LargeBinary(256), nullable=True)\n    is_admin = Column(Boolean)\n\n    otp_secret = Column(String(32), default=two_factor.random_base32)\n    is_totp = Column(Boolean, default=True)\n    hotp_counter = Column(Integer, default=0)\n    last_token = Column(String(6))\n\n    created_on = Column(DateTime, default=datetime.datetime.utcnow)\n    last_access = Column(DateTime)\n    passphrase_hash = Column(String(256))\n\n    login_attempts = relationship(\n        \"JournalistLoginAttempt\", backref=\"journalist\", cascade=\"all, delete\"\n    )\n\n    MIN_USERNAME_LEN = 3\n    MIN_NAME_LEN = 0\n    MAX_NAME_LEN = 100\n    INVALID_USERNAMES = [\"deleted\"]\n\n    def __init__(\n        self,\n        username: str,\n        password: str,\n        first_name: \"Optional[str]\" = None,\n        last_name: \"Optional[str]\" = None,\n        is_admin: bool = False,\n        otp_secret: \"Optional[str]\" = None,\n    ) -> None:\n        self.check_username_acceptable(username)\n        self.username = username\n        if first_name:\n            self.check_name_acceptable(first_name)\n            self.first_name = first_name\n        if last_name:\n            self.check_name_acceptable(last_name)\n            self.last_name = last_name\n        # nosemgrep: python.django.security.audit.unvalidated-password.unvalidated-password\n        self.set_password(password)\n        self.is_admin = is_admin\n        self.uuid = str(uuid.uuid4())\n\n        if otp_secret:\n            self.set_hotp_secret(otp_secret)\n\n    def __repr__(self) -> str:\n        return \"<Journalist {}{}>\".format(self.username, \" [admin]\" if self.is_admin else \"\")\n\n    def _scrypt_hash(self, password: str, salt: bytes) -> bytes:\n        backend = default_backend()\n        scrypt_instance = scrypt.Scrypt(\n            length=64,\n            salt=salt,\n            n=2**14,\n            r=8,\n            p=1,\n            backend=backend,\n        )\n        return scrypt_instance.derive(password.encode(\"utf-8\"))\n\n    MAX_PASSWORD_LEN = 128\n    MIN_PASSWORD_LEN = 14\n\n    def set_password(self, passphrase: \"Optional[str]\") -> None:\n        if passphrase is None:\n            raise PasswordError()\n\n        self.check_password_acceptable(passphrase)\n\n        hasher = argon2.PasswordHasher(**ARGON2_PARAMS)\n        # \"migrate\" from the legacy case\n        if not self.passphrase_hash:\n            self.passphrase_hash = hasher.hash(passphrase)\n            # argon2 creates one merged field that embeds randomly generated\n            # salt in the output like $alg$salt$hash\n            self.pw_hash = None\n            self.pw_salt = None\n\n        # Don't do anything if user's password hasn't changed.\n        if self.passphrase_hash and self.valid_password(passphrase):\n            return\n\n        self.passphrase_hash = hasher.hash(passphrase)\n\n    def set_name(self, first_name: Optional[str], last_name: Optional[str]) -> None:\n        if first_name:\n            self.check_name_acceptable(first_name)\n            self.first_name = first_name\n        if last_name:\n            self.check_name_acceptable(last_name)\n            self.last_name = last_name\n\n    @classmethod\n    def check_username_acceptable(cls, username: str) -> None:\n        if len(username) < cls.MIN_USERNAME_LEN:\n            raise InvalidUsernameException(\n                ngettext(\n                    \"Must be at least {num} character long.\",\n                    \"Must be at least {num} characters long.\",\n                    cls.MIN_USERNAME_LEN,\n                ).format(num=cls.MIN_USERNAME_LEN)\n            )\n        if username in cls.INVALID_USERNAMES:\n            raise InvalidUsernameException(\n                gettext(\n                    \"This username is invalid because it is reserved \"\n                    \"for internal use by the software.\"\n                )\n            )\n\n    @classmethod\n    def check_name_acceptable(cls, name: str) -> None:\n        # Enforce a reasonable maximum length for names\n        if len(name) > cls.MAX_NAME_LEN:\n            raise InvalidNameLength()\n\n    @classmethod\n    def check_password_acceptable(cls, password: str) -> None:\n        # Enforce a reasonable maximum length for passwords to avoid DoS\n        if len(password) > cls.MAX_PASSWORD_LEN:\n            raise InvalidPasswordLength(password)\n\n        # Enforce a reasonable minimum length for new passwords\n        if len(password) < cls.MIN_PASSWORD_LEN:\n            raise InvalidPasswordLength(password)\n\n        # Ensure all passwords are \"diceware-like\"\n        if len(password.split()) < 7:\n            raise NonDicewarePassword()\n\n    def valid_password(self, passphrase: \"Optional[str]\") -> bool:\n        if not passphrase:\n            return False\n\n        # Avoid hashing passwords that are over the maximum length\n        if len(passphrase) > self.MAX_PASSWORD_LEN:\n            raise InvalidPasswordLength(passphrase)\n\n        # No check on minimum password length here because some passwords\n        # may have been set prior to setting the minimum password length.\n\n        hasher = argon2.PasswordHasher(**ARGON2_PARAMS)\n        if self.passphrase_hash:\n            # default case\n            try:\n                is_valid = hasher.verify(self.passphrase_hash, passphrase)\n            except argon2.exceptions.VerificationError:\n                is_valid = False\n        else:\n            # legacy support\n            if self.pw_salt is None:\n                raise ValueError(\n                    f\"Should never happen: pw_salt is none for legacy Journalist {self.id}\"\n                )\n\n            # For type checking\n            if not isinstance(self.pw_hash, bytes):\n                raise RuntimeError(\"self.pw_hash isn't bytes\")\n\n            is_valid = compare_digest(self._scrypt_hash(passphrase, self.pw_salt), self.pw_hash)\n\n        # If the passphrase isn't valid, bail out now\n        if not is_valid:\n            return False\n        # From here on we can assume the passphrase was valid\n\n        # Perform migration checks\n        needs_update = False\n        if self.passphrase_hash:\n            # Check if the hash needs an update\n            if hasher.check_needs_rehash(self.passphrase_hash):\n                self.passphrase_hash = hasher.hash(passphrase)\n                needs_update = True\n        else:\n            # Migrate to an argon2 hash, which creates one merged field\n            # that embeds randomly generated salt in the output like\n            # $alg$salt$hash\n            self.passphrase_hash = hasher.hash(passphrase)\n            self.pw_salt = None\n            self.pw_hash = None\n            needs_update = True\n\n        if needs_update:\n            db.session.add(self)\n            db.session.commit()\n\n        return is_valid\n\n    def regenerate_totp_shared_secret(self) -> None:\n        self.otp_secret = two_factor.random_base32()\n\n    def set_hotp_secret(self, otp_secret: str) -> None:\n        self.otp_secret = base64.b32encode(binascii.unhexlify(otp_secret.replace(\" \", \"\"))).decode(\n            \"ascii\"\n        )\n        self.is_totp = False\n        self.hotp_counter = 0\n\n    @property\n    def totp(self) -> two_factor.TOTP:\n        if self.is_totp:\n            return two_factor.TOTP(self.otp_secret)\n        else:\n            raise ValueError(f\"{self} is not using TOTP\")\n\n    @property\n    def hotp(self) -> two_factor.HOTP:\n        if not self.is_totp:\n            return two_factor.HOTP(self.otp_secret)\n        else:\n            raise ValueError(f\"{self} is not using HOTP\")\n\n    @property\n    def formatted_otp_secret(self) -> str:\n        return two_factor.format_secret(self.otp_secret)\n\n    def verify_2fa_token(self, token: Optional[str]) -> str:\n        if not token:\n            raise two_factor.OtpTokenInvalid()\n\n        # Strip from 2fa tokens the whitespace that many clients add for readability\n        sanitized_token = \"\".join(token.split())\n\n        # Reject OTP tokens that have already been used\n        if self.last_token is not None and self.last_token == sanitized_token:\n            raise two_factor.OtpTokenInvalid(\"Token already used\")\n\n        if self.is_totp:\n            # TOTP\n            self.totp.verify(sanitized_token, datetime.datetime.utcnow())\n        else:\n            # HOTP\n            successful_counter_value = self.hotp.verify(sanitized_token, self.hotp_counter) # Untested\n            self.hotp_counter = successful_counter_value + 1 # Untested\n            db.session.commit() # Untested\n\n        return sanitized_token\n\n    _LOGIN_ATTEMPT_PERIOD = 60  # seconds\n    _MAX_LOGIN_ATTEMPTS_PER_PERIOD = 5\n\n    @classmethod\n    def throttle_login(cls, user: \"Journalist\") -> None:\n        # Record the login attempt...\n        login_attempt = JournalistLoginAttempt(user)\n        db.session.add(login_attempt)\n        db.session.commit()\n\n        # ...and reject it if they have exceeded the threshold\n        login_attempt_period = datetime.datetime.utcnow() - datetime.timedelta(\n            seconds=cls._LOGIN_ATTEMPT_PERIOD\n        )\n        attempts_within_period = (\n            JournalistLoginAttempt.query.filter(JournalistLoginAttempt.journalist_id == user.id)\n            .filter(JournalistLoginAttempt.timestamp > login_attempt_period)\n            .all()\n        )\n        if len(attempts_within_period) > cls._MAX_LOGIN_ATTEMPTS_PER_PERIOD:\n            raise LoginThrottledException(\n                f\"throttled ({len(attempts_within_period)} attempts in last \"\n                f\"{cls._LOGIN_ATTEMPT_PERIOD} seconds)\"\n            )\n\n    @classmethod\n    def login(\n        cls,\n        username: str,\n        password: Optional[str],\n        token: Optional[str],\n    ) -> \"Journalist\":\n        try:\n            user = Journalist.query.filter_by(username=username).one()\n        except NoResultFound:\n            raise InvalidUsernameException(gettext(\"Invalid username\"))\n\n        if user.username in Journalist.INVALID_USERNAMES:\n            raise InvalidUsernameException(gettext(\"Invalid username\"))\n\n        # Login hardening measures\n        cls.throttle_login(user)\n\n        sanitized_token = user.verify_2fa_token(token)\n\n        # If it is valid, store the token that to prevent OTP token reuse\n        user.last_token = sanitized_token\n        db.session.commit()\n\n        if not user.valid_password(password):\n            raise WrongPasswordException(\"invalid password\")\n\n        return user\n\n    def to_json(self, all_info: bool = True) -> Dict[str, Any]:\n        \"\"\"Returns a JSON representation of the journalist user. If all_info is\n        False, potentially sensitive or extraneous fields are excluded. Note\n        that both representations do NOT include credentials.\"\"\"\n        json_user: Dict[str, Any] = {\n            \"username\": self.username,\n            \"uuid\": self.uuid,\n            \"first_name\": self.first_name,\n            \"last_name\": self.last_name,\n        }\n\n        if all_info is True:\n            json_user[\"is_admin\"] = self.is_admin\n            if self.last_access:\n                json_user[\"last_login\"] = self.last_access\n            else:\n                json_user[\"last_login\"] = None\n\n        return json_user\n\n    def is_deleted_user(self) -> bool:\n        \"\"\"Is this the special \"deleted\" user managed by the system?\"\"\"\n        return self.username == \"deleted\"\n\n    @classmethod\n    def get_deleted(cls) -> \"Journalist\":\n        \"\"\"Get a system user that represents deleted journalists for referential integrity\n\n        Callers must commit the session themselves\n        \"\"\"\n        deleted = Journalist.query.filter_by(username=\"deleted\").one_or_none()\n        if deleted is None:\n            # Lazily create\n            deleted = cls(\n                # Use a placeholder username to bypass validation that would reject\n                # \"deleted\" as unusable\n                username=\"placeholder\",\n                # We store a randomly generated passphrase for this account that is\n                # never revealed to anyone.\n                password=PassphraseGenerator.get_default().generate_passphrase(),\n            )\n            deleted.username = \"deleted\"\n            db.session.add(deleted)\n        return deleted\n\n    def delete(self) -> None:\n        \"\"\"delete a journalist, migrating some data over to the \"deleted\" journalist\n\n        Callers must commit the session themselves\n        \"\"\"\n        deleted = self.get_deleted()\n        # All replies should be reassociated with the \"deleted\" journalist\n        for reply in Reply.query.filter_by(journalist_id=self.id).all():\n            reply.journalist_id = deleted.id\n            db.session.add(reply)\n\n        # For seen indicators, we need to make sure one doesn't already exist\n        # otherwise it'll hit a unique key conflict\n        already_seen_files = {\n            file.file_id for file in SeenFile.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for file in SeenFile.query.filter_by(journalist_id=self.id).all():\n            if file.file_id in already_seen_files:\n                db.session.delete(file)\n            else:\n                file.journalist_id = deleted.id\n                db.session.add(file)\n\n        already_seen_messages = {\n            message.message_id\n            for message in SeenMessage.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for message in SeenMessage.query.filter_by(journalist_id=self.id).all():\n            if message.message_id in already_seen_messages:\n                db.session.delete(message)\n            else:\n                message.journalist_id = deleted.id\n                db.session.add(message)\n\n        already_seen_replies = {\n            reply.reply_id for reply in SeenReply.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for reply in SeenReply.query.filter_by(journalist_id=self.id).all():\n            if reply.reply_id in already_seen_replies:\n                db.session.delete(reply)\n            else:\n                reply.journalist_id = deleted.id\n                db.session.add(reply)\n\n        # For the rest of the associated data we rely on cascading deletions\n        db.session.delete(self)",
        "callGraphToTestedFunction": [
          "verify_2fa_token"
        ]
      }
    },
    {
      "functionName": "make_star_false",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "make_star_false",
          "lines": [
            {
              "startLine": 294,
              "endLine": 299
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "make_star_false",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 294,
              "endLine": 299
            }
          ]
        },
        "uncoveredFnBody": "def make_star_false(filesystem_id: str) -> None:\n    source = get_source(filesystem_id) # Untested\n    if not source.star: # Untested\n        source_star = SourceStar(source) # Untested\n        db.session.add(source_star) # Untested\n        db.session.commit() # Untested\n    source.star.starred = False # Untested",
        "callGraphToTestedFunction": [
          "make_star_false"
        ]
      }
    },
    {
      "functionName": "verify_file",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "verify_file",
          "lines": [
            {
              "startLine": 276,
              "endLine": 276
            },
            {
              "startLine": 278,
              "endLine": 283
            },
            {
              "startLine": 285,
              "endLine": 295
            },
            {
              "startLine": 297,
              "endLine": 299
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "verify_file",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 276,
              "endLine": 276
            },
            {
              "startLine": 278,
              "endLine": 283
            },
            {
              "startLine": 285,
              "endLine": 295
            },
            {
              "startLine": 297,
              "endLine": 299
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file): # Untested\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file) # Untested\n                return result # Untested\n            log.debug(\"verify_file(): Handling detached verification\") # Untested\n            sig_fh = None # Untested\n            try: # Untested\n                sig_fh = open(sig_file, \"rb\") # Untested\n                args = [\"--verify %s -\" % sig_fh.name] # Untested\n                proc = self._open_subprocess(args) # Untested\n                writer = _util._threaded_copy_data(file, proc.stdin) # Untested\n                self._collect_output(proc, result, writer, stdin=proc.stdin) # Untested\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "verify_file"
        ]
      }
    },
    {
      "functionName": "logout_user",
      "replayTestFileNames": [],
      "file": "journalist_app/sessions.py",
      "callGraph": [
        {
          "file": "journalist_app/sessions.py",
          "functionName": "logout_user",
          "lines": [
            {
              "startLine": 221,
              "endLine": 221
            },
            {
              "startLine": 224,
              "endLine": 228
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/sessions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "logout_user",
          "filePath": "journalist_app/sessions.py",
          "uncoveredLines": [
            {
              "startLine": 221,
              "endLine": 221
            },
            {
              "startLine": 224,
              "endLine": 228
            }
          ]
        },
        "uncoveredFnBody": "class SessionInterface(FlaskSessionInterface):\n    def _generate_sid(self) -> str:\n        return token_urlsafe(32)\n\n    def _get_signer(self, app: Flask) -> URLSafeTimedSerializer:\n        if not app.secret_key:\n            raise RuntimeError(\"No secret key set\")\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt)\n\n    \"\"\"Uses the Redis key-value store as a session backend.\n\n    :param redis: A ``redis.Redis`` instance.\n    :param key_prefix: A prefix that is added to all Redis store keys.\n    :param salt: Allows to set the signer salt from the calling interface\n    :param header_name: if use_header, set the header name to parse\n    \"\"\"\n\n    def __init__(\n        self,\n        lifetime: int,\n        renew_count: int,\n        redis: Redis,\n        key_prefix: str,\n        salt: str,\n        header_name: str,\n    ) -> None:\n        self.serializer = session_json_serializer\n        self.redis = redis\n        self.lifetime = lifetime\n        self.renew_count = renew_count\n        self.key_prefix = key_prefix\n        self.api_key_prefix = \"api_\" + key_prefix\n        self.salt = salt\n        self.api_salt = \"api_\" + salt\n        self.header_name = header_name\n        self.new = False\n\n    def _new_session(self, is_api: bool = False, initial: Any = None) -> ServerSideSession:\n        sid = self._generate_sid()\n        token: str = self._get_signer(app).dumps(sid)  # type: ignore\n        session = ServerSideSession(sid=sid, token=token, lifetime=self.lifetime, initial=initial)\n        session.new = True\n        session.is_api = is_api\n        return session\n\n    def open_session(self, app: Flask, request: Request) -> Optional[ServerSideSession]:\n        \"\"\"This function is called by the flask session interface at the\n        beginning of each request.\n        \"\"\"\n        is_api = request.path.split(\"/\")[1] == \"api\"\n\n        if is_api:\n            self.key_prefix = self.api_key_prefix\n            self.salt = self.api_salt\n            auth_header = request.headers.get(self.header_name)\n            if auth_header:\n                split = auth_header.split(\" \")\n                if len(split) != 2 or split[0] != \"Token\":\n                    return self._new_session(is_api)\n                sid: Optional[str] = split[1]\n            else:\n                return self._new_session(is_api)\n        else:\n            sid = request.cookies.get(app.session_cookie_name)\n        if sid:\n            try:\n                sid = self._get_signer(app).loads(sid)\n            except BadSignature:\n                sid = None\n        if not sid:\n            return self._new_session(is_api)\n\n        val = self.redis.get(self.key_prefix + sid)\n        if val is not None:\n            try:\n                data = self.serializer.loads(val.decode(\"utf-8\"))\n                token: str = self._get_signer(app).dumps(sid)  # type: ignore\n                return ServerSideSession(sid=sid, token=token, initial=data)\n            except (JSONDecodeError, NotImplementedError):\n                return self._new_session(is_api)\n        # signed session_id provided in cookie is valid, but the session is not on the server\n        # anymore so maybe here is the code path for a meaningful error message\n        msg = gettext(\"You have been logged out due to inactivity.\")\n        return self._new_session(is_api, initial={\"_flashes\": [(\"error\", msg)]})\n\n    def save_session(  # type: ignore[override]\n        self, app: Flask, session: ServerSideSession, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, just\n        before sending the response.\n        \"\"\"\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        if session.to_destroy:\n            initial: Dict[str, Any] = {\"locale\": session.locale}\n            if session.flash:\n                initial[\"_flashes\"] = [session.flash]\n            self.redis.delete(self.key_prefix + session.sid)\n            if not session.is_api:\n                # Instead of deleting the cookie and send a new sid with the next request\n                # create the new session already, so we can pass along messages and locale\n                session = self._new_session(False, initial=initial)\n        expires = self.redis.ttl(name=self.key_prefix + session.sid)\n        if session.new:\n            session[\"renew_count\"] = self.renew_count\n            expires = self.lifetime\n        elif expires < (30 * 60) and session[\"renew_count\"] > 0:\n            session[\"renew_count\"] -= 1\n            expires += self.lifetime\n            session.modified = True\n        httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)\n        samesite = self.get_cookie_samesite(app)\n        val = self.serializer.dumps(dict(session))\n        if session.to_regenerate:\n            self.redis.delete(self.key_prefix + session.sid)\n            session.sid = self._generate_sid()\n            session.token = self._get_signer(app).dumps(session.sid)  # type: ignore\n        if session.new or session.to_regenerate:\n            self.redis.setex(name=self.key_prefix + session.sid, value=val, time=expires)\n        elif session.modified:\n            # To prevent race conditions where session is delete by an admin in the middle of a req\n            # accept to save the session object if and only if already exists using the xx flag\n            self.redis.set(name=self.key_prefix + session.sid, value=val, ex=expires, xx=True)\n        if not session.is_api and (session.new or session.to_regenerate):\n            response.headers.add(\"Vary\", \"Cookie\")\n            response.set_cookie(\n                app.session_cookie_name,\n                session.token,\n                httponly=httponly,\n                domain=domain,\n                path=path,\n                secure=secure,\n                samesite=samesite,\n            )\n\n    def logout_user(self, uid: int) -> None:\n        for key in self.redis.keys(self.key_prefix + \"*\") + self.redis.keys(\n            \"api_\" + self.key_prefix + \"*\"\n        ):\n            found = self.redis.get(key) # Untested\n            if found: # Untested\n                sess = session_json_serializer.loads(found.decode(\"utf-8\")) # Untested\n                if \"uid\" in sess and sess[\"uid\"] == uid: # Untested\n                    self.redis.delete(key) # Untested",
        "callGraphToTestedFunction": [
          "logout_user"
        ]
      }
    },
    {
      "functionName": "sign_key",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "sign_key",
          "lines": [
            {
              "startLine": 500,
              "endLine": 505
            },
            {
              "startLine": 507,
              "endLine": 508
            },
            {
              "startLine": 510,
              "endLine": 510
            },
            {
              "startLine": 512,
              "endLine": 517
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "sign_key",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 500,
              "endLine": 505
            },
            {
              "startLine": 507,
              "endLine": 508
            },
            {
              "startLine": 510,
              "endLine": 510
            },
            {
              "startLine": 512,
              "endLine": 517
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args) # Untested\n        result = self._result_map[\"signing\"](self) # Untested\n        confirm_command = \"%sy\\n\" % input_command # Untested\n        p.stdin.write(confirm_command.encode()) # Untested\n        self._collect_output(p, result, stdin=p.stdin) # Untested\n        return result # Untested\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "sign_key"
        ]
      }
    },
    {
      "functionName": "random_datetime",
      "replayTestFileNames": [],
      "file": "loaddata.py",
      "callGraph": [
        {
          "file": "loaddata.py",
          "functionName": "random_datetime",
          "lines": [
            {
              "startLine": 79,
              "endLine": 79
            },
            {
              "startLine": 83,
              "endLine": 84
            },
            {
              "startLine": 86,
              "endLine": 89
            },
            {
              "startLine": 92,
              "endLine": 92
            },
            {
              "startLine": 94,
              "endLine": 94
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "loaddata.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "random_datetime",
          "filePath": "loaddata.py",
          "uncoveredLines": [
            {
              "startLine": 79,
              "endLine": 79
            },
            {
              "startLine": 83,
              "endLine": 84
            },
            {
              "startLine": 86,
              "endLine": 89
            },
            {
              "startLine": 92,
              "endLine": 92
            },
            {
              "startLine": 94,
              "endLine": 94
            }
          ]
        },
        "uncoveredFnBody": "def random_datetime(nullable: bool) -> Optional[datetime.datetime]:\n    \"\"\"\n    Returns a random datetime or possibly None if nullable.\n    \"\"\"\n    if nullable and random_bool():\n        return None\n\n    now = datetime.datetime.now() # Untested\n    year = random.randint(2013, now.year) # Untested\n    max_day = 366 if calendar.isleap(year) else 365 # Untested\n    day = random.randint(1, max_day) # Untested\n\n    # Calculate the month/day given the year\n    date = datetime.date(year, 1, 1) + datetime.timedelta(days=day - 1)\n\n    return datetime.datetime(\n        year=year,\n        month=date.month,\n        day=date.day,\n        hour=random.randint(0, 23),\n        minute=random.randint(0, 59),\n        second=random.randint(0, 59),\n        microsecond=random.randint(0, 1000),\n    )",
        "callGraphToTestedFunction": [
          "random_datetime"
        ]
      }
    },
    {
      "functionName": "make_blueprint",
      "replayTestFileNames": [],
      "file": "journalist_app/api.py",
      "callGraph": [
        {
          "file": "journalist_app/api.py",
          "functionName": "make_blueprint",
          "lines": [
            {
              "startLine": 39,
              "endLine": 39
            },
            {
              "startLine": 41,
              "endLine": 43
            },
            {
              "startLine": 52,
              "endLine": 52
            },
            {
              "startLine": 55,
              "endLine": 57
            },
            {
              "startLine": 59,
              "endLine": 60
            },
            {
              "startLine": 66,
              "endLine": 69
            },
            {
              "startLine": 72,
              "endLine": 75
            },
            {
              "startLine": 77,
              "endLine": 79
            },
            {
              "startLine": 81,
              "endLine": 83
            },
            {
              "startLine": 85,
              "endLine": 90
            },
            {
              "startLine": 92,
              "endLine": 93
            },
            {
              "startLine": 95,
              "endLine": 95
            },
            {
              "startLine": 106,
              "endLine": 108
            },
            {
              "startLine": 110,
              "endLine": 110
            },
            {
              "startLine": 112,
              "endLine": 113
            },
            {
              "startLine": 120,
              "endLine": 120
            },
            {
              "startLine": 122,
              "endLine": 125
            },
            {
              "startLine": 127,
              "endLine": 135
            },
            {
              "startLine": 137,
              "endLine": 137
            },
            {
              "startLine": 139,
              "endLine": 144
            },
            {
              "startLine": 146,
              "endLine": 151
            },
            {
              "startLine": 153,
              "endLine": 155
            },
            {
              "startLine": 160,
              "endLine": 165
            },
            {
              "startLine": 167,
              "endLine": 167
            },
            {
              "startLine": 169,
              "endLine": 172
            },
            {
              "startLine": 177,
              "endLine": 181
            },
            {
              "startLine": 183,
              "endLine": 186
            },
            {
              "startLine": 188,
              "endLine": 188
            },
            {
              "startLine": 190,
              "endLine": 190
            },
            {
              "startLine": 194,
              "endLine": 203
            },
            {
              "startLine": 205,
              "endLine": 205
            },
            {
              "startLine": 207,
              "endLine": 211
            },
            {
              "startLine": 215,
              "endLine": 218
            },
            {
              "startLine": 220,
              "endLine": 221
            },
            {
              "startLine": 223,
              "endLine": 225
            },
            {
              "startLine": 227,
              "endLine": 229
            },
            {
              "startLine": 235,
              "endLine": 236
            },
            {
              "startLine": 239,
              "endLine": 239
            },
            {
              "startLine": 241,
              "endLine": 241
            },
            {
              "startLine": 243,
              "endLine": 244
            },
            {
              "startLine": 246,
              "endLine": 250
            },
            {
              "startLine": 252,
              "endLine": 261
            },
            {
              "startLine": 263,
              "endLine": 263
            },
            {
              "startLine": 265,
              "endLine": 265
            },
            {
              "startLine": 276,
              "endLine": 276
            },
            {
              "startLine": 278,
              "endLine": 286
            },
            {
              "startLine": 288,
              "endLine": 288
            },
            {
              "startLine": 290,
              "endLine": 293
            },
            {
              "startLine": 304,
              "endLine": 307
            },
            {
              "startLine": 312,
              "endLine": 313
            },
            {
              "startLine": 318,
              "endLine": 320
            },
            {
              "startLine": 322,
              "endLine": 323
            },
            {
              "startLine": 327,
              "endLine": 332
            },
            {
              "startLine": 334,
              "endLine": 338
            },
            {
              "startLine": 340,
              "endLine": 344
            },
            {
              "startLine": 347,
              "endLine": 347
            },
            {
              "startLine": 349,
              "endLine": 349
            },
            {
              "startLine": 351,
              "endLine": 351
            },
            {
              "startLine": 353,
              "endLine": 355
            },
            {
              "startLine": 357,
              "endLine": 360
            },
            {
              "startLine": 362,
              "endLine": 365
            },
            {
              "startLine": 367,
              "endLine": 367
            },
            {
              "startLine": 372,
              "endLine": 372
            },
            {
              "startLine": 374,
              "endLine": 374
            },
            {
              "startLine": 376,
              "endLine": 377
            },
            {
              "startLine": 379,
              "endLine": 379
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/api.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "make_blueprint",
          "filePath": "journalist_app/api.py",
          "uncoveredLines": [
            {
              "startLine": 39,
              "endLine": 39
            },
            {
              "startLine": 41,
              "endLine": 43
            },
            {
              "startLine": 52,
              "endLine": 52
            },
            {
              "startLine": 55,
              "endLine": 57
            },
            {
              "startLine": 59,
              "endLine": 60
            },
            {
              "startLine": 66,
              "endLine": 69
            },
            {
              "startLine": 72,
              "endLine": 75
            },
            {
              "startLine": 77,
              "endLine": 79
            },
            {
              "startLine": 81,
              "endLine": 83
            },
            {
              "startLine": 85,
              "endLine": 90
            },
            {
              "startLine": 92,
              "endLine": 93
            },
            {
              "startLine": 95,
              "endLine": 95
            },
            {
              "startLine": 106,
              "endLine": 108
            },
            {
              "startLine": 110,
              "endLine": 110
            },
            {
              "startLine": 112,
              "endLine": 113
            },
            {
              "startLine": 120,
              "endLine": 120
            },
            {
              "startLine": 122,
              "endLine": 125
            },
            {
              "startLine": 127,
              "endLine": 135
            },
            {
              "startLine": 137,
              "endLine": 137
            },
            {
              "startLine": 139,
              "endLine": 144
            },
            {
              "startLine": 146,
              "endLine": 151
            },
            {
              "startLine": 153,
              "endLine": 155
            },
            {
              "startLine": 160,
              "endLine": 165
            },
            {
              "startLine": 167,
              "endLine": 167
            },
            {
              "startLine": 169,
              "endLine": 172
            },
            {
              "startLine": 177,
              "endLine": 181
            },
            {
              "startLine": 183,
              "endLine": 186
            },
            {
              "startLine": 188,
              "endLine": 188
            },
            {
              "startLine": 190,
              "endLine": 190
            },
            {
              "startLine": 194,
              "endLine": 203
            },
            {
              "startLine": 205,
              "endLine": 205
            },
            {
              "startLine": 207,
              "endLine": 211
            },
            {
              "startLine": 215,
              "endLine": 218
            },
            {
              "startLine": 220,
              "endLine": 221
            },
            {
              "startLine": 223,
              "endLine": 225
            },
            {
              "startLine": 227,
              "endLine": 229
            },
            {
              "startLine": 235,
              "endLine": 236
            },
            {
              "startLine": 239,
              "endLine": 239
            },
            {
              "startLine": 241,
              "endLine": 241
            },
            {
              "startLine": 243,
              "endLine": 244
            },
            {
              "startLine": 246,
              "endLine": 250
            },
            {
              "startLine": 252,
              "endLine": 261
            },
            {
              "startLine": 263,
              "endLine": 263
            },
            {
              "startLine": 265,
              "endLine": 265
            },
            {
              "startLine": 276,
              "endLine": 276
            },
            {
              "startLine": 278,
              "endLine": 286
            },
            {
              "startLine": 288,
              "endLine": 288
            },
            {
              "startLine": 290,
              "endLine": 293
            },
            {
              "startLine": 304,
              "endLine": 307
            },
            {
              "startLine": 312,
              "endLine": 313
            },
            {
              "startLine": 318,
              "endLine": 320
            },
            {
              "startLine": 322,
              "endLine": 323
            },
            {
              "startLine": 327,
              "endLine": 332
            },
            {
              "startLine": 334,
              "endLine": 338
            },
            {
              "startLine": 340,
              "endLine": 344
            },
            {
              "startLine": 347,
              "endLine": 347
            },
            {
              "startLine": 349,
              "endLine": 349
            },
            {
              "startLine": 351,
              "endLine": 351
            },
            {
              "startLine": 353,
              "endLine": 355
            },
            {
              "startLine": 357,
              "endLine": 360
            },
            {
              "startLine": 362,
              "endLine": 365
            },
            {
              "startLine": 367,
              "endLine": 367
            },
            {
              "startLine": 372,
              "endLine": 372
            },
            {
              "startLine": 374,
              "endLine": 374
            },
            {
              "startLine": 376,
              "endLine": 377
            },
            {
              "startLine": 379,
              "endLine": 379
            }
          ]
        },
        "uncoveredFnBody": "def make_blueprint() -> Blueprint:\n    api = Blueprint(\"api\", __name__)\n\n    @api.route(\"/\")\n    def get_endpoints() -> Tuple[flask.Response, int]:\n        endpoints = {\n            \"sources_url\": \"/api/v1/sources\",\n            \"current_user_url\": \"/api/v1/user\",\n            \"all_users_url\": \"/api/v1/users\",\n            \"submissions_url\": \"/api/v1/submissions\",\n            \"replies_url\": \"/api/v1/replies\",\n            \"seen_url\": \"/api/v1/seen\",\n            \"auth_token_url\": \"/api/v1/token\",\n        }\n        return jsonify(endpoints), 200\n\n    # Before every post, we validate the payload before processing the request\n    @api.before_request\n    def validate_data() -> None:\n        if request.method == \"POST\":\n            # flag, star, and logout can have empty payloads\n            if not request.data:\n                dataless_endpoints = [\n                    \"add_star\",\n                    \"remove_star\",\n                    \"flag\",\n                    \"logout\",\n                ]\n                for endpoint in dataless_endpoints:\n                    if request.endpoint == \"api.\" + endpoint:\n                        return\n                abort(400, \"malformed request\")\n            # other requests must have valid JSON payload\n            else:\n                try:\n                    json.loads(request.data.decode(\"utf-8\"))\n                except ValueError:\n                    abort(400, \"malformed request\")\n\n    @api.route(\"/token\", methods=[\"POST\"])\n    def get_token() -> Tuple[flask.Response, int]:\n        creds = json.loads(request.data.decode(\"utf-8\"))\n\n        username = creds.get(\"username\", None)\n        passphrase = creds.get(\"passphrase\", None)\n        one_time_code = creds.get(\"one_time_code\", None)\n\n        if username is None:\n            abort(400, \"username field is missing\")\n        if passphrase is None:\n            abort(400, \"passphrase field is missing\")\n        if one_time_code is None:\n            abort(400, \"one_time_code field is missing\")\n\n        try:\n            journalist = Journalist.login(username, passphrase, one_time_code)\n\n            response = jsonify(\n                {\n                    \"token\": session.get_token(),\n                    \"expiration\": session.get_lifetime(),\n                    \"journalist_uuid\": journalist.uuid,\n                    \"journalist_first_name\": journalist.first_name,\n                    \"journalist_last_name\": journalist.last_name,\n                }\n            )\n\n            # Update access metadata\n            journalist.last_access = datetime.now(timezone.utc)\n            db.session.add(journalist)\n            db.session.commit()\n\n            session[\"uid\"] = journalist.id\n\n            return response, 200\n        except (\n            LoginThrottledException,\n            InvalidUsernameException,\n            OtpSecretInvalid,\n            OtpTokenInvalid,\n            WrongPasswordException,\n        ):\n            return abort(403, \"Token authentication failed.\")\n\n    @api.route(\"/sources\", methods=[\"GET\"])\n    def get_all_sources() -> Tuple[flask.Response, int]:\n        sources = Source.query.filter_by(pending=False, deleted_at=None).all()\n        return jsonify({\"sources\": [source.to_json() for source in sources]}), 200\n\n    @api.route(\"/sources/<source_uuid>\", methods=[\"GET\", \"DELETE\"])\n    def single_source(source_uuid: str) -> Tuple[flask.Response, int]:\n        if request.method == \"GET\":\n            source = get_or_404(Source, source_uuid, column=Source.uuid)\n            return jsonify(source.to_json()), 200\n        elif request.method == \"DELETE\":\n            source = get_or_404(Source, source_uuid, column=Source.uuid)\n            utils.delete_collection(source.filesystem_id)\n            return jsonify({\"message\": \"Source and submissions deleted\"}), 200\n        else:\n            abort(405)\n\n    @api.route(\"/sources/<source_uuid>/add_star\", methods=[\"POST\"])\n    def add_star(source_uuid: str) -> Tuple[flask.Response, int]:\n        source = get_or_404(Source, source_uuid, column=Source.uuid)\n        utils.make_star_true(source.filesystem_id)\n        db.session.commit()\n        return jsonify({\"message\": \"Star added\"}), 201\n\n    @api.route(\"/sources/<source_uuid>/remove_star\", methods=[\"DELETE\"])\n    def remove_star(source_uuid: str) -> Tuple[flask.Response, int]:\n        source = get_or_404(Source, source_uuid, column=Source.uuid)\n        utils.make_star_false(source.filesystem_id)\n        db.session.commit()\n        return jsonify({\"message\": \"Star removed\"}), 200\n\n    @api.route(\"/sources/<source_uuid>/flag\", methods=[\"POST\"])\n    def flag(source_uuid: str) -> Tuple[flask.Response, int]:\n        return (\n            jsonify({\"message\": \"Sources no longer need to be flagged for reply\"}),\n            200,\n        )\n\n    @api.route(\"/sources/<source_uuid>/conversation\", methods=[\"DELETE\"])\n    def source_conversation(source_uuid: str) -> Tuple[flask.Response, int]:\n        if request.method == \"DELETE\":\n            source = get_or_404(Source, source_uuid, column=Source.uuid)\n            utils.delete_source_files(source.filesystem_id)\n            return jsonify({\"message\": \"Source data deleted\"}), 200\n        else:\n            abort(405)\n\n    @api.route(\"/sources/<source_uuid>/submissions\", methods=[\"GET\"])\n    def all_source_submissions(source_uuid: str) -> Tuple[flask.Response, int]:\n        source = get_or_404(Source, source_uuid, column=Source.uuid)\n        return (\n            jsonify({\"submissions\": [submission.to_json() for submission in source.submissions]}),\n            200,\n        )\n\n    @api.route(\"/sources/<source_uuid>/submissions/<submission_uuid>/download\", methods=[\"GET\"])\n    def download_submission(source_uuid: str, submission_uuid: str) -> flask.Response:\n        get_or_404(Source, source_uuid, column=Source.uuid)\n        submission = get_or_404(Submission, submission_uuid, column=Submission.uuid)\n        return utils.serve_file_with_etag(submission)\n\n    @api.route(\"/sources/<source_uuid>/replies/<reply_uuid>/download\", methods=[\"GET\"])\n    def download_reply(source_uuid: str, reply_uuid: str) -> flask.Response:\n        get_or_404(Source, source_uuid, column=Source.uuid)\n        reply = get_or_404(Reply, reply_uuid, column=Reply.uuid)\n\n        return utils.serve_file_with_etag(reply)\n\n    @api.route(\n        \"/sources/<source_uuid>/submissions/<submission_uuid>\",\n        methods=[\"GET\", \"DELETE\"],\n    )\n    def single_submission(source_uuid: str, submission_uuid: str) -> Tuple[flask.Response, int]:\n        if request.method == \"GET\":\n            get_or_404(Source, source_uuid, column=Source.uuid)\n            submission = get_or_404(Submission, submission_uuid, column=Submission.uuid)\n            return jsonify(submission.to_json()), 200\n        elif request.method == \"DELETE\":\n            get_or_404(Source, source_uuid, column=Source.uuid)\n            submission = get_or_404(Submission, submission_uuid, column=Submission.uuid)\n            utils.delete_file_object(submission)\n            return jsonify({\"message\": \"Submission deleted\"}), 200\n        else:\n            abort(405)\n\n    @api.route(\"/sources/<source_uuid>/replies\", methods=[\"GET\", \"POST\"])\n    def all_source_replies(source_uuid: str) -> Tuple[flask.Response, int]:\n        if request.method == \"GET\":\n            source = get_or_404(Source, source_uuid, column=Source.uuid)\n            return (\n                jsonify({\"replies\": [reply.to_json() for reply in source.replies]}),\n                200,\n            )\n        elif request.method == \"POST\":\n            source = get_or_404(Source, source_uuid, column=Source.uuid)\n            if request.json is None:\n                abort(400, \"please send requests in valid JSON\")\n\n            if \"reply\" not in request.json:\n                abort(400, \"reply not found in request body\")\n\n            data = request.json\n            if not data[\"reply\"]:\n                abort(400, \"reply should not be empty\")\n\n            source.interaction_count += 1\n            try:\n                filename = Storage.get_default().save_pre_encrypted_reply(\n                    source.filesystem_id,\n                    source.interaction_count,\n                    source.journalist_filename,\n                    data[\"reply\"],\n                )\n            except NotEncrypted:\n                return jsonify({\"message\": \"You must encrypt replies client side\"}), 400\n\n            # issue #3918\n            filename = path.basename(filename)\n\n            reply = Reply(session.get_user(), source, filename, Storage.get_default())\n\n            reply_uuid = data.get(\"uuid\", None)\n            if reply_uuid is not None:\n                # check that is is parseable\n                try:\n                    UUID(reply_uuid)\n                except ValueError:\n                    abort(400, \"'uuid' was not a valid UUID\")\n                reply.uuid = reply_uuid\n\n            try: # Untested\n                db.session.add(reply) # Untested\n                seen_reply = SeenReply(reply=reply, journalist=session.get_user()) # Untested\n                db.session.add(seen_reply) # Untested\n                db.session.add(source) # Untested\n                db.session.commit() # Untested\n            except IntegrityError as e: # Untested\n                db.session.rollback() # Untested\n                if \"UNIQUE constraint failed: replies.uuid\" in str(e): # Untested\n                    abort(409, \"That UUID is already in use.\") # Untested\n                else:\n                    raise e\n\n            return (\n                jsonify(\n                    {\n                        \"message\": \"Your reply has been stored\",\n                        \"uuid\": reply.uuid,\n                        \"filename\": reply.filename,\n                    }\n                ),\n                201,\n            )\n        else:\n            abort(405)\n\n    @api.route(\"/sources/<source_uuid>/replies/<reply_uuid>\", methods=[\"GET\", \"DELETE\"])\n    def single_reply(source_uuid: str, reply_uuid: str) -> Tuple[flask.Response, int]:\n        get_or_404(Source, source_uuid, column=Source.uuid)\n        reply = get_or_404(Reply, reply_uuid, column=Reply.uuid)\n        if request.method == \"GET\":\n            return jsonify(reply.to_json()), 200\n        elif request.method == \"DELETE\":\n            utils.delete_file_object(reply)\n            return jsonify({\"message\": \"Reply deleted\"}), 200\n        else:\n            abort(405)\n\n    @api.route(\"/submissions\", methods=[\"GET\"])\n    def get_all_submissions() -> Tuple[flask.Response, int]:\n        submissions = Submission.query.all()\n        return (\n            jsonify(\n                {\n                    \"submissions\": [\n                        submission.to_json() for submission in submissions if submission.source\n                    ]\n                }\n            ),\n            200,\n        )\n\n    @api.route(\"/replies\", methods=[\"GET\"])\n    def get_all_replies() -> Tuple[flask.Response, int]:\n        replies = Reply.query.all()\n        return (\n            jsonify({\"replies\": [reply.to_json() for reply in replies if reply.source]}),\n            200,\n        )\n\n    @api.route(\"/seen\", methods=[\"POST\"])\n    def seen() -> Tuple[flask.Response, int]:\n        \"\"\"\n        Lists or marks the source conversation items that the journalist has seen.\n        \"\"\"\n\n        if request.method == \"POST\":\n            if request.json is None or not isinstance(request.json, collections.abc.Mapping):\n                abort(400, \"Please send requests in valid JSON.\")\n\n            if not any(map(request.json.get, [\"files\", \"messages\", \"replies\"])):\n                abort(400, \"Please specify the resources to mark seen.\")\n\n            # gather everything to be marked seen. if any don't exist,\n            # reject the request.\n            targets: Set[Union[Submission, Reply]] = set()\n            for file_uuid in request.json.get(\"files\", []):\n                f = Submission.query.filter(Submission.uuid == file_uuid).one_or_none()\n                if f is None or not f.is_file:\n                    abort(404, f\"file not found: {file_uuid}\")\n                targets.add(f)\n\n            for message_uuid in request.json.get(\"messages\", []):\n                m = Submission.query.filter(Submission.uuid == message_uuid).one_or_none()\n                if m is None or not m.is_message:\n                    abort(404, f\"message not found: {message_uuid}\")\n                targets.add(m)\n\n            for reply_uuid in request.json.get(\"replies\", []):\n                r = Reply.query.filter(Reply.uuid == reply_uuid).one_or_none()\n                if r is None:\n                    abort(404, f\"reply not found: {reply_uuid}\")\n                targets.add(r)\n\n            # now mark everything seen.\n            utils.mark_seen(list(targets), session.get_user())\n\n            return jsonify({\"message\": \"resources marked seen\"}), 200\n\n        abort(405)\n\n    @api.route(\"/user\", methods=[\"GET\"])\n    def get_current_user() -> Tuple[flask.Response, int]:\n        return jsonify(session.get_user().to_json()), 200\n\n    @api.route(\"/users\", methods=[\"GET\"])\n    def get_all_users() -> Tuple[flask.Response, int]:\n        users = Journalist.query.all()\n        return jsonify({\"users\": [user.to_json(all_info=False) for user in users]}), 200\n\n    @api.route(\"/logout\", methods=[\"POST\"])\n    def logout() -> Tuple[flask.Response, int]:\n        session.destroy()\n        return jsonify({\"message\": \"Your token has been revoked.\"}), 200\n\n    def _handle_api_http_exception(\n        error: werkzeug.exceptions.HTTPException,\n    ) -> Tuple[flask.Response, int]:\n        # Workaround for no blueprint-level 404/5 error handlers, see:\n        # https://github.com/pallets/flask/issues/503#issuecomment-71383286\n        response = jsonify({\"error\": error.name, \"message\": error.description})\n\n        return response, error.code  # type: ignore\n\n    for code in default_exceptions:\n        api.errorhandler(code)(_handle_api_http_exception)\n\n    return api",
        "callGraphToTestedFunction": [
          "make_blueprint"
        ]
      }
    },
    {
      "functionName": "delete_source_files",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "delete_source_files",
          "lines": [
            {
              "startLine": 352,
              "endLine": 353
            },
            {
              "startLine": 355,
              "endLine": 359
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "delete_source_files",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 352,
              "endLine": 353
            },
            {
              "startLine": 355,
              "endLine": 359
            }
          ]
        },
        "uncoveredFnBody": "def delete_source_files(filesystem_id: str) -> None:\n    \"\"\"deletes submissions and replies for specified source\"\"\"\n    source = get_source(filesystem_id, include_deleted=True)\n    if source is not None:\n        # queue all files for deletion and remove them from the database\n        for f in source.collection: # Untested\n            try: # Untested\n                delete_file_object(f) # Untested\n            except Exception: # Untested\n                pass # Untested",
        "callGraphToTestedFunction": [
          "delete_source_files"
        ]
      }
    },
    {
      "functionName": "add_source",
      "replayTestFileNames": [],
      "file": "loaddata.py",
      "callGraph": [
        {
          "file": "loaddata.py",
          "functionName": "add_source",
          "lines": [
            {
              "startLine": 256,
              "endLine": 256
            },
            {
              "startLine": 260,
              "endLine": 261
            },
            {
              "startLine": 266,
              "endLine": 269
            },
            {
              "startLine": 280,
              "endLine": 280
            },
            {
              "startLine": 283,
              "endLine": 287
            },
            {
              "startLine": 289,
              "endLine": 289
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "loaddata.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "add_source",
          "filePath": "loaddata.py",
          "uncoveredLines": [
            {
              "startLine": 256,
              "endLine": 256
            },
            {
              "startLine": 260,
              "endLine": 261
            },
            {
              "startLine": 266,
              "endLine": 269
            },
            {
              "startLine": 280,
              "endLine": 280
            },
            {
              "startLine": 283,
              "endLine": 287
            },
            {
              "startLine": 289,
              "endLine": 289
            }
          ]
        },
        "uncoveredFnBody": "def add_source(use_gpg: bool = False) -> Tuple[Source, str]:\n    \"\"\"\n    Adds a single source.\n    \"\"\"\n    codename = PassphraseGenerator.get_default().generate_passphrase()\n    source_user = create_source_user(\n        db_session=db.session,\n        source_passphrase=codename,\n        source_app_storage=Storage.get_default(),\n    )\n    source = source_user.get_db_record()\n    if use_gpg:\n        manager = EncryptionManager.get_default()\n        gen_key_input = manager.gpg().gen_key_input(\n            passphrase=source_user.gpg_secret,\n            name_email=source_user.filesystem_id,\n            key_type=\"RSA\",\n            key_length=4096,\n            name_real=\"Source Key\",\n            creation_date=\"2013-05-14\",\n            # '0' is the magic value that tells GPG's batch key generation not\n            # to set an expiration date.\n            expire_date=\"0\",\n        )\n        manager.gpg().gen_key(gen_key_input)\n\n        # Delete the Sequoia-generated keys\n        source.pgp_public_key = None # Untested\n        source.pgp_fingerprint = None # Untested\n        source.pgp_secret_key = None # Untested\n        db.session.add(source) # Untested\n    db.session.commit() # Untested\n\n    return source, codename",
        "callGraphToTestedFunction": [
          "add_source"
        ]
      }
    },
    {
      "functionName": "submit_message",
      "replayTestFileNames": [],
      "file": "loaddata.py",
      "callGraph": [
        {
          "file": "loaddata.py",
          "functionName": "submit_message",
          "lines": [
            {
              "startLine": 184,
              "endLine": 184
            },
            {
              "startLine": 188,
              "endLine": 189
            },
            {
              "startLine": 195,
              "endLine": 196
            },
            {
              "startLine": 198,
              "endLine": 200
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "loaddata.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "submit_message",
          "filePath": "loaddata.py",
          "uncoveredLines": [
            {
              "startLine": 184,
              "endLine": 184
            },
            {
              "startLine": 188,
              "endLine": 189
            },
            {
              "startLine": 195,
              "endLine": 196
            },
            {
              "startLine": 198,
              "endLine": 200
            }
          ]
        },
        "uncoveredFnBody": "def submit_message(source: Source, journalist_who_saw: Optional[Journalist]) -> None:\n    \"\"\"\n    Adds a single message submitted by a source.\n    \"\"\"\n    record_source_interaction(source)\n    fpath = Storage.get_default().save_message_submission(\n        source.filesystem_id,\n        source.interaction_count,\n        source.journalist_filename,\n        next(messages),\n    )\n    submission = Submission(source, fpath, Storage.get_default())\n    db.session.add(submission)\n\n    if journalist_who_saw: # Untested\n        seen_message = SeenMessage(message=submission, journalist=journalist_who_saw) # Untested\n        db.session.add(seen_message) # Untested",
        "callGraphToTestedFunction": [
          "submit_message"
        ]
      }
    },
    {
      "functionName": "validate_hotp_secret",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "validate_hotp_secret",
          "lines": [
            {
              "startLine": 132,
              "endLine": 133
            },
            {
              "startLine": 135,
              "endLine": 136
            },
            {
              "startLine": 144,
              "endLine": 144
            },
            {
              "startLine": 146,
              "endLine": 150
            },
            {
              "startLine": 156,
              "endLine": 156
            },
            {
              "startLine": 158,
              "endLine": 158
            },
            {
              "startLine": 162,
              "endLine": 164
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "validate_hotp_secret",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 132,
              "endLine": 133
            },
            {
              "startLine": 135,
              "endLine": 136
            },
            {
              "startLine": 144,
              "endLine": 144
            },
            {
              "startLine": 146,
              "endLine": 150
            },
            {
              "startLine": 156,
              "endLine": 156
            },
            {
              "startLine": 158,
              "endLine": 158
            },
            {
              "startLine": 162,
              "endLine": 164
            }
          ]
        },
        "uncoveredFnBody": "def validate_hotp_secret(user: Journalist, otp_secret: str) -> bool:\n    \"\"\"\n    Validates and sets the HOTP provided by a user\n    :param user: the change is for this instance of the User object\n    :param otp_secret: the new HOTP secret\n    :return: True if it validates, False if it does not\n    \"\"\"\n    strip_whitespace = otp_secret.replace(\" \", \"\")\n    secret_length = len(strip_whitespace)\n\n    if secret_length != HOTP.SECRET_HEX_LENGTH:\n        flash(\n            ngettext(\n                \"HOTP secrets are 40 characters long - you have entered {num}.\",\n                \"HOTP secrets are 40 characters long - you have entered {num}.\",\n                secret_length,\n            ).format(num=secret_length),\n            \"error\",\n        )\n        return False\n\n    try: # Untested\n        user.set_hotp_secret(otp_secret) # Untested\n    except (binascii.Error, TypeError) as e: # Untested\n        if \"Non-hexadecimal digit found\" in str(e): # Untested\n            flash( # Untested\n                gettext(\n                    \"Invalid HOTP secret format: \" \"please only submit letters A-F and numbers 0-9.\"\n                ),\n                \"error\",\n            )\n            return False\n        else:\n            flash(\n                gettext(\"An unexpected error occurred! \" \"Please inform your admin.\"),\n                \"error\",\n            )\n            current_app.logger.error(f\"set_hotp_secret '{otp_secret}' (id {user.id}) failed: {e}\")\n            return False\n    return True",
        "callGraphToTestedFunction": [
          "validate_hotp_secret"
        ]
      }
    },
    {
      "functionName": "save_session",
      "replayTestFileNames": [],
      "file": "journalist_app/sessions.py",
      "callGraph": [
        {
          "file": "journalist_app/sessions.py",
          "functionName": "save_session",
          "lines": [
            {
              "startLine": 175,
              "endLine": 182
            },
            {
              "startLine": 185,
              "endLine": 204
            },
            {
              "startLine": 207,
              "endLine": 210
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/sessions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "save_session",
          "filePath": "journalist_app/sessions.py",
          "uncoveredLines": [
            {
              "startLine": 175,
              "endLine": 182
            },
            {
              "startLine": 185,
              "endLine": 204
            },
            {
              "startLine": 207,
              "endLine": 210
            }
          ]
        },
        "uncoveredFnBody": "class SessionInterface(FlaskSessionInterface):\n    def _generate_sid(self) -> str:\n        return token_urlsafe(32)\n\n    def _get_signer(self, app: Flask) -> URLSafeTimedSerializer:\n        if not app.secret_key:\n            raise RuntimeError(\"No secret key set\")\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt)\n\n    \"\"\"Uses the Redis key-value store as a session backend.\n\n    :param redis: A ``redis.Redis`` instance.\n    :param key_prefix: A prefix that is added to all Redis store keys.\n    :param salt: Allows to set the signer salt from the calling interface\n    :param header_name: if use_header, set the header name to parse\n    \"\"\"\n\n    def __init__(\n        self,\n        lifetime: int,\n        renew_count: int,\n        redis: Redis,\n        key_prefix: str,\n        salt: str,\n        header_name: str,\n    ) -> None:\n        self.serializer = session_json_serializer\n        self.redis = redis\n        self.lifetime = lifetime\n        self.renew_count = renew_count\n        self.key_prefix = key_prefix\n        self.api_key_prefix = \"api_\" + key_prefix\n        self.salt = salt\n        self.api_salt = \"api_\" + salt\n        self.header_name = header_name\n        self.new = False\n\n    def _new_session(self, is_api: bool = False, initial: Any = None) -> ServerSideSession:\n        sid = self._generate_sid()\n        token: str = self._get_signer(app).dumps(sid)  # type: ignore\n        session = ServerSideSession(sid=sid, token=token, lifetime=self.lifetime, initial=initial)\n        session.new = True\n        session.is_api = is_api\n        return session\n\n    def open_session(self, app: Flask, request: Request) -> Optional[ServerSideSession]:\n        \"\"\"This function is called by the flask session interface at the\n        beginning of each request.\n        \"\"\"\n        is_api = request.path.split(\"/\")[1] == \"api\"\n\n        if is_api:\n            self.key_prefix = self.api_key_prefix\n            self.salt = self.api_salt\n            auth_header = request.headers.get(self.header_name)\n            if auth_header:\n                split = auth_header.split(\" \")\n                if len(split) != 2 or split[0] != \"Token\":\n                    return self._new_session(is_api)\n                sid: Optional[str] = split[1]\n            else:\n                return self._new_session(is_api)\n        else:\n            sid = request.cookies.get(app.session_cookie_name)\n        if sid:\n            try:\n                sid = self._get_signer(app).loads(sid)\n            except BadSignature:\n                sid = None\n        if not sid:\n            return self._new_session(is_api)\n\n        val = self.redis.get(self.key_prefix + sid)\n        if val is not None:\n            try:\n                data = self.serializer.loads(val.decode(\"utf-8\"))\n                token: str = self._get_signer(app).dumps(sid)  # type: ignore\n                return ServerSideSession(sid=sid, token=token, initial=data)\n            except (JSONDecodeError, NotImplementedError):\n                return self._new_session(is_api)\n        # signed session_id provided in cookie is valid, but the session is not on the server\n        # anymore so maybe here is the code path for a meaningful error message\n        msg = gettext(\"You have been logged out due to inactivity.\")\n        return self._new_session(is_api, initial={\"_flashes\": [(\"error\", msg)]})\n\n    def save_session(  # type: ignore[override]\n        self, app: Flask, session: ServerSideSession, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, just\n        before sending the response.\n        \"\"\"\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        if session.to_destroy:\n            initial: Dict[str, Any] = {\"locale\": session.locale}\n            if session.flash:\n                initial[\"_flashes\"] = [session.flash]\n            self.redis.delete(self.key_prefix + session.sid)\n            if not session.is_api:\n                # Instead of deleting the cookie and send a new sid with the next request\n                # create the new session already, so we can pass along messages and locale\n                session = self._new_session(False, initial=initial) # Untested\n        expires = self.redis.ttl(name=self.key_prefix + session.sid) # Untested\n        if session.new: # Untested\n            session[\"renew_count\"] = self.renew_count # Untested\n            expires = self.lifetime # Untested\n        elif expires < (30 * 60) and session[\"renew_count\"] > 0: # Untested\n            session[\"renew_count\"] -= 1 # Untested\n            expires += self.lifetime # Untested\n            session.modified = True # Untested\n        httponly = self.get_cookie_httponly(app) # Untested\n        secure = self.get_cookie_secure(app) # Untested\n        samesite = self.get_cookie_samesite(app) # Untested\n        val = self.serializer.dumps(dict(session)) # Untested\n        if session.to_regenerate: # Untested\n            self.redis.delete(self.key_prefix + session.sid) # Untested\n            session.sid = self._generate_sid() # Untested\n            session.token = self._get_signer(app).dumps(session.sid)  # type: ignore # Untested\n        if session.new or session.to_regenerate: # Untested\n            self.redis.setex(name=self.key_prefix + session.sid, value=val, time=expires) # Untested\n        elif session.modified: # Untested\n            # To prevent race conditions where session is delete by an admin in the middle of a req\n            # accept to save the session object if and only if already exists using the xx flag\n            self.redis.set(name=self.key_prefix + session.sid, value=val, ex=expires, xx=True)\n        if not session.is_api and (session.new or session.to_regenerate):\n            response.headers.add(\"Vary\", \"Cookie\")\n            response.set_cookie(\n                app.session_cookie_name,\n                session.token,\n                httponly=httponly,\n                domain=domain,\n                path=path,\n                secure=secure,\n                samesite=samesite,\n            )\n\n    def logout_user(self, uid: int) -> None:\n        for key in self.redis.keys(self.key_prefix + \"*\") + self.redis.keys(\n            \"api_\" + self.key_prefix + \"*\"\n        ):\n            found = self.redis.get(key)\n            if found:\n                sess = session_json_serializer.loads(found.decode(\"utf-8\"))\n                if \"uid\" in sess and sess[\"uid\"] == uid:\n                    self.redis.delete(key)",
        "callGraphToTestedFunction": [
          "save_session"
        ]
      }
    },
    {
      "functionName": "create_default_journalists",
      "replayTestFileNames": [],
      "file": "loaddata.py",
      "callGraph": [
        {
          "file": "loaddata.py",
          "functionName": "create_default_journalists",
          "lines": [
            {
              "startLine": 301,
              "endLine": 301
            },
            {
              "startLine": 305,
              "endLine": 310
            },
            {
              "startLine": 312,
              "endLine": 312
            },
            {
              "startLine": 314,
              "endLine": 319
            },
            {
              "startLine": 321,
              "endLine": 321
            },
            {
              "startLine": 323,
              "endLine": 324
            },
            {
              "startLine": 327,
              "endLine": 330
            },
            {
              "startLine": 332,
              "endLine": 332
            },
            {
              "startLine": 334,
              "endLine": 334
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "loaddata.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "create_default_journalists",
          "filePath": "loaddata.py",
          "uncoveredLines": [
            {
              "startLine": 301,
              "endLine": 301
            },
            {
              "startLine": 305,
              "endLine": 310
            },
            {
              "startLine": 312,
              "endLine": 312
            },
            {
              "startLine": 314,
              "endLine": 319
            },
            {
              "startLine": 321,
              "endLine": 321
            },
            {
              "startLine": 323,
              "endLine": 324
            },
            {
              "startLine": 327,
              "endLine": 330
            },
            {
              "startLine": 332,
              "endLine": 332
            },
            {
              "startLine": 334,
              "endLine": 334
            }
          ]
        },
        "uncoveredFnBody": "def create_default_journalists() -> Tuple[Journalist, ...]:\n    \"\"\"\n    Adds a set of journalists that should always be created.\n    \"\"\"\n    try:\n        default_journalist = add_journalist(\"journalist\", is_admin=True)\n    except IntegrityError as e:\n        db.session.rollback()\n        if \"UNIQUE constraint failed: journalists.\" in str(e):\n            default_journalist = Journalist.query.filter_by(username=\"journalist\").one()\n        else:\n            raise e\n\n    try: # Untested\n        dellsberg = add_journalist(\"dellsberg\") # Untested\n    except IntegrityError as e: # Untested\n        db.session.rollback() # Untested\n        if \"UNIQUE constraint failed: journalists.\" in str(e): # Untested\n            dellsberg = Journalist.query.filter_by(username=\"dellsberg\").one() # Untested\n        else:\n            raise e\n\n    try:\n        journalist_to_be_deleted = add_journalist(\n            username=\"clarkkent\", first_name=\"Clark\", last_name=\"Kent\"\n        )\n    except IntegrityError as e:\n        db.session.rollback()\n        if \"UNIQUE constraint failed: journalists.\" in str(e):\n            journalist_to_be_deleted = Journalist.query.filter_by(username=\"clarkkent\").one()\n        else:\n            raise e\n\n    return default_journalist, dellsberg, journalist_to_be_deleted",
        "callGraphToTestedFunction": [
          "create_default_journalists"
        ]
      }
    },
    {
      "functionName": "set_diceware_password",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "set_diceware_password",
          "lines": [
            {
              "startLine": 470,
              "endLine": 471
            },
            {
              "startLine": 474,
              "endLine": 474
            },
            {
              "startLine": 476,
              "endLine": 478
            },
            {
              "startLine": 482,
              "endLine": 482
            },
            {
              "startLine": 484,
              "endLine": 487
            },
            {
              "startLine": 495,
              "endLine": 496
            },
            {
              "startLine": 499,
              "endLine": 500
            },
            {
              "startLine": 518,
              "endLine": 518
            },
            {
              "startLine": 532,
              "endLine": 532
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "set_diceware_password",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 470,
              "endLine": 471
            },
            {
              "startLine": 474,
              "endLine": 474
            },
            {
              "startLine": 476,
              "endLine": 478
            },
            {
              "startLine": 482,
              "endLine": 482
            },
            {
              "startLine": 484,
              "endLine": 487
            },
            {
              "startLine": 495,
              "endLine": 496
            },
            {
              "startLine": 499,
              "endLine": 500
            },
            {
              "startLine": 518,
              "endLine": 518
            },
            {
              "startLine": 532,
              "endLine": 532
            }
          ]
        },
        "uncoveredFnBody": "def set_diceware_password(\n    user: Journalist, password: Optional[str], admin: Optional[bool] = False\n) -> bool:\n    try:\n        if password is not None:\n            # FIXME: password being None will trigger an error in set_password(), we\n            # should turn it into a type error\n            verify_pending_password(user, password)\n        # nosemgrep: python.django.security.audit.unvalidated-password.unvalidated-password\n        user.set_password(password)\n    except PasswordError:\n        flash(\n            gettext(\"The password you submitted is invalid. Password not changed.\"),\n            \"error\",\n        )\n        return False\n\n    try: # Untested\n        db.session.commit() # Untested\n    except Exception: # Untested\n        flash( # Untested\n            gettext(\n                \"There was an error, and the new password might not have been \"\n                \"saved correctly. To prevent you from getting locked \"\n                \"out of your account, you should reset your password again.\"\n            ),\n            \"error\",\n        )\n        current_app.logger.error(\"Failed to update a valid password.\")\n        return False\n\n    # using Markup so the HTML isn't escaped\n    if not admin:\n        session.destroy(\n            (\n                \"success\",\n                Markup(\n                    \"<p>{message} <span><code>{password}</code></span></p>\".format(\n                        message=Markup.escape(\n                            gettext(\n                                \"Password updated. Don't forget to save it in your KeePassX database. \"  # noqa: E501\n                                \"New password:\"\n                            )\n                        ),\n                        password=Markup.escape(\"\" if password is None else password),\n                    )\n                ),\n            ),\n            session.get(\"locale\"),\n        )\n    else:\n        flash(\n            Markup(\n                \"<p>{message} <span><code>{password}</code></span></p>\".format(\n                    message=Markup.escape(\n                        gettext(\n                            \"Password updated. Don't forget to save it in your KeePassX database. \"\n                            \"New password:\"\n                        )\n                    ),\n                    password=Markup.escape(\"\" if password is None else password),\n                )\n            ),\n            \"success\",\n        )\n    return True",
        "callGraphToTestedFunction": [
          "set_diceware_password"
        ]
      }
    },
    {
      "functionName": "col_delete",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "col_delete",
          "lines": [
            {
              "startLine": 320,
              "endLine": 321
            },
            {
              "startLine": 323,
              "endLine": 326
            },
            {
              "startLine": 328,
              "endLine": 328
            },
            {
              "startLine": 330,
              "endLine": 330
            },
            {
              "startLine": 336,
              "endLine": 336
            },
            {
              "startLine": 347,
              "endLine": 347
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "col_delete",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 320,
              "endLine": 321
            },
            {
              "startLine": 323,
              "endLine": 326
            },
            {
              "startLine": 328,
              "endLine": 328
            },
            {
              "startLine": 330,
              "endLine": 330
            },
            {
              "startLine": 336,
              "endLine": 336
            },
            {
              "startLine": 347,
              "endLine": 347
            }
          ]
        },
        "uncoveredFnBody": "def col_delete(cols_selected: List[str]) -> werkzeug.Response:\n    \"\"\"deleting multiple collections from the index\"\"\"\n    if len(cols_selected) < 1:\n        flash(gettext(\"No collections selected for deletion.\"), \"error\")\n    else:\n        now = datetime.now(timezone.utc) # Untested\n        sources = Source.query.filter(Source.filesystem_id.in_(cols_selected)) # Untested\n        sources.update({Source.deleted_at: now}, synchronize_session=\"fetch\") # Untested\n        db.session.commit() # Untested\n\n        num = len(cols_selected)\n\n        success_message = ngettext(\n            \"The account and all data for the source have been deleted.\",\n            \"The accounts and all data for {n} sources have been deleted.\",\n            num,\n        ).format(n=num)\n\n        flash(\n            Markup(\n                \"<b>{}</b> {}\".format(\n                    # Translators: Precedes a message confirming the success of an operation.\n                    escape(gettext(\"Success!\")),\n                    escape(success_message),\n                )\n            ),\n            \"success\",\n        )\n\n    return redirect(url_for(\"main.index\"))",
        "callGraphToTestedFunction": [
          "col_delete"
        ]
      }
    },
    {
      "functionName": "make_blueprint",
      "replayTestFileNames": [],
      "file": "journalist_app/main.py",
      "callGraph": [
        {
          "file": "journalist_app/main.py",
          "functionName": "make_blueprint",
          "lines": [
            {
              "startLine": 32,
              "endLine": 32
            },
            {
              "startLine": 34,
              "endLine": 37
            },
            {
              "startLine": 42,
              "endLine": 43
            },
            {
              "startLine": 50,
              "endLine": 52
            },
            {
              "startLine": 54,
              "endLine": 56
            },
            {
              "startLine": 58,
              "endLine": 58
            },
            {
              "startLine": 60,
              "endLine": 63
            },
            {
              "startLine": 65,
              "endLine": 66
            },
            {
              "startLine": 71,
              "endLine": 71
            },
            {
              "startLine": 80,
              "endLine": 80
            },
            {
              "startLine": 94,
              "endLine": 96
            },
            {
              "startLine": 100,
              "endLine": 100
            },
            {
              "startLine": 113,
              "endLine": 115
            },
            {
              "startLine": 117,
              "endLine": 117
            },
            {
              "startLine": 119,
              "endLine": 120
            },
            {
              "startLine": 134,
              "endLine": 138
            },
            {
              "startLine": 140,
              "endLine": 142
            },
            {
              "startLine": 148,
              "endLine": 156
            },
            {
              "startLine": 163,
              "endLine": 163
            },
            {
              "startLine": 168,
              "endLine": 168
            },
            {
              "startLine": 181,
              "endLine": 181
            },
            {
              "startLine": 183,
              "endLine": 191
            },
            {
              "startLine": 201,
              "endLine": 202
            },
            {
              "startLine": 213,
              "endLine": 213
            },
            {
              "startLine": 215,
              "endLine": 215
            },
            {
              "startLine": 217,
              "endLine": 219
            },
            {
              "startLine": 224,
              "endLine": 225
            },
            {
              "startLine": 227,
              "endLine": 227
            },
            {
              "startLine": 229,
              "endLine": 231
            },
            {
              "startLine": 237,
              "endLine": 241
            },
            {
              "startLine": 243,
              "endLine": 243
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/main.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "make_blueprint",
          "filePath": "journalist_app/main.py",
          "uncoveredLines": [
            {
              "startLine": 32,
              "endLine": 32
            },
            {
              "startLine": 34,
              "endLine": 37
            },
            {
              "startLine": 42,
              "endLine": 43
            },
            {
              "startLine": 50,
              "endLine": 52
            },
            {
              "startLine": 54,
              "endLine": 56
            },
            {
              "startLine": 58,
              "endLine": 58
            },
            {
              "startLine": 60,
              "endLine": 63
            },
            {
              "startLine": 65,
              "endLine": 66
            },
            {
              "startLine": 71,
              "endLine": 71
            },
            {
              "startLine": 80,
              "endLine": 80
            },
            {
              "startLine": 94,
              "endLine": 96
            },
            {
              "startLine": 100,
              "endLine": 100
            },
            {
              "startLine": 113,
              "endLine": 115
            },
            {
              "startLine": 117,
              "endLine": 117
            },
            {
              "startLine": 119,
              "endLine": 120
            },
            {
              "startLine": 134,
              "endLine": 138
            },
            {
              "startLine": 140,
              "endLine": 142
            },
            {
              "startLine": 148,
              "endLine": 156
            },
            {
              "startLine": 163,
              "endLine": 163
            },
            {
              "startLine": 168,
              "endLine": 168
            },
            {
              "startLine": 181,
              "endLine": 181
            },
            {
              "startLine": 183,
              "endLine": 191
            },
            {
              "startLine": 201,
              "endLine": 202
            },
            {
              "startLine": 213,
              "endLine": 213
            },
            {
              "startLine": 215,
              "endLine": 215
            },
            {
              "startLine": 217,
              "endLine": 219
            },
            {
              "startLine": 224,
              "endLine": 225
            },
            {
              "startLine": 227,
              "endLine": 227
            },
            {
              "startLine": 229,
              "endLine": 231
            },
            {
              "startLine": 237,
              "endLine": 241
            },
            {
              "startLine": 243,
              "endLine": 243
            }
          ]
        },
        "uncoveredFnBody": "def make_blueprint() -> Blueprint:\n    view = Blueprint(\"main\", __name__)\n\n    @view.route(\"/login\", methods=(\"GET\", \"POST\"))\n    def login() -> Union[str, werkzeug.Response]:\n        if request.method == \"POST\":\n            user = validate_user(\n                request.form[\"username\"],\n                request.form[\"password\"],\n                request.form[\"token\"],\n            )\n            if user:\n                current_app.logger.info(\n                    \"'{}' logged in with the two-factor code {}\".format(\n                        request.form[\"username\"], request.form[\"token\"]\n                    )\n                )\n\n                # Update access metadata\n                user.last_access = datetime.now(timezone.utc)\n                db.session.add(user)\n                db.session.commit()\n\n                session[\"uid\"] = user.id\n                session.regenerate()\n                return redirect(url_for(\"main.index\"))\n\n        return render_template(\"login.html\")\n\n    @view.route(\"/logout\", methods=(\"POST\",))\n    def logout() -> werkzeug.Response:\n        session.destroy()\n        return redirect(url_for(\"main.index\"))\n\n    @view.route(\"/\")\n    def index() -> str:\n        # Gather the count of unread submissions for each source\n        # ID. This query will be joined in the queries for starred and\n        # unstarred sources below, and the unread counts added to\n        # their result sets as an extra column.\n        unread_stmt = (\n            db.session.query(Submission.source_id, func.count(\"*\").label(\"num_unread\"))\n            .filter_by(seen_files=None, seen_messages=None)\n            .group_by(Submission.source_id)\n            .subquery()\n        )\n\n        # Query for starred sources, along with their unread\n        # submission counts.\n        starred = (\n            db.session.query(Source, unread_stmt.c.num_unread)\n            .filter_by(pending=False, deleted_at=None)\n            .filter(Source.last_updated.isnot(None))\n            .filter(SourceStar.starred.is_(True))\n            .outerjoin(SourceStar)\n            .options(joinedload(Source.submissions))\n            .options(joinedload(Source.star))\n            .outerjoin(unread_stmt, Source.id == unread_stmt.c.source_id)\n            .order_by(Source.last_updated.desc())\n            .all()\n        )\n\n        # Now, add \"num_unread\" attributes to the source entities.\n        for source, num_unread in starred:\n            source.num_unread = num_unread or 0\n        starred = [source for source, num_unread in starred]\n\n        # Query for sources without stars, along with their unread\n        # submission counts.\n        unstarred = (\n            db.session.query(Source, unread_stmt.c.num_unread)\n            .filter_by(pending=False, deleted_at=None)\n            .filter(Source.last_updated.isnot(None))\n            .filter(~Source.star.has(SourceStar.starred.is_(True)))\n            .options(joinedload(Source.submissions))\n            .options(joinedload(Source.star))\n            .outerjoin(unread_stmt, Source.id == unread_stmt.c.source_id)\n            .order_by(Source.last_updated.desc())\n            .all()\n        )\n\n        # Again, add \"num_unread\" attributes to the source entities.\n        for source, num_unread in unstarred:\n            source.num_unread = num_unread or 0\n        unstarred = [source for source, num_unread in unstarred]\n\n        return render_template(\"index.html\", unstarred=unstarred, starred=starred)\n\n    @view.route(\"/reply\", methods=(\"POST\",))\n    def reply() -> werkzeug.Response:\n        \"\"\"Attempt to send a Reply from a Journalist to a Source. Empty\n        messages are rejected, and an informative error message is flashed\n        on the client. In the case of unexpected errors involving database\n        transactions (potentially caused by racing request threads that\n        modify the same the database object) logging is done in such a way\n        so as not to write potentially sensitive information to disk, and a\n        generic error message is flashed on the client.\n\n        Returns:\n           flask.Response: The user is redirected to the same Source\n               collection view, regardless if the Reply is created\n               successfully.\n        \"\"\"\n        form = ReplyForm()\n        if not form.validate_on_submit():\n            for error in form.message.errors:\n                flash(error, \"error\")\n            return redirect(url_for(\"col.col\", filesystem_id=g.filesystem_id))\n\n        g.source.interaction_count += 1\n        filename = f\"{g.source.interaction_count}-{g.source.journalist_filename}-reply.gpg\"\n        EncryptionManager.get_default().encrypt_journalist_reply(\n            for_source=g.source,\n            reply_in=form.message.data,\n            encrypted_reply_path_out=Path(Storage.get_default().path(g.filesystem_id, filename)),\n        )\n\n        try:\n            reply = Reply(session.get_user(), g.source, filename, Storage.get_default())\n            db.session.add(reply)\n            seen_reply = SeenReply(reply=reply, journalist=session.get_user())\n            db.session.add(seen_reply)\n            db.session.commit()\n            store.async_add_checksum_for_file(reply, Storage.get_default())\n        except Exception as exc:\n            flash(\n                gettext(\"An unexpected error occurred! Please \" \"inform your admin.\"),\n                \"error\",\n            )\n            # We take a cautious approach to logging here because we're dealing\n            # with responses to sources. It's possible the exception message\n            # could contain information we don't want to write to disk.\n            current_app.logger.error(\n                f\"Reply from '{session.get_user().username}' (ID {session.get_uid()}) \"\n                f\"failed: {exc.__class__}!\"\n            )\n        else:\n            flash(\n                Markup(\n                    \"<b>{}</b> {}\".format(\n                        # Translators: Precedes a message confirming the success of an operation.\n                        escape(gettext(\"Success!\")),\n                        escape(\n                            gettext(\"The source will receive your reply \" \"next time they log in.\")\n                        ),\n                    )\n                ),\n                \"success\",\n            )\n        finally:\n            return redirect(url_for(\"col.col\", filesystem_id=g.filesystem_id))\n\n    @view.route(\"/bulk\", methods=(\"POST\",)) # Untested\n    def bulk() -> Union[str, werkzeug.Response]: # Untested\n        action = request.form[\"action\"] # Untested\n        error_redirect = url_for(\"col.col\", filesystem_id=g.filesystem_id) # Untested\n        doc_names_selected = request.form.getlist(\"doc_names_selected\") # Untested\n        selected_docs = [doc for doc in g.source.collection if doc.filename in doc_names_selected] # Untested\n        if selected_docs == []: # Untested\n            if action == \"download\": # Untested\n                flash( # Untested\n                    Markup(\n                        \"<b>{}</b> {}\".format(\n                            # Translators: Error shown when a user has not selected items to act on.\n                            escape(gettext(\"Nothing Selected\")),\n                            escape(gettext(\"You must select one or more items for download\")),\n                        )\n                    ),\n                    \"error\",\n                )\n            elif action == \"delete\":\n                flash(\n                    Markup(\n                        \"<b>{}</b> {}\".format(\n                            # Translators: Error shown when a user has not selected items to act on.\n                            escape(gettext(\"Nothing Selected\")),\n                            escape(gettext(\"You must select one or more items for deletion\")),\n                        )\n                    ),\n                    \"error\",\n                )\n            else:\n                abort(400)\n\n            return redirect(error_redirect)\n\n        if action == \"download\":\n            source = get_source(g.filesystem_id)\n            return download(\n                source.journalist_filename,\n                selected_docs,\n                on_error_redirect=error_redirect,\n            )\n        elif action == \"delete\":\n            return bulk_delete(g.filesystem_id, selected_docs)\n        else:\n            abort(400)\n\n    @view.route(\"/download_unread/<filesystem_id>\")\n    def download_unread_filesystem_id(filesystem_id: str) -> werkzeug.Response:\n        unseen_submissions = (\n            Submission.query.join(Source)\n            .filter(Source.deleted_at.is_(None), Source.filesystem_id == filesystem_id)\n            .filter(~Submission.seen_files.any(), ~Submission.seen_messages.any())\n            .all()\n        )\n        if len(unseen_submissions) == 0:\n            flash(gettext(\"No unread submissions for this source.\"), \"error\")\n            return redirect(url_for(\"col.col\", filesystem_id=filesystem_id))\n        source = get_source(filesystem_id)\n        return download(source.journalist_filename, unseen_submissions)\n\n    return view",
        "callGraphToTestedFunction": [
          "make_blueprint"
        ]
      }
    },
    {
      "functionName": "make_blueprint",
      "replayTestFileNames": [],
      "file": "source_app/main.py",
      "callGraph": [
        {
          "file": "source_app/main.py",
          "functionName": "make_blueprint",
          "lines": [
            {
              "startLine": 64,
              "endLine": 64
            },
            {
              "startLine": 66,
              "endLine": 66
            },
            {
              "startLine": 172,
              "endLine": 172
            },
            {
              "startLine": 215,
              "endLine": 215
            },
            {
              "startLine": 255,
              "endLine": 255
            },
            {
              "startLine": 259,
              "endLine": 259
            },
            {
              "startLine": 388,
              "endLine": 388
            },
            {
              "startLine": 391,
              "endLine": 391
            },
            {
              "startLine": 403,
              "endLine": 404
            },
            {
              "startLine": 426,
              "endLine": 426
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "source_app/main.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "make_blueprint",
          "filePath": "source_app/main.py",
          "uncoveredLines": [
            {
              "startLine": 64,
              "endLine": 64
            },
            {
              "startLine": 66,
              "endLine": 66
            },
            {
              "startLine": 172,
              "endLine": 172
            },
            {
              "startLine": 215,
              "endLine": 215
            },
            {
              "startLine": 255,
              "endLine": 255
            },
            {
              "startLine": 259,
              "endLine": 259
            },
            {
              "startLine": 388,
              "endLine": 388
            },
            {
              "startLine": 391,
              "endLine": 391
            },
            {
              "startLine": 403,
              "endLine": 404
            },
            {
              "startLine": 426,
              "endLine": 426
            }
          ]
        },
        "uncoveredFnBody": "def make_blueprint(config: SecureDropConfig) -> Blueprint:\n    view = Blueprint(\"main\", __name__)\n\n    @view.route(\"/\")\n    def index() -> str:\n        return render_template(\"index.html\")\n\n    @view.route(\"/generate\", methods=(\"POST\", \"GET\"))\n    def generate() -> Union[str, werkzeug.Response]:\n        if request.method == \"POST\":\n            # Try to detect Tor2Web usage by looking to see if tor2web_check got mangled\n            tor2web_check = request.form.get(\"tor2web_check\")\n            if tor2web_check is None:\n                # Missing form field\n                abort(403)\n            elif tor2web_check != 'href=\"fake.onion\"':\n                return redirect(url_for(\"info.tor2web_warning\"))\n\n        if SessionManager.is_user_logged_in(db_session=db.session):\n            flash_msg(\n                \"notification\",\n                None,\n                gettext(\n                    \"You were redirected because you are already logged in. \"\n                    \"If you want to create a new account, you should log out first.\"\n                ),\n            )\n            return redirect(url_for(\".lookup\"))\n        codename = PassphraseGenerator.get_default().generate_passphrase(\n            preferred_language=g.localeinfo.language\n        )\n\n        # Generate a unique id for each browser tab and associate the codename with this id.\n        # This will allow retrieval of the codename displayed in the tab from which the source has\n        # clicked to proceed to /generate (ref. issue #4458)\n        tab_id = urlsafe_b64encode(os.urandom(64)).decode()\n        codenames = session.get(\"codenames\", {})\n        codenames[tab_id] = codename\n        session[\"codenames\"] = fit_codenames_into_cookie(codenames)\n        session[\"codenames_expire\"] = datetime.now(timezone.utc) + timedelta(\n            minutes=config.SESSION_EXPIRATION_MINUTES\n        )\n        return render_template(\"generate.html\", codename=codename, tab_id=tab_id)\n\n    @view.route(\"/create\", methods=[\"POST\"])\n    def create() -> werkzeug.Response:\n        if SessionManager.is_user_logged_in(db_session=db.session):\n            flash_msg(\n                \"notification\",\n                None,\n                gettext(\n                    \"You are already logged in. Please verify your codename as it \"\n                    \"may differ from the one displayed on the previous page.\"\n                ),\n            )\n        else:\n            # Ensure the codenames have not expired\n            date_codenames_expire = session.get(\"codenames_expire\")\n            if not date_codenames_expire or datetime.now(timezone.utc) >= date_codenames_expire:\n                return clear_session_and_redirect_to_logged_out_page(flask_session=session)\n\n            tab_id = request.form[\"tab_id\"]\n            codename = session[\"codenames\"][tab_id]\n            del session[\"codenames\"]\n\n            try:\n                current_app.logger.info(\"Creating new source user...\")\n                create_source_user(\n                    db_session=db.session,\n                    source_passphrase=codename,\n                    source_app_storage=Storage.get_default(),\n                )\n            except (SourcePassphraseCollisionError, SourceDesignationCollisionError) as e:\n                current_app.logger.error(f\"Could not create a source: {e}\")\n                flash_msg(\n                    \"error\",\n                    None,\n                    gettext(\n                        \"There was a temporary problem creating your account. Please try again.\"\n                    ),\n                )\n                return redirect(url_for(\".index\"))\n\n            # All done - source user was successfully created\n            current_app.logger.info(\"New source user created\")\n            session[\"new_user_codename\"] = codename\n            SessionManager.log_user_in(\n                db_session=db.session, supplied_passphrase=DicewarePassphrase(codename)\n            )\n\n        return redirect(url_for(\".lookup\"))\n\n    @view.route(\"/lookup\", methods=(\"GET\",))\n    @login_required\n    def lookup(logged_in_source: SourceUser) -> str:\n        replies = []\n        logged_in_source_in_db = logged_in_source.get_db_record()\n        source_inbox = Reply.query.filter_by(\n            source_id=logged_in_source_in_db.id, deleted_by_source=False\n        ).all()\n\n        first_submission = logged_in_source_in_db.interaction_count == 0\n\n        if first_submission:\n            min_message_length = InstanceConfig.get_default().initial_message_min_len\n        else:\n            min_message_length = 0\n\n        for reply in source_inbox:\n            reply_path = Storage.get_default().path(\n                logged_in_source.filesystem_id,\n                reply.filename,\n            )\n            try:\n                with open(reply_path, \"rb\") as f:\n                    contents = f.read()\n                decrypted_reply = EncryptionManager.get_default().decrypt_journalist_reply(\n                    for_source_user=logged_in_source,\n                    ciphertext_in=contents,\n                )\n                reply.decrypted = decrypted_reply\n            except UnicodeDecodeError:\n                current_app.logger.error(f\"Could not decode reply {reply.filename}\")\n            except FileNotFoundError:\n                current_app.logger.error(f\"Reply file missing: {reply.filename}\")\n            except (GpgDecryptError, RedwoodError) as e:\n                current_app.logger.error(f\"Could not decrypt reply {reply.filename}: {str(e)}\")\n            else:\n                reply.date = datetime.utcfromtimestamp(os.stat(reply_path).st_mtime)\n                replies.append(reply)\n\n        # Sort the replies by date\n        replies.sort(key=operator.attrgetter(\"date\"), reverse=True)\n\n        return render_template(\n            \"lookup.html\",\n            is_user_logged_in=True,\n            allow_document_uploads=InstanceConfig.get_default().allow_document_uploads,\n            replies=replies,\n            min_len=min_message_length,\n            new_user_codename=session.get(\"new_user_codename\", None),\n            form=SubmissionForm(),\n        )\n\n    @view.route(\"/submit\", methods=(\"POST\",))\n    @login_required\n    def submit(logged_in_source: SourceUser) -> werkzeug.Response:\n        allow_document_uploads = InstanceConfig.get_default().allow_document_uploads\n        form = SubmissionForm()\n        if not form.validate():\n            for field, errors in form.errors.items():\n                for error in errors:\n                    flash_msg(\"error\", None, error)\n            return redirect(url_for(\"main.lookup\"))\n\n        msg = request.form[\"msg\"]\n        fh = None\n        if allow_document_uploads and \"fh\" in request.files:\n            fh = request.files[\"fh\"]\n\n        # Don't submit anything if it was an \"empty\" submission. #878\n        if not (msg or fh):\n            if allow_document_uploads:\n                html_contents = gettext(\"You must enter a message or choose a file to submit.\")\n            else:\n                html_contents = gettext(\"You must enter a message.\")\n\n            flash_msg(\"error\", None, html_contents)\n            return redirect(url_for(\"main.lookup\"))\n\n        fnames = []\n        logged_in_source_in_db = logged_in_source.get_db_record()\n        first_submission = logged_in_source_in_db.interaction_count == 0\n\n        if first_submission:\n            min_len = InstanceConfig.get_default().initial_message_min_len\n            if (min_len > 0) and (msg and not fh) and (len(msg) < min_len):\n                flash_msg(\n                    \"error\",\n                    None,\n                    gettext(\"Your first message must be at least {} characters long.\").format(\n                        min_len\n                    ),\n                )\n                return redirect(url_for(\"main.lookup\"))\n\n            # if the new_user_codename key is not present in the session, this is\n            # not a first session\n            new_codename = session.get(\"new_user_codename\", None)\n\n            codenames_rejected = InstanceConfig.get_default().reject_message_with_codename\n            if new_codename is not None:\n                if codenames_rejected and codename_detected(msg, new_codename):\n                    flash_msg(\n                        \"error\",\n                        None,\n                        gettext(\"Please do not submit your codename!\"),\n                        gettext(\n                            \"Keep your codename secret, and use it to log in later to \"\n                            \"check for replies.\"\n                        ),\n                    )\n                    return redirect(url_for(\"main.lookup\"))\n\n        if not os.path.exists(Storage.get_default().path(logged_in_source.filesystem_id)):\n            current_app.logger.debug(\n                f\"Store directory not found for source \"\n                f\"'{logged_in_source_in_db.journalist_designation}', creating one.\"\n            )\n            os.mkdir(Storage.get_default().path(logged_in_source.filesystem_id))\n\n        if msg:\n            logged_in_source_in_db.interaction_count += 1\n            fnames.append(\n                Storage.get_default().save_message_submission(\n                    logged_in_source_in_db.filesystem_id,\n                    logged_in_source_in_db.interaction_count,\n                    logged_in_source_in_db.journalist_filename,\n                    msg,\n                )\n            )\n        if fh:\n            logged_in_source_in_db.interaction_count += 1\n            fnames.append(\n                Storage.get_default().save_file_submission(\n                    logged_in_source_in_db.filesystem_id,\n                    logged_in_source_in_db.interaction_count,\n                    logged_in_source_in_db.journalist_filename,\n                    fh.filename,\n                    fh.stream,\n                )\n            )\n\n        if first_submission or msg or fh:\n            if first_submission:\n                html_contents = gettext(\n                    \"Thank you for sending this information to us. Please \"\n                    \"check back later for replies.\"\n                )\n            elif msg and not fh:\n                html_contents = gettext(\"Thanks! We received your message.\")\n            elif fh and not msg:\n                html_contents = gettext(\"Thanks! We received your file.\")\n            else:\n                html_contents = gettext(\"Thanks! We received your file and message.\")\n\n            flash_msg(\"success\", gettext(\"Success!\"), html_contents)\n\n        new_submissions = []\n        for fname in fnames:\n            submission = Submission(logged_in_source_in_db, fname, Storage.get_default())\n            db.session.add(submission)\n            new_submissions.append(submission)\n\n        logged_in_source_in_db.pending = False\n        logged_in_source_in_db.last_updated = datetime.now(timezone.utc)\n        db.session.commit()\n\n        for sub in new_submissions:\n            store.async_add_checksum_for_file(sub, Storage.get_default())\n\n        normalize_timestamps(logged_in_source)\n\n        return redirect(url_for(\"main.lookup\"))\n\n    @view.route(\"/delete\", methods=(\"POST\",))\n    @login_required\n    def delete(logged_in_source: SourceUser) -> werkzeug.Response:\n        \"\"\"This deletes the reply from the source's inbox, but preserves\n        the history for journalists such that they can view conversation\n        history.\n        \"\"\"\n\n        query = Reply.query.filter_by(\n            filename=request.form[\"reply_filename\"], source_id=logged_in_source.db_record_id\n        )\n        reply = get_one_or_else(query, current_app.logger, abort)\n        reply.deleted_by_source = True\n        db.session.add(reply)\n        db.session.commit()\n\n        flash_msg(\"success\", gettext(\"Success!\"), gettext(\"Reply deleted\"))\n        return redirect(url_for(\".lookup\"))\n\n    @view.route(\"/delete-all\", methods=(\"POST\",))\n    @login_required\n    def batch_delete(logged_in_source: SourceUser) -> werkzeug.Response:\n        replies = (\n            Reply.query.filter(Reply.source_id == logged_in_source.db_record_id)\n            .filter(Reply.deleted_by_source == False)\n            .all()\n        )\n        if len(replies) == 0:\n            current_app.logger.error(\"Found no replies when at least one was \" \"expected\")\n            return redirect(url_for(\".lookup\"))\n\n        for reply in replies:\n            reply.deleted_by_source = True\n            db.session.add(reply)\n        db.session.commit()\n\n        flash_msg(\"success\", gettext(\"Success!\"), gettext(\"All replies have been deleted\"))\n        return redirect(url_for(\".lookup\"))\n\n    @view.route(\"/login\", methods=(\"GET\", \"POST\"))\n    def login() -> Union[str, werkzeug.Response]:\n        form = LoginForm()\n        if not form.validate_on_submit():\n            return render_template(\"login.html\", form=form)\n        try:\n            source_user = SessionManager.log_user_in(\n                db_session=db.session,\n                supplied_passphrase=DicewarePassphrase(request.form[\"codename\"].strip()),\n            )\n        except InvalidPassphraseError:\n            current_app.logger.info(\"Login failed for invalid codename\")\n            flash_msg(\"error\", None, gettext(\"Sorry, that is not a recognized codename.\"))\n            return render_template(\"login.html\", form=form)\n        # Success: a valid passphrase was supplied and the source was logged-in\n        source = source_user.get_db_record()\n        if source.fingerprint is None:\n            # This legacy source didn't have a PGP keypair generated yet,\n            # do it now.\n            public_key, secret_key, fingerprint = redwood.generate_source_key_pair(\n                source_user.gpg_secret, source_user.filesystem_id\n            )\n            source.pgp_public_key = public_key\n            source.pgp_secret_key = secret_key\n            source.pgp_fingerprint = fingerprint\n            db.session.add(source)\n            db.session.commit()\n        elif source.pgp_secret_key is None:\n            # Need to migrate the secret key out of GPG\n            encryption_mgr = EncryptionManager.get_default()\n            try:\n                secret_key = encryption_mgr.get_source_secret_key_from_gpg(\n                    source.fingerprint, source_user.gpg_secret\n                )\n            except GpgKeyNotFoundError:\n                # Don't fail here, but it's likely decryption of journalist\n                # messages will fail.\n                secret_key = None\n            if secret_key:\n                source.pgp_secret_key = secret_key\n                db.session.add(source)\n                db.session.commit()\n                # Let's optimistically delete the GPG key from the keyring\n                # if *everything* has been migrated. If this fails it's OK,\n                # since we still try to delete from the keyring on source\n                # deletion too.\n                if source.pgp_fingerprint and source.pgp_public_key:\n                    try:\n                        encryption_mgr.delete_source_key_pair(source.filesystem_id)\n                    except:  # noqa: E722 # Untested\n                        pass # Untested\n\n        return redirect(url_for(\".lookup\", from_login=\"1\"))\n\n    @view.route(\"/logout\", methods=(\"POST\",))\n    @login_required\n    def logout(logged_in_source: SourceUser) -> Union[str, werkzeug.Response]:\n        \"\"\"\n        If a user is logged in, show them a logout page that prompts them to\n        click the New Identity button in Tor Browser to complete their session.\n        Otherwise redirect to the main Source Interface page.\n        \"\"\"\n        if SessionManager.is_user_logged_in(db_session=db.session):\n            SessionManager.log_user_out()\n\n            # Clear the session after we render the message so it's localized\n            # If a user specified a locale, save it and restore it\n            session.clear()\n            session[\"locale\"] = g.localeinfo.id\n\n            return render_template(\"logout.html\")\n        else:\n            return redirect(url_for(\".index\"))\n\n    @view.route(\"/robots.txt\")\n    def robots_txt() -> werkzeug.Response:\n        \"\"\"Tell robots we don't want them\"\"\"\n        resp = make_response(\"User-agent: *\\nDisallow: /\")\n        resp.headers[\"content-type\"] = \"text/plain\"\n        return resp\n\n    return view",
        "callGraphToTestedFunction": [
          "make_blueprint"
        ]
      }
    },
    {
      "functionName": "sig",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/_parsers.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/_parsers.py",
          "functionName": "sig",
          "lines": [
            {
              "startLine": 1233,
              "endLine": 1233
            },
            {
              "startLine": 1238,
              "endLine": 1244
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/_parsers.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "sig",
          "filePath": "pretty_bad_protocol/_parsers.py",
          "uncoveredLines": [
            {
              "startLine": 1233,
              "endLine": 1233
            },
            {
              "startLine": 1238,
              "endLine": 1244
            }
          ]
        },
        "uncoveredFnBody": "class ListKeys(list):\n    \"\"\"Handle status messages for --list-keys.\n\n    Handles pub and uid (relating the latter to the former).  Don't care about\n    the following attributes/status messages (from doc/DETAILS):\n\n    |  crt = X.509 certificate\n    |  crs = X.509 certificate and private key available\n    |  ssb = secret subkey (secondary key)\n    |  uat = user attribute (same as user id except for field 10).\n    |  pkd = public key data (special field format, see below)\n    |  grp = reserved for gpgsm\n    |  rvk = revocation key\n    \"\"\"\n\n    def __init__(self, gpg):  # type: ignore[no-untyped-def]\n        super().__init__()\n        self._gpg = gpg\n        self.curkey = None\n        self.curuid = None\n        self.fingerprints = []\n        self.uids = []\n        self.sigs = {}\n        self.certs = {}\n        self.revs = {}\n\n    def key(self, args):  # type: ignore[no-untyped-def]\n        vars = (\n            \"\"\"\n            type trust length algo keyid date expires dummy ownertrust uid\n        \"\"\"\n        ).split()\n        self.curkey = {}\n        for i in range(len(vars)):\n            self.curkey[vars[i]] = args[i]\n        self.curkey[\"uids\"] = []\n        self.curkey[\"sigs\"] = {}\n        self.curkey[\"rev\"] = {}\n        if self.curkey[\"uid\"]:\n            self.curuid = self.curkey[\"uid\"]\n            self.curkey[\"uids\"].append(self.curuid)\n            self.sigs[self.curuid] = set()\n            self.certs[self.curuid] = set()\n            self.revs[self.curuid] = set()\n            self.curkey[\"sigs\"][self.curuid] = []\n        del self.curkey[\"uid\"]\n        self.curkey[\"subkeys\"] = []\n        self.append(self.curkey)\n\n    pub = sec = key\n\n    def fpr(self, args):  # type: ignore[no-untyped-def]\n        self.curkey[\"fingerprint\"] = args[9]\n        self.fingerprints.append(args[9])\n\n    def uid(self, args):  # type: ignore[no-untyped-def]\n        uid = args[9]\n        uid = ESCAPE_PATTERN.sub(lambda m: chr(int(m.group(1), 16)), uid)\n        self.curkey[\"uids\"].append(uid)\n        self.curuid = uid\n        self.curkey[\"sigs\"][uid] = []\n        self.sigs[uid] = set()\n        self.certs[uid] = set()\n        self.uids.append(uid)\n\n    def sig(self, args):  # type: ignore[no-untyped-def]\n        vars = (\n            \"\"\"\n            type trust length algo keyid date expires dummy ownertrust uid\n        \"\"\"\n        ).split()\n        sig = {} # Untested\n        for i in range(len(vars)): # Untested\n            sig[vars[i]] = args[i] # Untested\n        self.curkey[\"sigs\"][self.curuid].append(sig) # Untested\n        self.sigs[self.curuid].add(sig[\"keyid\"]) # Untested\n        if sig[\"trust\"] == \"!\": # Untested\n            self.certs[self.curuid].add(sig[\"keyid\"]) # Untested\n\n    def sub(self, args):  # type: ignore[no-untyped-def]\n        subkey = [args[4], args[11]]\n        self.curkey[\"subkeys\"].append(subkey)\n\n    def rev(self, args):  # type: ignore[no-untyped-def]\n        self.curkey[\"rev\"] = {\"keyid\": args[4], \"revtime\": args[5], \"uid\": self.curuid}\n\n    def _handle_status(self, key, value):  # type: ignore[no-untyped-def]\n        pass",
        "callGraphToTestedFunction": [
          "sig"
        ]
      }
    },
    {
      "functionName": "get_accepted_languages",
      "replayTestFileNames": [],
      "file": "i18n.py",
      "callGraph": [
        {
          "file": "i18n.py",
          "functionName": "get_accepted_languages",
          "lines": [
            {
              "startLine": 238,
              "endLine": 240
            },
            {
              "startLine": 251,
              "endLine": 254
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "i18n.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_accepted_languages",
          "filePath": "i18n.py",
          "uncoveredLines": [
            {
              "startLine": 238,
              "endLine": 240
            },
            {
              "startLine": 251,
              "endLine": 254
            }
          ]
        },
        "uncoveredFnBody": "def get_accepted_languages() -> List[str]:\n    \"\"\"\n    Convert a request's list of accepted languages into locale identifiers.\n    \"\"\"\n    accept_languages = []\n    for code in request.accept_languages.values():\n        try:\n            parsed = Locale.parse(code, \"-\")\n            accept_languages.append(str(parsed))\n\n            # We only have two Chinese translations, simplified\n            # and traditional, based on script and not\n            # region. Browsers tend to send identifiers with\n            # region, e.g. zh-CN or zh-TW. Babel can generally\n            # infer the script from those, so we can fabricate a\n            # fallback entry without region, in the hope that it\n            # will match one of our translations and the site will\n            # at least be more legible at first contact than the\n            # probable default locale of English.\n            if parsed.language == \"zh\" and parsed.script: # Untested\n                accept_languages.append(str(Locale(language=parsed.language, script=parsed.script))) # Untested\n        except (ValueError, UnknownLocaleError): # Untested\n            pass # Untested\n    return accept_languages",
        "callGraphToTestedFunction": [
          "get_accepted_languages"
        ]
      }
    },
    {
      "functionName": "encrypt",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "encrypt",
          "lines": [
            {
              "startLine": 1048,
              "endLine": 1049
            },
            {
              "startLine": 1051,
              "endLine": 1054
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "encrypt",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 1048,
              "endLine": 1049
            },
            {
              "startLine": 1051,
              "endLine": 1054
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding) # Untested\n        result = self._encrypt(stream, recipients, **kwargs) # Untested\n        stream.close() # Untested\n        return result # Untested\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "encrypt"
        ]
      }
    },
    {
      "functionName": "import_ownertrust",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/_trust.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/_trust.py",
          "functionName": "import_ownertrust",
          "lines": [
            {
              "startLine": 75,
              "endLine": 76
            },
            {
              "startLine": 78,
              "endLine": 78
            },
            {
              "startLine": 80,
              "endLine": 83
            },
            {
              "startLine": 85,
              "endLine": 86
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/_trust.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "import_ownertrust",
          "filePath": "pretty_bad_protocol/_trust.py",
          "uncoveredLines": [
            {
              "startLine": 75,
              "endLine": 76
            },
            {
              "startLine": 78,
              "endLine": 78
            },
            {
              "startLine": 80,
              "endLine": 83
            },
            {
              "startLine": 85,
              "endLine": 86
            }
          ]
        },
        "uncoveredFnBody": "def import_ownertrust(cls, trustdb=None):  # type: ignore[no-untyped-def]\n    \"\"\"Import ownertrust from a trustdb file.\n\n    :param str trustdb: The path to the trustdb.gpg file. If not given,\n                        defaults to :file:`trustdb.gpg` in the current GnuPG\n                        homedir.\n    \"\"\"\n    if trustdb is None:\n        trustdb = os.path.join(cls.homedir, \"trustdb.gpg\")\n\n    import_proc = cls._open_subprocess([\"--import-ownertrust\"])\n\n    try: # Untested\n        tdb = open(trustdb, \"rb\") # Untested\n    except OSError: # Untested\n        log.error(\"trustdb file %s does not exist!\" % trustdb) # Untested\n\n    _util._threaded_copy_data(tdb, import_proc.stdin)\n    import_proc.wait()",
        "callGraphToTestedFunction": [
          "import_ownertrust"
        ]
      }
    },
    {
      "functionName": "add_journalist",
      "replayTestFileNames": [],
      "file": "loaddata.py",
      "callGraph": [
        {
          "file": "loaddata.py",
          "functionName": "add_journalist",
          "lines": [
            {
              "startLine": 127,
              "endLine": 127
            },
            {
              "startLine": 137,
              "endLine": 138
            },
            {
              "startLine": 140,
              "endLine": 140
            },
            {
              "startLine": 147,
              "endLine": 148
            },
            {
              "startLine": 150,
              "endLine": 153
            },
            {
              "startLine": 155,
              "endLine": 159
            },
            {
              "startLine": 161,
              "endLine": 161
            },
            {
              "startLine": 171,
              "endLine": 171
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "loaddata.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "add_journalist",
          "filePath": "loaddata.py",
          "uncoveredLines": [
            {
              "startLine": 127,
              "endLine": 127
            },
            {
              "startLine": 137,
              "endLine": 138
            },
            {
              "startLine": 140,
              "endLine": 140
            },
            {
              "startLine": 147,
              "endLine": 148
            },
            {
              "startLine": 150,
              "endLine": 153
            },
            {
              "startLine": 155,
              "endLine": 159
            },
            {
              "startLine": 161,
              "endLine": 161
            },
            {
              "startLine": 171,
              "endLine": 171
            }
          ]
        },
        "uncoveredFnBody": "def add_journalist(\n    username: str,\n    is_admin: bool = False,\n    first_name: str = \"\",\n    last_name: str = \"\",\n    progress: Optional[Tuple[int, int]] = None,\n) -> Journalist:\n    \"\"\"\n    Adds a single journalist account.\n    \"\"\"\n    test_password = \"correct horse battery staple profanity oil chewy\"\n    test_otp_secret = \"JHCOGO7VCER3EJ4L\"\n\n    journalist = Journalist(\n        username=username,\n        password=test_password,\n        first_name=first_name,\n        last_name=last_name,\n        is_admin=is_admin,\n    )\n    journalist.otp_secret = test_otp_secret\n    if random_bool():\n        # to add legacy passwords back in\n        journalist.passphrase_hash = None\n        salt = random_chars(32).encode(\"utf-8\")\n        journalist.pw_salt = salt\n        journalist.pw_hash = journalist._scrypt_hash(test_password, salt)\n\n    db.session.add(journalist) # Untested\n    attempt = JournalistLoginAttempt(journalist) # Untested\n    attempt.timestamp = random_datetime(nullable=True) # Untested\n    db.session.add(attempt) # Untested\n    db.session.commit() # Untested\n\n    print(\n        \"Created {}journalist{} (username={}, password={}, otp_secret={}, is_admin={})\".format(\n            \"additional \" if progress else \"\",\n            \" {}/{}\".format(*progress) if progress else \"\",\n            username,\n            test_password,\n            test_otp_secret,\n            is_admin,\n        )\n    )\n    return journalist",
        "callGraphToTestedFunction": [
          "add_journalist"
        ]
      }
    },
    {
      "functionName": "commit_account_changes",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "commit_account_changes",
          "lines": [
            {
              "startLine": 39,
              "endLine": 44
            },
            {
              "startLine": 48,
              "endLine": 49
            },
            {
              "startLine": 51,
              "endLine": 51
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "commit_account_changes",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 39,
              "endLine": 44
            },
            {
              "startLine": 48,
              "endLine": 49
            },
            {
              "startLine": 51,
              "endLine": 51
            }
          ]
        },
        "uncoveredFnBody": "def commit_account_changes(user: Journalist) -> None:\n    if db.session.is_modified(user): # Untested\n        try: # Untested\n            db.session.add(user) # Untested\n            db.session.commit() # Untested\n        except Exception as e: # Untested\n            flash( # Untested\n                gettext(\"An unexpected error occurred! Please \" \"inform your admin.\"),\n                \"error\",\n            )\n            current_app.logger.error(f\"Account changes for '{user}' failed: {e}\")\n            db.session.rollback()\n        else:\n            flash(gettext(\"Account updated.\"), \"success\")",
        "callGraphToTestedFunction": [
          "commit_account_changes"
        ]
      }
    },
    {
      "functionName": "submit_file",
      "replayTestFileNames": [],
      "file": "loaddata.py",
      "callGraph": [
        {
          "file": "loaddata.py",
          "functionName": "submit_file",
          "lines": [
            {
              "startLine": 203,
              "endLine": 203
            },
            {
              "startLine": 207,
              "endLine": 209
            },
            {
              "startLine": 211,
              "endLine": 211
            },
            {
              "startLine": 213,
              "endLine": 213
            },
            {
              "startLine": 221,
              "endLine": 222
            },
            {
              "startLine": 224,
              "endLine": 226
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "loaddata.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "submit_file",
          "filePath": "loaddata.py",
          "uncoveredLines": [
            {
              "startLine": 203,
              "endLine": 203
            },
            {
              "startLine": 207,
              "endLine": 209
            },
            {
              "startLine": 211,
              "endLine": 211
            },
            {
              "startLine": 213,
              "endLine": 213
            },
            {
              "startLine": 221,
              "endLine": 222
            },
            {
              "startLine": 224,
              "endLine": 226
            }
          ]
        },
        "uncoveredFnBody": "def submit_file(source: Source, journalist_who_saw: Optional[Journalist], size: int = 0) -> None:\n    \"\"\"\n    Adds a single file submitted by a source.\n    \"\"\"\n    record_source_interaction(source)\n    if not size:\n        file_bytes = b\"This is an example of a plain text file upload\"\n    else:\n        file_bytes = os.urandom(size * 1024)\n\n    fpath = Storage.get_default().save_file_submission(\n        source.filesystem_id,\n        source.interaction_count,\n        source.journalist_filename,\n        \"memo.txt\",\n        io.BytesIO(file_bytes),\n    )\n\n    submission = Submission(source, fpath, Storage.get_default())\n    db.session.add(submission)\n\n    if journalist_who_saw: # Untested\n        seen_file = SeenFile(file=submission, journalist=journalist_who_saw) # Untested\n        db.session.add(seen_file) # Untested",
        "callGraphToTestedFunction": [
          "submit_file"
        ]
      }
    },
    {
      "functionName": "get_bulk_archive",
      "replayTestFileNames": [],
      "file": "store.py",
      "callGraph": [
        {
          "file": "store.py",
          "functionName": "get_bulk_archive",
          "lines": [
            {
              "startLine": 192,
              "endLine": 192
            },
            {
              "startLine": 195,
              "endLine": 195
            },
            {
              "startLine": 198,
              "endLine": 198
            },
            {
              "startLine": 200,
              "endLine": 203
            },
            {
              "startLine": 206,
              "endLine": 207
            },
            {
              "startLine": 209,
              "endLine": 212
            },
            {
              "startLine": 214,
              "endLine": 215
            },
            {
              "startLine": 224,
              "endLine": 225
            },
            {
              "startLine": 227,
              "endLine": 228
            },
            {
              "startLine": 230,
              "endLine": 230
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "store.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_bulk_archive",
          "filePath": "store.py",
          "uncoveredLines": [
            {
              "startLine": 192,
              "endLine": 192
            },
            {
              "startLine": 195,
              "endLine": 195
            },
            {
              "startLine": 198,
              "endLine": 198
            },
            {
              "startLine": 200,
              "endLine": 203
            },
            {
              "startLine": 206,
              "endLine": 207
            },
            {
              "startLine": 209,
              "endLine": 212
            },
            {
              "startLine": 214,
              "endLine": 215
            },
            {
              "startLine": 224,
              "endLine": 225
            },
            {
              "startLine": 227,
              "endLine": 228
            },
            {
              "startLine": 230,
              "endLine": 230
            }
          ]
        },
        "uncoveredFnBody": "class Storage:\n    def __init__(self, storage_path: str, temp_dir: str) -> None:\n        if not os.path.isabs(storage_path):\n            raise PathException(f\"storage_path {storage_path} is not absolute\")\n        self.__storage_path = storage_path\n\n        if not os.path.isabs(temp_dir):\n            raise PathException(f\"temp_dir {temp_dir} is not absolute\")\n        self.__temp_dir = temp_dir\n\n        # where files and directories are sent to be securely deleted\n        self.__shredder_path = os.path.abspath(os.path.join(self.__storage_path, \"../shredder\"))\n        os.makedirs(self.__shredder_path, mode=0o700, exist_ok=True)\n\n        # crash if we don't have a way to securely remove files\n        if not rm.check_secure_delete_capability():\n            raise AssertionError(\"Secure file deletion is not possible.\")\n\n    @classmethod\n    def get_default(cls) -> \"Storage\":\n        global _default_storage\n        if _default_storage is None:\n            config = SecureDropConfig.get_current()\n            _default_storage = cls(str(config.STORE_DIR), str(config.TEMP_DIR))\n\n        return _default_storage\n\n    @property\n    def storage_path(self) -> str:\n        return self.__storage_path\n\n    @property\n    def shredder_path(self) -> str:\n        return self.__shredder_path\n\n    def shredder_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the shredder.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__shredder_path))\n        return common_path == self.__shredder_path\n\n    def store_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the store.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__storage_path))\n        return common_path == self.__storage_path\n\n    def verify(self, p: str) -> bool:\n        \"\"\"\n        Verify that a given path is valid for the store.\n        \"\"\"\n\n        if self.store_contains(p):\n            # verifying a hypothetical path\n            if not os.path.exists(p):\n                return True\n\n            # extant paths must be directories or correctly-named plain files\n            if os.path.isdir(p):\n                return True\n\n            if os.path.isfile(p) and VALIDATE_FILENAME(os.path.basename(p)):\n                return True\n\n        raise PathException(f\"Path not valid in store: {p}\")\n\n    def path(self, filesystem_id: str, filename: str = \"\") -> str:\n        \"\"\"\n        Returns the path resolved within `self.__storage_path`.\n\n        Raises PathException if `verify` doesn't like the path.\n        \"\"\"\n        joined = os.path.join(os.path.realpath(self.__storage_path), filesystem_id, filename)\n        absolute = os.path.realpath(joined)\n        if not self.verify(absolute):\n            raise PathException(\n                f'Could not resolve (\"{filesystem_id}\", \"{filename}\") to a path within '\n                \"the store.\"\n            )\n        return absolute\n\n    def path_without_filesystem_id(self, filename: str) -> str:\n        \"\"\"Get the normalized, absolute file path, within\n        `self.__storage_path` for a filename when the filesystem_id\n        is not known.\n        \"\"\"\n\n        joined_paths = []\n        for rootdir, _, files in os.walk(os.path.realpath(self.__storage_path)):\n            for file_ in files:\n                if file_ in filename:\n                    joined_paths.append(os.path.join(rootdir, file_))\n\n        if len(joined_paths) > 1:\n            raise TooManyFilesException(\"Found duplicate files!\")\n        elif len(joined_paths) == 0:\n            raise NoFileFoundException(f\"File not found: {filename}\")\n        else:\n            absolute = joined_paths[0]\n\n        if not self.verify(absolute):\n            raise PathException(f\"\"\"Could not resolve \"{filename}\" to a path within the store.\"\"\")\n        return absolute\n\n    def get_bulk_archive(\n        self, selected_submissions: \"List\", zip_directory: str = \"\"\n    ) -> \"_TemporaryFileWrapper\":\n        \"\"\"Generate a zip file from the selected submissions\"\"\"\n        zip_file = tempfile.NamedTemporaryFile(\n            prefix=\"tmp_securedrop_bulk_dl_\", dir=self.__temp_dir, delete=False\n        )\n        sources = {i.source.journalist_designation for i in selected_submissions}\n        # The below nested for-loops are there to create a more usable\n        # folder structure per #383\n        missing_files = False\n\n        with zipfile.ZipFile(zip_file, \"w\") as zip:\n            for source in sources:\n                fname = \"\"\n                submissions = [\n                    s for s in selected_submissions if s.source.journalist_designation == source\n                ]\n                for submission in submissions:\n                    filename = self.path(submission.source.filesystem_id, submission.filename)\n\n                    if os.path.exists(filename): # Untested\n                        document_number = submission.filename.split(\"-\")[0] # Untested\n                        if zip_directory == submission.source.journalist_filename: # Untested\n                            fname = zip_directory # Untested\n                        else:\n                            fname = os.path.join(zip_directory, source)\n                        zip.write(\n                            filename,\n                            arcname=os.path.join(\n                                fname,\n                                f\"{document_number}_{submission.source.last_updated.date()}\",\n                                os.path.basename(filename),\n                            ),\n                        )\n                    else:\n                        missing_files = True\n                        current_app.logger.error(f\"File {filename} not found\")\n\n        if missing_files:\n            raise FileNotFoundError\n        else:\n            return zip_file\n\n    def move_to_shredder(self, path: str) -> None:\n        \"\"\"\n        Moves content from the store to the shredder for secure deletion.\n\n        Python's safe_renames (and the underlying rename(2) calls) will\n        silently overwrite content, which could bypass secure\n        deletion, so we create a temporary directory under the\n        shredder directory and move the specified content there.\n\n        This function is intended to be atomic and quick, for use in\n        deletions via the UI and API. The actual secure deletion is\n        performed by an asynchronous process that monitors the\n        shredder directory.\n        \"\"\"\n        if not self.verify(path):\n            raise ValueError(f\"\"\"Path is not within the store: \"{path}\" \"\"\")\n\n        if not os.path.exists(path):\n            raise ValueError(f\"\"\"Path does not exist: \"{path}\" \"\"\")\n\n        relpath = os.path.relpath(path, start=self.storage_path)\n        dest = os.path.join(tempfile.mkdtemp(dir=self.__shredder_path), relpath)\n        current_app.logger.info(f\"Moving {path} to shredder: {dest}\")\n        safe_renames(path, dest)\n\n    def clear_shredder(self) -> None:\n        current_app.logger.info(\"Clearing shredder\")\n        directories = []\n        targets = []\n        for directory, subdirs, files in os.walk(self.shredder_path):\n            for subdir in subdirs:\n                real_subdir = os.path.realpath(os.path.join(directory, subdir))\n                if self.shredder_contains(real_subdir):\n                    directories.append(real_subdir)\n            for f in files:\n                abs_file = os.path.abspath(os.path.join(directory, f))\n                if os.path.islink(abs_file):\n                    # Somehow, a symbolic link was created in the\n                    # store. This shouldn't happen in normal\n                    # operations. Just remove the link; don't try to\n                    # shred its target. Note that we only have special\n                    # handling for symlinks. Hard links -- which\n                    # again, shouldn't occur in the store -- will\n                    # result in the file data being shredded once for\n                    # each link.\n                    current_app.logger.info(f\"Deleting link {abs_file} to {os.readlink(abs_file)}\")\n                    os.unlink(abs_file)\n                    continue\n                if self.shredder_contains(abs_file):\n                    targets.append(abs_file)\n\n        target_count = len(targets)\n        current_app.logger.info(f\"Files to delete: {target_count}\")\n        for i, t in enumerate(targets, 1):\n            current_app.logger.info(f\"Securely deleting file {i}/{target_count}: {t}\")\n            rm.secure_delete(t)\n            current_app.logger.info(f\"Securely deleted file {i}/{target_count}: {t}\")\n\n        directories_to_remove = set(directories)\n        dir_count = len(directories_to_remove)\n        for i, d in enumerate(reversed(sorted(directories_to_remove)), 1):\n            current_app.logger.debug(f\"Removing directory {i}/{dir_count}: {d}\")\n            os.rmdir(d)\n            current_app.logger.debug(f\"Removed directory {i}/{dir_count}: {d}\")\n\n    def save_file_submission(\n        self,\n        filesystem_id: str,\n        count: int,\n        journalist_filename: str,\n        filename: Optional[str],\n        stream: BinaryIO,\n    ) -> str:\n        if filename is not None:\n            sanitized_filename = secure_filename(filename)\n        else:\n            sanitized_filename = secure_filename(\"unknown.file\")\n\n        # We store file submissions in a .gz file for two reasons:\n        #\n        # 1. Downloading large files over Tor is very slow. If we can\n        # compress the file, we can speed up future downloads.\n        #\n        # 2. We want to record the original filename because it might be\n        # useful, either for context about the content of the submission\n        # or for figuring out which application should be used to open\n        # it. However, we'd like to encrypt that info and have the\n        # decrypted file automatically have the name of the original\n        # file. Given various usability constraints in GPG and Tails, this\n        # is the most user-friendly way we have found to do this.\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-doc.gz.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n        with SecureTemporaryFile(\"/tmp\") as stf:  # noqa: S108\n            with gzip.GzipFile(filename=sanitized_filename, mode=\"wb\", fileobj=stf, mtime=0) as gzf:\n                # Buffer the stream into the gzip file to avoid excessive\n                # memory consumption\n                while True:\n                    buf = stream.read(1024 * 8)\n                    if not buf:\n                        break\n                    gzf.write(buf)\n\n            EncryptionManager.get_default().encrypt_source_file(\n                file_in=stf,\n                encrypted_file_path_out=Path(encrypted_file_path),\n            )\n\n        return encrypted_file_name\n\n    def save_pre_encrypted_reply(\n        self, filesystem_id: str, count: int, journalist_filename: str, content: str\n    ) -> str:\n        if \"-----BEGIN PGP MESSAGE-----\" not in content.split(\"\\n\")[0]:\n            raise NotEncrypted\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-reply.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n\n        with open(encrypted_file_path, \"w\") as fh:\n            fh.write(content)\n\n        return encrypted_file_path\n\n    def save_message_submission(\n        self, filesystem_id: str, count: int, journalist_filename: str, message: str\n    ) -> str:\n        filename = f\"{count}-{journalist_filename}-msg.gpg\"\n        msg_loc = self.path(filesystem_id, filename)\n        EncryptionManager.get_default().encrypt_source_message(\n            message_in=message,\n            encrypted_message_path_out=Path(msg_loc),\n        )\n        return filename",
        "callGraphToTestedFunction": [
          "get_bulk_archive"
        ]
      }
    },
    {
      "functionName": "decrypt_file",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "decrypt_file",
          "lines": [
            {
              "startLine": 1078,
              "endLine": 1088
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "decrypt_file",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 1078,
              "endLine": 1088
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"] # Untested\n        if output:  # write the output to a file with the specified name # Untested\n            if os.path.exists(output): # Untested\n                os.remove(output)  # to avoid overwrite confirmation message # Untested\n            args.append(\"--output %s\" % output) # Untested\n        if always_trust: # Untested\n            args.append(\"--always-trust\") # Untested\n        result = self._result_map[\"crypt\"](self) # Untested\n        self._handle_io(args, filename, result, passphrase, binary=True) # Untested\n        log.debug(\"decrypt result: %r\", result.data) # Untested\n        return result # Untested",
        "callGraphToTestedFunction": [
          "decrypt_file"
        ]
      }
    },
    {
      "functionName": "export_ownertrust",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/_trust.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/_trust.py",
          "functionName": "export_ownertrust",
          "lines": [
            {
              "startLine": 54,
              "endLine": 55
            },
            {
              "startLine": 57,
              "endLine": 60
            },
            {
              "startLine": 62,
              "endLine": 65
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/_trust.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "export_ownertrust",
          "filePath": "pretty_bad_protocol/_trust.py",
          "uncoveredLines": [
            {
              "startLine": 54,
              "endLine": 55
            },
            {
              "startLine": 57,
              "endLine": 60
            },
            {
              "startLine": 62,
              "endLine": 65
            }
          ]
        },
        "uncoveredFnBody": "def export_ownertrust(cls, trustdb=None):  # type: ignore[no-untyped-def]\n    \"\"\"Export ownertrust to a trustdb file.\n\n    If there is already a file named :file:`trustdb.gpg` in the current GnuPG\n    homedir, it will be renamed to :file:`trustdb.gpg.bak`.\n\n    :param string trustdb: The path to the trustdb.gpg file. If not given,\n                           defaults to ``'trustdb.gpg'`` in the current GnuPG\n                           homedir.\n    \"\"\"\n    if trustdb is None:\n        trustdb = os.path.join(cls.homedir, \"trustdb.gpg\")\n\n    try:\n        os.rename(trustdb, trustdb + \".bak\")\n    except OSError as err:\n        log.debug(str(err))\n\n    export_proc = cls._open_subprocess([\"--export-ownertrust\"]) # Untested\n    tdb = open(trustdb, \"wb\") # Untested\n    _util._threaded_copy_data(export_proc.stdout, tdb) # Untested\n    export_proc.wait() # Untested",
        "callGraphToTestedFunction": [
          "export_ownertrust"
        ]
      }
    },
    {
      "functionName": "verify_pending_password",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "verify_pending_password",
          "lines": [
            {
              "startLine": 453,
              "endLine": 454
            },
            {
              "startLine": 456,
              "endLine": 464
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "verify_pending_password",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 453,
              "endLine": 454
            },
            {
              "startLine": 456,
              "endLine": 464
            }
          ]
        },
        "uncoveredFnBody": "def verify_pending_password(for_: Union[Journalist, Literal[\"new\"]], passphrase: str) -> None:\n    if isinstance(for_, Journalist):\n        id = str(for_.id)\n    else:  # \"new\"\n        id = for_ # Untested\n    pending_password_hash = session.get(f\"pending_password_{id}\") # Untested\n    if pending_password_hash is None: # Untested\n        raise PasswordError() # Untested\n    hasher = argon2.PasswordHasher(**ARGON2_PARAMS) # Untested\n    try: # Untested\n        hasher.verify(pending_password_hash, passphrase) # Untested\n    except argon2.exceptions.VerificationError: # Untested\n        raise PasswordError() # Untested",
        "callGraphToTestedFunction": [
          "verify_pending_password"
        ]
      }
    },
    {
      "functionName": "colorize",
      "replayTestFileNames": [],
      "file": "management/run.py",
      "callGraph": [
        {
          "file": "management/run.py",
          "functionName": "colorize",
          "lines": [
            {
              "startLine": 13,
              "endLine": 13
            },
            {
              "startLine": 19,
              "endLine": 19
            },
            {
              "startLine": 40,
              "endLine": 43
            },
            {
              "startLine": 45,
              "endLine": 45
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "management/run.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "colorize",
          "filePath": "management/run.py",
          "uncoveredLines": [
            {
              "startLine": 13,
              "endLine": 13
            },
            {
              "startLine": 19,
              "endLine": 19
            },
            {
              "startLine": 40,
              "endLine": 43
            },
            {
              "startLine": 45,
              "endLine": 45
            }
          ]
        },
        "uncoveredFnBody": "def colorize(s: str, color: str, bold: bool = False) -> str:\n    \"\"\"\n    Returns the string s surrounded by shell metacharacters to display\n    it with the given color and optionally bolded.\n    \"\"\"\n    # List of shell colors from https://www.siafoo.net/snippet/88\n    shell_colors = {\n        \"gray\": \"30\",\n        \"red\": \"31\",\n        \"green\": \"32\",\n        \"yellow\": \"33\",\n        \"blue\": \"34\",\n        \"magenta\": \"35\",\n        \"cyan\": \"36\",\n        \"white\": \"37\",\n        \"crimson\": \"38\",\n        \"highlighted_red\": \"41\",\n        \"highlighted_green\": \"42\",\n        \"highlighted_brown\": \"43\",\n        \"highlighted_blue\": \"44\",\n        \"highlighted_magenta\": \"45\",\n        \"highlighted_cyan\": \"46\",\n        \"highlighted_gray\": \"47\",\n        \"highlighted_crimson\": \"48\",\n    }\n\n    # Based on http://stackoverflow.com/a/2330297/1093000\n    attrs = [] # Untested\n    attrs.append(shell_colors[color]) # Untested\n    if bold: # Untested\n        attrs.append(\"1\") # Untested\n\n    return \"\\x1b[{}m{}\\x1b[0m\".format(\";\".join(attrs), s)",
        "callGraphToTestedFunction": [
          "colorize"
        ]
      }
    },
    {
      "functionName": "delete_pending_source",
      "replayTestFileNames": [],
      "file": "management/sources.py",
      "callGraph": [
        {
          "file": "management/sources.py",
          "functionName": "delete_pending_source",
          "lines": [
            {
              "startLine": 42,
              "endLine": 42
            },
            {
              "startLine": 46,
              "endLine": 53
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "management/sources.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "delete_pending_source",
          "filePath": "management/sources.py",
          "uncoveredLines": [
            {
              "startLine": 42,
              "endLine": 42
            },
            {
              "startLine": 46,
              "endLine": 53
            }
          ]
        },
        "uncoveredFnBody": "def delete_pending_source(source: Source) -> None:\n    \"\"\"\n    Delete a pending source from the database\n    \"\"\"\n    if source.pending: # Untested\n        with app_context(): # Untested\n            try: # Untested\n                db.session.delete(source) # Untested\n                db.session.commit() # Untested\n            except Exception as exc: # Untested\n                db.session.rollback() # Untested\n                print(f\"ERROR: Could not remove pending source: {exc}.\") # Untested",
        "callGraphToTestedFunction": [
          "delete_pending_source"
        ]
      }
    },
    {
      "functionName": "bulk_delete",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "bulk_delete",
          "lines": [
            {
              "startLine": 254,
              "endLine": 259
            },
            {
              "startLine": 261,
              "endLine": 262
            },
            {
              "startLine": 266,
              "endLine": 266
            },
            {
              "startLine": 277,
              "endLine": 278
            },
            {
              "startLine": 281,
              "endLine": 281
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "bulk_delete",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 254,
              "endLine": 259
            },
            {
              "startLine": 261,
              "endLine": 262
            },
            {
              "startLine": 266,
              "endLine": 266
            },
            {
              "startLine": 277,
              "endLine": 278
            },
            {
              "startLine": 281,
              "endLine": 281
            }
          ]
        },
        "uncoveredFnBody": "def bulk_delete(\n    filesystem_id: str, items_selected: List[Union[Submission, Reply]]\n) -> werkzeug.Response:\n    deletion_errors = 0 # Untested\n    for item in items_selected: # Untested\n        try: # Untested\n            delete_file_object(item) # Untested\n        except ValueError: # Untested\n            deletion_errors += 1 # Untested\n\n    num_selected = len(items_selected)\n    success_message = ngettext(\n        \"The item has been deleted.\", \"{num} items have been deleted.\", num_selected\n    ).format(num=num_selected)\n\n    flash(\n        Markup(\n            \"<b>{}</b> {}\".format(\n                # Translators: Precedes a message confirming the success of an operation.\n                escape(gettext(\"Success!\")),\n                escape(success_message),\n            )\n        ),\n        \"success\",\n    )\n\n    if deletion_errors > 0:\n        current_app.logger.error(\n            \"Disconnected submission entries (%d) were detected\", deletion_errors\n        )\n    return redirect(url_for(\"col.col\", filesystem_id=filesystem_id))",
        "callGraphToTestedFunction": [
          "bulk_delete"
        ]
      }
    },
    {
      "functionName": "expire",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "expire",
          "lines": [
            {
              "startLine": 600,
              "endLine": 600
            },
            {
              "startLine": 602,
              "endLine": 605
            },
            {
              "startLine": 607,
              "endLine": 607
            },
            {
              "startLine": 611,
              "endLine": 613
            },
            {
              "startLine": 615,
              "endLine": 616
            },
            {
              "startLine": 618,
              "endLine": 619
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "expire",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 600,
              "endLine": 600
            },
            {
              "startLine": 602,
              "endLine": 605
            },
            {
              "startLine": 607,
              "endLine": 607
            },
            {
              "startLine": 611,
              "endLine": 613
            },
            {
              "startLine": 615,
              "endLine": 616
            },
            {
              "startLine": 618,
              "endLine": 619
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try: # Untested\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0 # Untested\n        except IndexError: # Untested\n            sub_keys_number = 0 # Untested\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "expire"
        ]
      }
    },
    {
      "functionName": "path_without_filesystem_id",
      "replayTestFileNames": [],
      "file": "store.py",
      "callGraph": [
        {
          "file": "store.py",
          "functionName": "path_without_filesystem_id",
          "lines": [
            {
              "startLine": 171,
              "endLine": 175
            },
            {
              "startLine": 177,
              "endLine": 180
            },
            {
              "startLine": 182,
              "endLine": 182
            },
            {
              "startLine": 184,
              "endLine": 186
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "store.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "path_without_filesystem_id",
          "filePath": "store.py",
          "uncoveredLines": [
            {
              "startLine": 171,
              "endLine": 175
            },
            {
              "startLine": 177,
              "endLine": 180
            },
            {
              "startLine": 182,
              "endLine": 182
            },
            {
              "startLine": 184,
              "endLine": 186
            }
          ]
        },
        "uncoveredFnBody": "class Storage:\n    def __init__(self, storage_path: str, temp_dir: str) -> None:\n        if not os.path.isabs(storage_path):\n            raise PathException(f\"storage_path {storage_path} is not absolute\")\n        self.__storage_path = storage_path\n\n        if not os.path.isabs(temp_dir):\n            raise PathException(f\"temp_dir {temp_dir} is not absolute\")\n        self.__temp_dir = temp_dir\n\n        # where files and directories are sent to be securely deleted\n        self.__shredder_path = os.path.abspath(os.path.join(self.__storage_path, \"../shredder\"))\n        os.makedirs(self.__shredder_path, mode=0o700, exist_ok=True)\n\n        # crash if we don't have a way to securely remove files\n        if not rm.check_secure_delete_capability():\n            raise AssertionError(\"Secure file deletion is not possible.\")\n\n    @classmethod\n    def get_default(cls) -> \"Storage\":\n        global _default_storage\n        if _default_storage is None:\n            config = SecureDropConfig.get_current()\n            _default_storage = cls(str(config.STORE_DIR), str(config.TEMP_DIR))\n\n        return _default_storage\n\n    @property\n    def storage_path(self) -> str:\n        return self.__storage_path\n\n    @property\n    def shredder_path(self) -> str:\n        return self.__shredder_path\n\n    def shredder_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the shredder.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__shredder_path))\n        return common_path == self.__shredder_path\n\n    def store_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the store.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__storage_path))\n        return common_path == self.__storage_path\n\n    def verify(self, p: str) -> bool:\n        \"\"\"\n        Verify that a given path is valid for the store.\n        \"\"\"\n\n        if self.store_contains(p):\n            # verifying a hypothetical path\n            if not os.path.exists(p):\n                return True\n\n            # extant paths must be directories or correctly-named plain files\n            if os.path.isdir(p):\n                return True\n\n            if os.path.isfile(p) and VALIDATE_FILENAME(os.path.basename(p)):\n                return True\n\n        raise PathException(f\"Path not valid in store: {p}\")\n\n    def path(self, filesystem_id: str, filename: str = \"\") -> str:\n        \"\"\"\n        Returns the path resolved within `self.__storage_path`.\n\n        Raises PathException if `verify` doesn't like the path.\n        \"\"\"\n        joined = os.path.join(os.path.realpath(self.__storage_path), filesystem_id, filename)\n        absolute = os.path.realpath(joined)\n        if not self.verify(absolute):\n            raise PathException(\n                f'Could not resolve (\"{filesystem_id}\", \"{filename}\") to a path within '\n                \"the store.\"\n            )\n        return absolute\n\n    def path_without_filesystem_id(self, filename: str) -> str:\n        \"\"\"Get the normalized, absolute file path, within\n        `self.__storage_path` for a filename when the filesystem_id\n        is not known.\n        \"\"\"\n\n        joined_paths = [] # Untested\n        for rootdir, _, files in os.walk(os.path.realpath(self.__storage_path)): # Untested\n            for file_ in files: # Untested\n                if file_ in filename: # Untested\n                    joined_paths.append(os.path.join(rootdir, file_)) # Untested\n\n        if len(joined_paths) > 1:\n            raise TooManyFilesException(\"Found duplicate files!\")\n        elif len(joined_paths) == 0:\n            raise NoFileFoundException(f\"File not found: {filename}\")\n        else:\n            absolute = joined_paths[0]\n\n        if not self.verify(absolute):\n            raise PathException(f\"\"\"Could not resolve \"{filename}\" to a path within the store.\"\"\")\n        return absolute\n\n    def get_bulk_archive(\n        self, selected_submissions: \"List\", zip_directory: str = \"\"\n    ) -> \"_TemporaryFileWrapper\":\n        \"\"\"Generate a zip file from the selected submissions\"\"\"\n        zip_file = tempfile.NamedTemporaryFile(\n            prefix=\"tmp_securedrop_bulk_dl_\", dir=self.__temp_dir, delete=False\n        )\n        sources = {i.source.journalist_designation for i in selected_submissions}\n        # The below nested for-loops are there to create a more usable\n        # folder structure per #383\n        missing_files = False\n\n        with zipfile.ZipFile(zip_file, \"w\") as zip:\n            for source in sources:\n                fname = \"\"\n                submissions = [\n                    s for s in selected_submissions if s.source.journalist_designation == source\n                ]\n                for submission in submissions:\n                    filename = self.path(submission.source.filesystem_id, submission.filename)\n\n                    if os.path.exists(filename):\n                        document_number = submission.filename.split(\"-\")[0]\n                        if zip_directory == submission.source.journalist_filename:\n                            fname = zip_directory\n                        else:\n                            fname = os.path.join(zip_directory, source)\n                        zip.write(\n                            filename,\n                            arcname=os.path.join(\n                                fname,\n                                f\"{document_number}_{submission.source.last_updated.date()}\",\n                                os.path.basename(filename),\n                            ),\n                        )\n                    else:\n                        missing_files = True\n                        current_app.logger.error(f\"File {filename} not found\")\n\n        if missing_files:\n            raise FileNotFoundError\n        else:\n            return zip_file\n\n    def move_to_shredder(self, path: str) -> None:\n        \"\"\"\n        Moves content from the store to the shredder for secure deletion.\n\n        Python's safe_renames (and the underlying rename(2) calls) will\n        silently overwrite content, which could bypass secure\n        deletion, so we create a temporary directory under the\n        shredder directory and move the specified content there.\n\n        This function is intended to be atomic and quick, for use in\n        deletions via the UI and API. The actual secure deletion is\n        performed by an asynchronous process that monitors the\n        shredder directory.\n        \"\"\"\n        if not self.verify(path):\n            raise ValueError(f\"\"\"Path is not within the store: \"{path}\" \"\"\")\n\n        if not os.path.exists(path):\n            raise ValueError(f\"\"\"Path does not exist: \"{path}\" \"\"\")\n\n        relpath = os.path.relpath(path, start=self.storage_path)\n        dest = os.path.join(tempfile.mkdtemp(dir=self.__shredder_path), relpath)\n        current_app.logger.info(f\"Moving {path} to shredder: {dest}\")\n        safe_renames(path, dest)\n\n    def clear_shredder(self) -> None:\n        current_app.logger.info(\"Clearing shredder\")\n        directories = []\n        targets = []\n        for directory, subdirs, files in os.walk(self.shredder_path):\n            for subdir in subdirs:\n                real_subdir = os.path.realpath(os.path.join(directory, subdir))\n                if self.shredder_contains(real_subdir):\n                    directories.append(real_subdir)\n            for f in files:\n                abs_file = os.path.abspath(os.path.join(directory, f))\n                if os.path.islink(abs_file):\n                    # Somehow, a symbolic link was created in the\n                    # store. This shouldn't happen in normal\n                    # operations. Just remove the link; don't try to\n                    # shred its target. Note that we only have special\n                    # handling for symlinks. Hard links -- which\n                    # again, shouldn't occur in the store -- will\n                    # result in the file data being shredded once for\n                    # each link.\n                    current_app.logger.info(f\"Deleting link {abs_file} to {os.readlink(abs_file)}\")\n                    os.unlink(abs_file)\n                    continue\n                if self.shredder_contains(abs_file):\n                    targets.append(abs_file)\n\n        target_count = len(targets)\n        current_app.logger.info(f\"Files to delete: {target_count}\")\n        for i, t in enumerate(targets, 1):\n            current_app.logger.info(f\"Securely deleting file {i}/{target_count}: {t}\")\n            rm.secure_delete(t)\n            current_app.logger.info(f\"Securely deleted file {i}/{target_count}: {t}\")\n\n        directories_to_remove = set(directories)\n        dir_count = len(directories_to_remove)\n        for i, d in enumerate(reversed(sorted(directories_to_remove)), 1):\n            current_app.logger.debug(f\"Removing directory {i}/{dir_count}: {d}\")\n            os.rmdir(d)\n            current_app.logger.debug(f\"Removed directory {i}/{dir_count}: {d}\")\n\n    def save_file_submission(\n        self,\n        filesystem_id: str,\n        count: int,\n        journalist_filename: str,\n        filename: Optional[str],\n        stream: BinaryIO,\n    ) -> str:\n        if filename is not None:\n            sanitized_filename = secure_filename(filename)\n        else:\n            sanitized_filename = secure_filename(\"unknown.file\")\n\n        # We store file submissions in a .gz file for two reasons:\n        #\n        # 1. Downloading large files over Tor is very slow. If we can\n        # compress the file, we can speed up future downloads.\n        #\n        # 2. We want to record the original filename because it might be\n        # useful, either for context about the content of the submission\n        # or for figuring out which application should be used to open\n        # it. However, we'd like to encrypt that info and have the\n        # decrypted file automatically have the name of the original\n        # file. Given various usability constraints in GPG and Tails, this\n        # is the most user-friendly way we have found to do this.\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-doc.gz.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n        with SecureTemporaryFile(\"/tmp\") as stf:  # noqa: S108\n            with gzip.GzipFile(filename=sanitized_filename, mode=\"wb\", fileobj=stf, mtime=0) as gzf:\n                # Buffer the stream into the gzip file to avoid excessive\n                # memory consumption\n                while True:\n                    buf = stream.read(1024 * 8)\n                    if not buf:\n                        break\n                    gzf.write(buf)\n\n            EncryptionManager.get_default().encrypt_source_file(\n                file_in=stf,\n                encrypted_file_path_out=Path(encrypted_file_path),\n            )\n\n        return encrypted_file_name\n\n    def save_pre_encrypted_reply(\n        self, filesystem_id: str, count: int, journalist_filename: str, content: str\n    ) -> str:\n        if \"-----BEGIN PGP MESSAGE-----\" not in content.split(\"\\n\")[0]:\n            raise NotEncrypted\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-reply.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n\n        with open(encrypted_file_path, \"w\") as fh:\n            fh.write(content)\n\n        return encrypted_file_path\n\n    def save_message_submission(\n        self, filesystem_id: str, count: int, journalist_filename: str, message: str\n    ) -> str:\n        filename = f\"{count}-{journalist_filename}-msg.gpg\"\n        msg_loc = self.path(filesystem_id, filename)\n        EncryptionManager.get_default().encrypt_source_message(\n            message_in=message,\n            encrypted_message_path_out=Path(msg_loc),\n        )\n        return filename",
        "callGraphToTestedFunction": [
          "path_without_filesystem_id"
        ]
      }
    },
    {
      "functionName": "upload",
      "replayTestFileNames": [],
      "file": "upload-screenshots.py",
      "callGraph": [
        {
          "file": "upload-screenshots.py",
          "functionName": "upload",
          "lines": [
            {
              "startLine": 146,
              "endLine": 146
            },
            {
              "startLine": 152,
              "endLine": 153
            },
            {
              "startLine": 155,
              "endLine": 155
            },
            {
              "startLine": 157,
              "endLine": 160
            },
            {
              "startLine": 162,
              "endLine": 165
            },
            {
              "startLine": 167,
              "endLine": 167
            },
            {
              "startLine": 169,
              "endLine": 172
            },
            {
              "startLine": 174,
              "endLine": 174
            },
            {
              "startLine": 179,
              "endLine": 181
            },
            {
              "startLine": 183,
              "endLine": 184
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "upload-screenshots.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "upload",
          "filePath": "upload-screenshots.py",
          "uncoveredLines": [
            {
              "startLine": 146,
              "endLine": 146
            },
            {
              "startLine": 152,
              "endLine": 153
            },
            {
              "startLine": 155,
              "endLine": 155
            },
            {
              "startLine": 157,
              "endLine": 160
            },
            {
              "startLine": 162,
              "endLine": 165
            },
            {
              "startLine": 167,
              "endLine": 167
            },
            {
              "startLine": 169,
              "endLine": 172
            },
            {
              "startLine": 174,
              "endLine": 174
            },
            {
              "startLine": 179,
              "endLine": 181
            },
            {
              "startLine": 183,
              "endLine": 184
            }
          ]
        },
        "uncoveredFnBody": "class WeblateUploader:\n    \"\"\"\n    Manages Weblate screenshot batch uploads, matching filenames against\n    titles of existing screenshots to create/update as appropriate.\n    \"\"\"\n\n    def __init__(\n        self,\n        token: str,\n        base_url: str,\n        project: str,\n        component: str,\n        files: List[str],\n        request_limit: int,\n        canonicalization_rules: List[Tuple[str, str]],\n    ) -> None:\n        if len(token) != 40:\n            raise BadOrMissingTokenError(\n                \"API token is not in expected 40 character format.\", base_url\n            )\n\n        self.base_url = base_url\n        self.screenshots_endpoint = urljoin(base_url, \"/api/screenshots/\")\n        self.project = project\n        self.component = component\n        self.files = files\n        self.request_limit = request_limit\n        self.canonicalization_rules = canonicalization_rules\n        self.user_agent = \"Python Weblate Uploader V1.0\"\n\n        # While not all requests require authentication, any useful operation of this\n        # script does, and providing a token for all requests ensures we avoid hitting\n        # the rate limit for unauthenticated users. See:\n        # https://docs.weblate.org/en/latest/api.html#rate-limiting\n        self.session = requests.Session()\n        headers = {\n            \"User-Agent\": self.user_agent,\n            \"Authorization\": f\"Token {token}\",\n        }\n        self.session.headers.update(headers)\n\n    def get_existing_screenshots(self) -> List[Dict[str, str]]:\n        \"\"\"\n        Obtains a list of all existing screenshots, and returns it as a list\n        in the API's format. Paginates up to the request limit.\n        \"\"\"\n        next_screenshots_url = self.screenshots_endpoint\n\n        # API results are paginated, so we must loop through a set of results and\n        # concatenate them.\n        screenshots: List[Dict[str, str]] = []\n        request_count = 0\n        while next_screenshots_url is not None:\n            response = self.session.get(next_screenshots_url)\n            response.raise_for_status()\n            screenshots_page = response.json()\n            next_screenshots_url = screenshots_page[\"next\"]\n            screenshots += screenshots_page[\"results\"]\n            request_count += 1\n            if request_count >= self.request_limit:\n                msg = f\"Request limit of {self.request_limit} exceeded. Aborting.\"\n                raise RequestLimitError(msg)\n        return screenshots\n\n    def _canonicalize(self, filename: str) -> str:\n        \"\"\"\n        Derives a human-readable title from a filename using the defined\n        canonicalization rules, if any. This is used to later update the\n        screenshot.\n        \"\"\"\n        for pattern, repl in self.canonicalization_rules:\n            filename = re.sub(pattern, repl, filename)\n        return filename\n\n    def upload(self, check_existing_screenshots: bool = True) -> None:\n        \"\"\"\n        Uploads all files using the screenshots endpoint. Optionally, checks\n        files against a list of existing screenshots and replaces them rather\n        than creating new uploads.\n        \"\"\"\n        if check_existing_screenshots is True:\n            existing_screenshots = self.get_existing_screenshots()\n        else:\n            existing_screenshots = []\n\n        for file in self.files:\n            basename = os.path.basename(file)\n            canonical_name = self._canonicalize(basename)\n            existing_screenshot_url = None\n\n            for screenshot in existing_screenshots:\n                if screenshot[\"name\"] == canonical_name:\n                    existing_screenshot_url = screenshot[\"file_url\"]\n                    break\n\n            image = {\"image\": open(file, \"rb\")}\n\n            if existing_screenshot_url is not None: # Untested\n                print(f\"Replacing existing screenshot {basename}\") # Untested\n                response = self.session.post(existing_screenshot_url, files=image) # Untested\n                response.raise_for_status() # Untested\n            else:\n                fields = {\n                    \"name\": canonical_name,\n                    \"project_slug\": \"securedrop\",\n                    \"component_slug\": \"securedrop\",\n                }\n                print(f\"Uploading new screenshot {basename}\")\n                response = self.session.post(self.screenshots_endpoint, files=image, data=fields)\n                response.raise_for_status()\n\n        result_url = urljoin(self.base_url, f\"screenshots/{self.project}/{self.component}\")\n        print(f\"Upload complete. Visit {result_url} to review the results.\")",
        "callGraphToTestedFunction": [
          "upload"
        ]
      }
    },
    {
      "functionName": "get_existing_screenshots",
      "replayTestFileNames": [],
      "file": "upload-screenshots.py",
      "callGraph": [
        {
          "file": "upload-screenshots.py",
          "functionName": "get_existing_screenshots",
          "lines": [
            {
              "startLine": 113,
              "endLine": 113
            },
            {
              "startLine": 118,
              "endLine": 118
            },
            {
              "startLine": 122,
              "endLine": 134
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "upload-screenshots.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_existing_screenshots",
          "filePath": "upload-screenshots.py",
          "uncoveredLines": [
            {
              "startLine": 113,
              "endLine": 113
            },
            {
              "startLine": 118,
              "endLine": 118
            },
            {
              "startLine": 122,
              "endLine": 134
            }
          ]
        },
        "uncoveredFnBody": "class WeblateUploader:\n    \"\"\"\n    Manages Weblate screenshot batch uploads, matching filenames against\n    titles of existing screenshots to create/update as appropriate.\n    \"\"\"\n\n    def __init__(\n        self,\n        token: str,\n        base_url: str,\n        project: str,\n        component: str,\n        files: List[str],\n        request_limit: int,\n        canonicalization_rules: List[Tuple[str, str]],\n    ) -> None:\n        if len(token) != 40:\n            raise BadOrMissingTokenError(\n                \"API token is not in expected 40 character format.\", base_url\n            )\n\n        self.base_url = base_url\n        self.screenshots_endpoint = urljoin(base_url, \"/api/screenshots/\")\n        self.project = project\n        self.component = component\n        self.files = files\n        self.request_limit = request_limit\n        self.canonicalization_rules = canonicalization_rules\n        self.user_agent = \"Python Weblate Uploader V1.0\"\n\n        # While not all requests require authentication, any useful operation of this\n        # script does, and providing a token for all requests ensures we avoid hitting\n        # the rate limit for unauthenticated users. See:\n        # https://docs.weblate.org/en/latest/api.html#rate-limiting\n        self.session = requests.Session()\n        headers = {\n            \"User-Agent\": self.user_agent,\n            \"Authorization\": f\"Token {token}\",\n        }\n        self.session.headers.update(headers)\n\n    def get_existing_screenshots(self) -> List[Dict[str, str]]:\n        \"\"\"\n        Obtains a list of all existing screenshots, and returns it as a list\n        in the API's format. Paginates up to the request limit.\n        \"\"\"\n        next_screenshots_url = self.screenshots_endpoint\n\n        # API results are paginated, so we must loop through a set of results and\n        # concatenate them.\n        screenshots: List[Dict[str, str]] = [] # Untested\n        request_count = 0 # Untested\n        while next_screenshots_url is not None: # Untested\n            response = self.session.get(next_screenshots_url) # Untested\n            response.raise_for_status() # Untested\n            screenshots_page = response.json() # Untested\n            next_screenshots_url = screenshots_page[\"next\"] # Untested\n            screenshots += screenshots_page[\"results\"] # Untested\n            request_count += 1 # Untested\n            if request_count >= self.request_limit: # Untested\n                msg = f\"Request limit of {self.request_limit} exceeded. Aborting.\" # Untested\n                raise RequestLimitError(msg) # Untested\n        return screenshots # Untested\n\n    def _canonicalize(self, filename: str) -> str:\n        \"\"\"\n        Derives a human-readable title from a filename using the defined\n        canonicalization rules, if any. This is used to later update the\n        screenshot.\n        \"\"\"\n        for pattern, repl in self.canonicalization_rules:\n            filename = re.sub(pattern, repl, filename)\n        return filename\n\n    def upload(self, check_existing_screenshots: bool = True) -> None:\n        \"\"\"\n        Uploads all files using the screenshots endpoint. Optionally, checks\n        files against a list of existing screenshots and replaces them rather\n        than creating new uploads.\n        \"\"\"\n        if check_existing_screenshots is True:\n            existing_screenshots = self.get_existing_screenshots()\n        else:\n            existing_screenshots = []\n\n        for file in self.files:\n            basename = os.path.basename(file)\n            canonical_name = self._canonicalize(basename)\n            existing_screenshot_url = None\n\n            for screenshot in existing_screenshots:\n                if screenshot[\"name\"] == canonical_name:\n                    existing_screenshot_url = screenshot[\"file_url\"]\n                    break\n\n            image = {\"image\": open(file, \"rb\")}\n\n            if existing_screenshot_url is not None:\n                print(f\"Replacing existing screenshot {basename}\")\n                response = self.session.post(existing_screenshot_url, files=image)\n                response.raise_for_status()\n            else:\n                fields = {\n                    \"name\": canonical_name,\n                    \"project_slug\": \"securedrop\",\n                    \"component_slug\": \"securedrop\",\n                }\n                print(f\"Uploading new screenshot {basename}\")\n                response = self.session.post(self.screenshots_endpoint, files=image, data=fields)\n                response.raise_for_status()\n\n        result_url = urljoin(self.base_url, f\"screenshots/{self.project}/{self.component}\")\n        print(f\"Upload complete. Visit {result_url} to review the results.\")",
        "callGraphToTestedFunction": [
          "get_existing_screenshots"
        ]
      }
    },
    {
      "functionName": "col_delete_data",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "col_delete_data",
          "lines": [
            {
              "startLine": 364,
              "endLine": 365
            },
            {
              "startLine": 376,
              "endLine": 377
            },
            {
              "startLine": 379,
              "endLine": 379
            },
            {
              "startLine": 390,
              "endLine": 390
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "col_delete_data",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 364,
              "endLine": 365
            },
            {
              "startLine": 376,
              "endLine": 377
            },
            {
              "startLine": 379,
              "endLine": 379
            },
            {
              "startLine": 390,
              "endLine": 390
            }
          ]
        },
        "uncoveredFnBody": "def col_delete_data(cols_selected: List[str]) -> werkzeug.Response:\n    \"\"\"deletes store data for selected sources\"\"\"\n    if len(cols_selected) < 1:\n        flash(\n            Markup(\n                \"<b>{}</b> {}\".format(\n                    # Translators: Error shown when a user has not selected items to act on.\n                    escape(gettext(\"Nothing Selected\")),\n                    escape(gettext(\"You must select one or more items for deletion.\")),\n                )\n            ),\n            \"error\",\n        )\n    else:\n        for filesystem_id in cols_selected: # Untested\n            delete_source_files(filesystem_id) # Untested\n\n        flash(\n            Markup(\n                \"<b>{}</b> {}\".format(\n                    # Translators: Precedes a message confirming the success of an operation.\n                    escape(gettext(\"Success!\")),\n                    escape(gettext(\"The files and messages have been deleted.\")),\n                )\n            ),\n            \"success\",\n        )\n\n    return redirect(url_for(\"main.index\"))",
        "callGraphToTestedFunction": [
          "col_delete_data"
        ]
      }
    },
    {
      "functionName": "add_sources",
      "replayTestFileNames": [],
      "file": "loaddata.py",
      "callGraph": [
        {
          "file": "loaddata.py",
          "functionName": "add_sources",
          "lines": [
            {
              "startLine": 343,
              "endLine": 343
            },
            {
              "startLine": 347,
              "endLine": 347
            },
            {
              "startLine": 349,
              "endLine": 351
            },
            {
              "startLine": 355,
              "endLine": 355
            },
            {
              "startLine": 359,
              "endLine": 360
            },
            {
              "startLine": 362,
              "endLine": 364
            },
            {
              "startLine": 366,
              "endLine": 367
            },
            {
              "startLine": 372,
              "endLine": 372
            },
            {
              "startLine": 374,
              "endLine": 375
            },
            {
              "startLine": 377,
              "endLine": 381
            },
            {
              "startLine": 383,
              "endLine": 383
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "loaddata.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "add_sources",
          "filePath": "loaddata.py",
          "uncoveredLines": [
            {
              "startLine": 343,
              "endLine": 343
            },
            {
              "startLine": 347,
              "endLine": 347
            },
            {
              "startLine": 349,
              "endLine": 351
            },
            {
              "startLine": 355,
              "endLine": 355
            },
            {
              "startLine": 359,
              "endLine": 360
            },
            {
              "startLine": 362,
              "endLine": 364
            },
            {
              "startLine": 366,
              "endLine": 367
            },
            {
              "startLine": 372,
              "endLine": 372
            },
            {
              "startLine": 374,
              "endLine": 375
            },
            {
              "startLine": 377,
              "endLine": 381
            },
            {
              "startLine": 383,
              "endLine": 383
            }
          ]
        },
        "uncoveredFnBody": "def add_sources(args: argparse.Namespace, journalists: Tuple[Journalist, ...]) -> None:\n    \"\"\"\n    Add sources with submissions and replies.\n    \"\"\"\n    default_journalist, dellsberg, journalist_to_be_deleted = journalists\n\n    starred_sources_count = int(args.source_count * args.source_star_fraction)\n    replied_sources_count = int(args.source_count * args.source_reply_fraction)\n    seen_message_count = max(\n        int(args.source_count * args.messages_per_source * args.seen_message_fraction),\n        1,\n    )\n    seen_file_count = max(\n        int(args.source_count * args.files_per_source * args.seen_file_fraction), 1\n    )\n\n    for i in range(1, args.source_count + 1):\n        source, codename = add_source(use_gpg=args.gpg)\n\n        for _ in range(args.messages_per_source):\n            submit_message(source, secrets.choice(journalists) if seen_message_count > 0 else None)\n            seen_message_count -= 1\n\n        for _ in range(args.files_per_source):\n            submit_file(\n                source,\n                secrets.choice(journalists) if seen_file_count > 0 else None,\n                args.random_file_size,\n            )\n            seen_file_count -= 1\n\n        if i <= starred_sources_count:\n            star_source(source)\n\n        if i <= replied_sources_count: # Untested\n            for _ in range(args.replies_per_source): # Untested\n                journalist_who_replied = secrets.choice([dellsberg, journalist_to_be_deleted]) # Untested\n                journalist_who_saw = secrets.choice([default_journalist, None]) # Untested\n                add_reply(source, journalist_who_replied, journalist_who_saw) # Untested\n\n        print(\n            f\"Created source {i}/{args.source_count} (codename: '{codename}', \"\n            f\"journalist designation '{source.journalist_designation}', \"\n            f\"files: {args.files_per_source}, messages: {args.messages_per_source}, \"\n            f\"replies: {args.replies_per_source if i <= replied_sources_count else 0})\"\n        )",
        "callGraphToTestedFunction": [
          "add_sources"
        ]
      }
    },
    {
      "functionName": "encrypted_to",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "encrypted_to",
          "lines": [
            {
              "startLine": 1136,
              "endLine": 1142
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "encrypted_to",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 1136,
              "endLine": 1142
            }
          ]
        },
        "uncoveredFnBody": "class GPGUtilities:\n    \"\"\"Extra tools for working with GnuPG.\"\"\"\n\n    def __init__(self, gpg):  # type: ignore[no-untyped-def]\n        \"\"\"Initialise extra utility functions.\"\"\"\n        self._gpg = gpg\n\n    def find_key_by_email(self, email, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"Find user's key based on their email address.\n\n        :param str email: The email address to search for.\n        :param bool secret: If True, search through secret keyring.\n        \"\"\"\n        for key in self.list_keys(secret=secret):\n            for uid in key[\"uids\"]:\n                if re.search(email, uid):\n                    return key\n        raise LookupError(\"GnuPG public key for email %s not found!\" % email)\n\n    def find_key_by_subkey(self, subkey):  # type: ignore[no-untyped-def]\n        \"\"\"Find a key by a fingerprint of one of its subkeys.\n\n        :param str subkey: The fingerprint of the subkey to search for.\n        \"\"\"\n        for key in self.list_keys():\n            for sub in key[\"subkeys\"]:\n                if sub[0] == subkey:\n                    return key\n        raise LookupError(\"GnuPG public key for subkey %s not found!\" % subkey)\n\n    def send_keys(self, keyserver, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Send keys to a keyserver.\"\"\"\n        result = self._result_map[\"list\"](self)\n        log.debug(\"send_keys: %r\", keyids)\n        data = _util._make_binary_stream(\"\", self._encoding)\n        args = [\"--keyserver\", keyserver, \"--send-keys\"]\n        args.extend(keyids)\n        self._handle_io(args, data, result, binary=True)\n        log.debug(\"send_keys result: %r\", result.__dict__)\n        data.close()\n        return result\n\n    def encrypted_to(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"Return the key to which raw_data is encrypted to.\"\"\"\n        # TODO: make this support multiple keys.\n        result = self._gpg.list_packets(raw_data) # Untested\n        if not result.key: # Untested\n            raise LookupError(\"Content is not encrypted to a GnuPG key!\") # Untested\n        try: # Untested\n            return self.find_key_by_keyid(result.key) # Untested\n        except:  # noqa: E722 # Untested\n            return self.find_key_by_subkey(result.key) # Untested\n\n    def is_encrypted_sym(self, raw_data):  # type: ignore[no-untyped-def]\n        result = self._gpg.list_packets(raw_data)\n        return bool(result.need_passphrase_sym)\n\n    def is_encrypted_asym(self, raw_data):  # type: ignore[no-untyped-def]\n        result = self._gpg.list_packets(raw_data)\n        return bool(result.key)\n\n    def is_encrypted(self, raw_data):  # type: ignore[no-untyped-def]\n        return self.is_encrypted_asym(raw_data) or self.is_encrypted_sym(raw_data)",
        "callGraphToTestedFunction": [
          "encrypted_to"
        ]
      }
    },
    {
      "functionName": "download",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "download",
          "lines": [
            {
              "startLine": 208,
              "endLine": 211
            },
            {
              "startLine": 221,
              "endLine": 223
            },
            {
              "startLine": 225,
              "endLine": 225
            },
            {
              "startLine": 229,
              "endLine": 229
            },
            {
              "startLine": 231,
              "endLine": 231
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "download",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 208,
              "endLine": 211
            },
            {
              "startLine": 221,
              "endLine": 223
            },
            {
              "startLine": 225,
              "endLine": 225
            },
            {
              "startLine": 229,
              "endLine": 229
            },
            {
              "startLine": 231,
              "endLine": 231
            }
          ]
        },
        "uncoveredFnBody": "def download(\n    zip_basename: str,\n    submissions: List[Union[Submission, Reply]],\n    on_error_redirect: Optional[str] = None,\n) -> werkzeug.Response:\n    \"\"\"Send client contents of ZIP-file *zip_basename*-<timestamp>.zip\n    containing *submissions*. The ZIP-file, being a\n    :class:`tempfile.NamedTemporaryFile`, is stored on disk only\n    temporarily.\n\n    :param str zip_basename: The basename of the ZIP-file download.\n\n    :param list submissions: A list of :class:`models.Submission`s to\n                             include in the ZIP-file.\n    \"\"\"\n    try: # Untested\n        zf = Storage.get_default().get_bulk_archive(submissions, zip_directory=zip_basename) # Untested\n    except FileNotFoundError: # Untested\n        flash( # Untested\n            ngettext(\n                \"Your download failed because the file could not be found. An admin can find \"\n                + \"more information in the system and monitoring logs.\",\n                \"Your download failed because a file could not be found. An admin can find \"\n                + \"more information in the system and monitoring logs.\",\n                len(submissions),\n            ),\n            \"error\",\n        )\n        if on_error_redirect is None:\n            on_error_redirect = url_for(\"main.index\")\n        return redirect(on_error_redirect)\n\n    attachment_filename = \"{}--{}.zip\".format(\n        zip_basename, datetime.now(timezone.utc).strftime(\"%Y-%m-%d--%H-%M-%S\")\n    )\n\n    mark_seen(submissions, session.get_user())\n\n    return send_file(\n        zf.name,\n        mimetype=\"application/zip\",\n        download_name=attachment_filename,\n        as_attachment=True,\n    )",
        "callGraphToTestedFunction": [
          "download"
        ]
      }
    },
    {
      "functionName": "get_logo_url",
      "replayTestFileNames": [],
      "file": "journalist_app/__init__.py",
      "callGraph": [
        {
          "file": "journalist_app/__init__.py",
          "functionName": "get_logo_url",
          "lines": [
            {
              "startLine": 27,
              "endLine": 28
            },
            {
              "startLine": 30,
              "endLine": 37
            },
            {
              "startLine": 39,
              "endLine": 39
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/__init__.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_logo_url",
          "filePath": "journalist_app/__init__.py",
          "uncoveredLines": [
            {
              "startLine": 27,
              "endLine": 28
            },
            {
              "startLine": 30,
              "endLine": 37
            },
            {
              "startLine": 39,
              "endLine": 39
            }
          ]
        },
        "uncoveredFnBody": "def get_logo_url(app: Flask) -> str:\n    if not app.static_folder:\n        raise FileNotFoundError\n\n    custom_logo_filename = \"i/custom_logo.png\" # Untested\n    default_logo_filename = \"i/logo.png\" # Untested\n    custom_logo_path = Path(app.static_folder) / custom_logo_filename # Untested\n    default_logo_path = Path(app.static_folder) / default_logo_filename # Untested\n    if custom_logo_path.is_file(): # Untested\n        return url_for(\"static\", filename=custom_logo_filename) # Untested\n    elif default_logo_path.is_file(): # Untested\n        return url_for(\"static\", filename=default_logo_filename) # Untested\n\n    raise FileNotFoundError",
        "callGraphToTestedFunction": [
          "get_logo_url"
        ]
      }
    },
    {
      "functionName": "clear_shredder",
      "replayTestFileNames": [],
      "file": "store.py",
      "callGraph": [
        {
          "file": "store.py",
          "functionName": "clear_shredder",
          "lines": [
            {
              "startLine": 258,
              "endLine": 268
            },
            {
              "startLine": 277,
              "endLine": 281
            },
            {
              "startLine": 283,
              "endLine": 288
            },
            {
              "startLine": 290,
              "endLine": 295
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "store.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "clear_shredder",
          "filePath": "store.py",
          "uncoveredLines": [
            {
              "startLine": 258,
              "endLine": 268
            },
            {
              "startLine": 277,
              "endLine": 281
            },
            {
              "startLine": 283,
              "endLine": 288
            },
            {
              "startLine": 290,
              "endLine": 295
            }
          ]
        },
        "uncoveredFnBody": "class Storage:\n    def __init__(self, storage_path: str, temp_dir: str) -> None:\n        if not os.path.isabs(storage_path):\n            raise PathException(f\"storage_path {storage_path} is not absolute\")\n        self.__storage_path = storage_path\n\n        if not os.path.isabs(temp_dir):\n            raise PathException(f\"temp_dir {temp_dir} is not absolute\")\n        self.__temp_dir = temp_dir\n\n        # where files and directories are sent to be securely deleted\n        self.__shredder_path = os.path.abspath(os.path.join(self.__storage_path, \"../shredder\"))\n        os.makedirs(self.__shredder_path, mode=0o700, exist_ok=True)\n\n        # crash if we don't have a way to securely remove files\n        if not rm.check_secure_delete_capability():\n            raise AssertionError(\"Secure file deletion is not possible.\")\n\n    @classmethod\n    def get_default(cls) -> \"Storage\":\n        global _default_storage\n        if _default_storage is None:\n            config = SecureDropConfig.get_current()\n            _default_storage = cls(str(config.STORE_DIR), str(config.TEMP_DIR))\n\n        return _default_storage\n\n    @property\n    def storage_path(self) -> str:\n        return self.__storage_path\n\n    @property\n    def shredder_path(self) -> str:\n        return self.__shredder_path\n\n    def shredder_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the shredder.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__shredder_path))\n        return common_path == self.__shredder_path\n\n    def store_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the store.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__storage_path))\n        return common_path == self.__storage_path\n\n    def verify(self, p: str) -> bool:\n        \"\"\"\n        Verify that a given path is valid for the store.\n        \"\"\"\n\n        if self.store_contains(p):\n            # verifying a hypothetical path\n            if not os.path.exists(p):\n                return True\n\n            # extant paths must be directories or correctly-named plain files\n            if os.path.isdir(p):\n                return True\n\n            if os.path.isfile(p) and VALIDATE_FILENAME(os.path.basename(p)):\n                return True\n\n        raise PathException(f\"Path not valid in store: {p}\")\n\n    def path(self, filesystem_id: str, filename: str = \"\") -> str:\n        \"\"\"\n        Returns the path resolved within `self.__storage_path`.\n\n        Raises PathException if `verify` doesn't like the path.\n        \"\"\"\n        joined = os.path.join(os.path.realpath(self.__storage_path), filesystem_id, filename)\n        absolute = os.path.realpath(joined)\n        if not self.verify(absolute):\n            raise PathException(\n                f'Could not resolve (\"{filesystem_id}\", \"{filename}\") to a path within '\n                \"the store.\"\n            )\n        return absolute\n\n    def path_without_filesystem_id(self, filename: str) -> str:\n        \"\"\"Get the normalized, absolute file path, within\n        `self.__storage_path` for a filename when the filesystem_id\n        is not known.\n        \"\"\"\n\n        joined_paths = []\n        for rootdir, _, files in os.walk(os.path.realpath(self.__storage_path)):\n            for file_ in files:\n                if file_ in filename:\n                    joined_paths.append(os.path.join(rootdir, file_))\n\n        if len(joined_paths) > 1:\n            raise TooManyFilesException(\"Found duplicate files!\")\n        elif len(joined_paths) == 0:\n            raise NoFileFoundException(f\"File not found: {filename}\")\n        else:\n            absolute = joined_paths[0]\n\n        if not self.verify(absolute):\n            raise PathException(f\"\"\"Could not resolve \"{filename}\" to a path within the store.\"\"\")\n        return absolute\n\n    def get_bulk_archive(\n        self, selected_submissions: \"List\", zip_directory: str = \"\"\n    ) -> \"_TemporaryFileWrapper\":\n        \"\"\"Generate a zip file from the selected submissions\"\"\"\n        zip_file = tempfile.NamedTemporaryFile(\n            prefix=\"tmp_securedrop_bulk_dl_\", dir=self.__temp_dir, delete=False\n        )\n        sources = {i.source.journalist_designation for i in selected_submissions}\n        # The below nested for-loops are there to create a more usable\n        # folder structure per #383\n        missing_files = False\n\n        with zipfile.ZipFile(zip_file, \"w\") as zip:\n            for source in sources:\n                fname = \"\"\n                submissions = [\n                    s for s in selected_submissions if s.source.journalist_designation == source\n                ]\n                for submission in submissions:\n                    filename = self.path(submission.source.filesystem_id, submission.filename)\n\n                    if os.path.exists(filename):\n                        document_number = submission.filename.split(\"-\")[0]\n                        if zip_directory == submission.source.journalist_filename:\n                            fname = zip_directory\n                        else:\n                            fname = os.path.join(zip_directory, source)\n                        zip.write(\n                            filename,\n                            arcname=os.path.join(\n                                fname,\n                                f\"{document_number}_{submission.source.last_updated.date()}\",\n                                os.path.basename(filename),\n                            ),\n                        )\n                    else:\n                        missing_files = True\n                        current_app.logger.error(f\"File {filename} not found\")\n\n        if missing_files:\n            raise FileNotFoundError\n        else:\n            return zip_file\n\n    def move_to_shredder(self, path: str) -> None:\n        \"\"\"\n        Moves content from the store to the shredder for secure deletion.\n\n        Python's safe_renames (and the underlying rename(2) calls) will\n        silently overwrite content, which could bypass secure\n        deletion, so we create a temporary directory under the\n        shredder directory and move the specified content there.\n\n        This function is intended to be atomic and quick, for use in\n        deletions via the UI and API. The actual secure deletion is\n        performed by an asynchronous process that monitors the\n        shredder directory.\n        \"\"\"\n        if not self.verify(path):\n            raise ValueError(f\"\"\"Path is not within the store: \"{path}\" \"\"\")\n\n        if not os.path.exists(path):\n            raise ValueError(f\"\"\"Path does not exist: \"{path}\" \"\"\")\n\n        relpath = os.path.relpath(path, start=self.storage_path)\n        dest = os.path.join(tempfile.mkdtemp(dir=self.__shredder_path), relpath)\n        current_app.logger.info(f\"Moving {path} to shredder: {dest}\")\n        safe_renames(path, dest)\n\n    def clear_shredder(self) -> None:\n        current_app.logger.info(\"Clearing shredder\") # Untested\n        directories = [] # Untested\n        targets = [] # Untested\n        for directory, subdirs, files in os.walk(self.shredder_path): # Untested\n            for subdir in subdirs: # Untested\n                real_subdir = os.path.realpath(os.path.join(directory, subdir)) # Untested\n                if self.shredder_contains(real_subdir): # Untested\n                    directories.append(real_subdir) # Untested\n            for f in files: # Untested\n                abs_file = os.path.abspath(os.path.join(directory, f)) # Untested\n                if os.path.islink(abs_file): # Untested\n                    # Somehow, a symbolic link was created in the\n                    # store. This shouldn't happen in normal\n                    # operations. Just remove the link; don't try to\n                    # shred its target. Note that we only have special\n                    # handling for symlinks. Hard links -- which\n                    # again, shouldn't occur in the store -- will\n                    # result in the file data being shredded once for\n                    # each link.\n                    current_app.logger.info(f\"Deleting link {abs_file} to {os.readlink(abs_file)}\")\n                    os.unlink(abs_file)\n                    continue\n                if self.shredder_contains(abs_file):\n                    targets.append(abs_file)\n\n        target_count = len(targets)\n        current_app.logger.info(f\"Files to delete: {target_count}\")\n        for i, t in enumerate(targets, 1):\n            current_app.logger.info(f\"Securely deleting file {i}/{target_count}: {t}\")\n            rm.secure_delete(t)\n            current_app.logger.info(f\"Securely deleted file {i}/{target_count}: {t}\")\n\n        directories_to_remove = set(directories)\n        dir_count = len(directories_to_remove)\n        for i, d in enumerate(reversed(sorted(directories_to_remove)), 1):\n            current_app.logger.debug(f\"Removing directory {i}/{dir_count}: {d}\")\n            os.rmdir(d)\n            current_app.logger.debug(f\"Removed directory {i}/{dir_count}: {d}\")\n\n    def save_file_submission(\n        self,\n        filesystem_id: str,\n        count: int,\n        journalist_filename: str,\n        filename: Optional[str],\n        stream: BinaryIO,\n    ) -> str:\n        if filename is not None:\n            sanitized_filename = secure_filename(filename)\n        else:\n            sanitized_filename = secure_filename(\"unknown.file\")\n\n        # We store file submissions in a .gz file for two reasons:\n        #\n        # 1. Downloading large files over Tor is very slow. If we can\n        # compress the file, we can speed up future downloads.\n        #\n        # 2. We want to record the original filename because it might be\n        # useful, either for context about the content of the submission\n        # or for figuring out which application should be used to open\n        # it. However, we'd like to encrypt that info and have the\n        # decrypted file automatically have the name of the original\n        # file. Given various usability constraints in GPG and Tails, this\n        # is the most user-friendly way we have found to do this.\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-doc.gz.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n        with SecureTemporaryFile(\"/tmp\") as stf:  # noqa: S108\n            with gzip.GzipFile(filename=sanitized_filename, mode=\"wb\", fileobj=stf, mtime=0) as gzf:\n                # Buffer the stream into the gzip file to avoid excessive\n                # memory consumption\n                while True:\n                    buf = stream.read(1024 * 8)\n                    if not buf:\n                        break\n                    gzf.write(buf)\n\n            EncryptionManager.get_default().encrypt_source_file(\n                file_in=stf,\n                encrypted_file_path_out=Path(encrypted_file_path),\n            )\n\n        return encrypted_file_name\n\n    def save_pre_encrypted_reply(\n        self, filesystem_id: str, count: int, journalist_filename: str, content: str\n    ) -> str:\n        if \"-----BEGIN PGP MESSAGE-----\" not in content.split(\"\\n\")[0]:\n            raise NotEncrypted\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-reply.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n\n        with open(encrypted_file_path, \"w\") as fh:\n            fh.write(content)\n\n        return encrypted_file_path\n\n    def save_message_submission(\n        self, filesystem_id: str, count: int, journalist_filename: str, message: str\n    ) -> str:\n        filename = f\"{count}-{journalist_filename}-msg.gpg\"\n        msg_loc = self.path(filesystem_id, filename)\n        EncryptionManager.get_default().encrypt_source_message(\n            message_in=message,\n            encrypted_message_path_out=Path(msg_loc),\n        )\n        return filename",
        "callGraphToTestedFunction": [
          "clear_shredder"
        ]
      }
    },
    {
      "functionName": "key",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/_parsers.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/_parsers.py",
          "functionName": "key",
          "lines": [
            {
              "startLine": 1206,
              "endLine": 1211
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/_parsers.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "key",
          "filePath": "pretty_bad_protocol/_parsers.py",
          "uncoveredLines": [
            {
              "startLine": 1206,
              "endLine": 1211
            }
          ]
        },
        "uncoveredFnBody": "class ListKeys(list):\n    \"\"\"Handle status messages for --list-keys.\n\n    Handles pub and uid (relating the latter to the former).  Don't care about\n    the following attributes/status messages (from doc/DETAILS):\n\n    |  crt = X.509 certificate\n    |  crs = X.509 certificate and private key available\n    |  ssb = secret subkey (secondary key)\n    |  uat = user attribute (same as user id except for field 10).\n    |  pkd = public key data (special field format, see below)\n    |  grp = reserved for gpgsm\n    |  rvk = revocation key\n    \"\"\"\n\n    def __init__(self, gpg):  # type: ignore[no-untyped-def]\n        super().__init__()\n        self._gpg = gpg\n        self.curkey = None\n        self.curuid = None\n        self.fingerprints = []\n        self.uids = []\n        self.sigs = {}\n        self.certs = {}\n        self.revs = {}\n\n    def key(self, args):  # type: ignore[no-untyped-def]\n        vars = (\n            \"\"\"\n            type trust length algo keyid date expires dummy ownertrust uid\n        \"\"\"\n        ).split()\n        self.curkey = {}\n        for i in range(len(vars)):\n            self.curkey[vars[i]] = args[i]\n        self.curkey[\"uids\"] = []\n        self.curkey[\"sigs\"] = {}\n        self.curkey[\"rev\"] = {}\n        if self.curkey[\"uid\"]:\n            self.curuid = self.curkey[\"uid\"] # Untested\n            self.curkey[\"uids\"].append(self.curuid) # Untested\n            self.sigs[self.curuid] = set() # Untested\n            self.certs[self.curuid] = set() # Untested\n            self.revs[self.curuid] = set() # Untested\n            self.curkey[\"sigs\"][self.curuid] = [] # Untested\n        del self.curkey[\"uid\"]\n        self.curkey[\"subkeys\"] = []\n        self.append(self.curkey)\n\n    pub = sec = key\n\n    def fpr(self, args):  # type: ignore[no-untyped-def]\n        self.curkey[\"fingerprint\"] = args[9]\n        self.fingerprints.append(args[9])\n\n    def uid(self, args):  # type: ignore[no-untyped-def]\n        uid = args[9]\n        uid = ESCAPE_PATTERN.sub(lambda m: chr(int(m.group(1), 16)), uid)\n        self.curkey[\"uids\"].append(uid)\n        self.curuid = uid\n        self.curkey[\"sigs\"][uid] = []\n        self.sigs[uid] = set()\n        self.certs[uid] = set()\n        self.uids.append(uid)\n\n    def sig(self, args):  # type: ignore[no-untyped-def]\n        vars = (\n            \"\"\"\n            type trust length algo keyid date expires dummy ownertrust uid\n        \"\"\"\n        ).split()\n        sig = {}\n        for i in range(len(vars)):\n            sig[vars[i]] = args[i]\n        self.curkey[\"sigs\"][self.curuid].append(sig)\n        self.sigs[self.curuid].add(sig[\"keyid\"])\n        if sig[\"trust\"] == \"!\":\n            self.certs[self.curuid].add(sig[\"keyid\"])\n\n    def sub(self, args):  # type: ignore[no-untyped-def]\n        subkey = [args[4], args[11]]\n        self.curkey[\"subkeys\"].append(subkey)\n\n    def rev(self, args):  # type: ignore[no-untyped-def]\n        self.curkey[\"rev\"] = {\"keyid\": args[4], \"revtime\": args[5], \"uid\": self.curuid}\n\n    def _handle_status(self, key, value):  # type: ignore[no-untyped-def]\n        pass",
        "callGraphToTestedFunction": [
          "key"
        ]
      }
    },
    {
      "functionName": "make_blueprint",
      "replayTestFileNames": [],
      "file": "journalist_app/admin.py",
      "callGraph": [
        {
          "file": "journalist_app/admin.py",
          "functionName": "make_blueprint",
          "lines": [
            {
              "startLine": 46,
              "endLine": 46
            },
            {
              "startLine": 48,
              "endLine": 52
            },
            {
              "startLine": 54,
              "endLine": 58
            },
            {
              "startLine": 60,
              "endLine": 60
            },
            {
              "startLine": 63,
              "endLine": 63
            },
            {
              "startLine": 69,
              "endLine": 69
            },
            {
              "startLine": 72,
              "endLine": 74
            },
            {
              "startLine": 76,
              "endLine": 83
            },
            {
              "startLine": 89,
              "endLine": 89
            },
            {
              "startLine": 91,
              "endLine": 94
            },
            {
              "startLine": 102,
              "endLine": 106
            },
            {
              "startLine": 108,
              "endLine": 108
            },
            {
              "startLine": 110,
              "endLine": 111
            },
            {
              "startLine": 113,
              "endLine": 113
            },
            {
              "startLine": 115,
              "endLine": 115
            },
            {
              "startLine": 117,
              "endLine": 119
            },
            {
              "startLine": 121,
              "endLine": 123
            },
            {
              "startLine": 127,
              "endLine": 127
            },
            {
              "startLine": 129,
              "endLine": 140
            },
            {
              "startLine": 142,
              "endLine": 145
            },
            {
              "startLine": 147,
              "endLine": 157
            },
            {
              "startLine": 159,
              "endLine": 164
            },
            {
              "startLine": 172,
              "endLine": 175
            },
            {
              "startLine": 182,
              "endLine": 185
            },
            {
              "startLine": 193,
              "endLine": 193
            },
            {
              "startLine": 197,
              "endLine": 199
            },
            {
              "startLine": 201,
              "endLine": 206
            },
            {
              "startLine": 211,
              "endLine": 211
            },
            {
              "startLine": 219,
              "endLine": 219
            },
            {
              "startLine": 221,
              "endLine": 223
            },
            {
              "startLine": 232,
              "endLine": 232
            },
            {
              "startLine": 236,
              "endLine": 236
            },
            {
              "startLine": 240,
              "endLine": 241
            },
            {
              "startLine": 243,
              "endLine": 245
            },
            {
              "startLine": 253,
              "endLine": 253
            },
            {
              "startLine": 257,
              "endLine": 260
            },
            {
              "startLine": 263,
              "endLine": 264
            },
            {
              "startLine": 270,
              "endLine": 270
            },
            {
              "startLine": 272,
              "endLine": 273
            },
            {
              "startLine": 278,
              "endLine": 278
            },
            {
              "startLine": 286,
              "endLine": 294
            },
            {
              "startLine": 302,
              "endLine": 304
            },
            {
              "startLine": 311,
              "endLine": 312
            },
            {
              "startLine": 314,
              "endLine": 314
            },
            {
              "startLine": 316,
              "endLine": 319
            },
            {
              "startLine": 325,
              "endLine": 325
            },
            {
              "startLine": 327,
              "endLine": 328
            },
            {
              "startLine": 332,
              "endLine": 332
            },
            {
              "startLine": 334,
              "endLine": 335
            },
            {
              "startLine": 340,
              "endLine": 340
            },
            {
              "startLine": 342,
              "endLine": 352
            },
            {
              "startLine": 354,
              "endLine": 354
            },
            {
              "startLine": 356,
              "endLine": 359
            },
            {
              "startLine": 361,
              "endLine": 363
            },
            {
              "startLine": 365,
              "endLine": 368
            },
            {
              "startLine": 372,
              "endLine": 372
            },
            {
              "startLine": 374,
              "endLine": 377
            },
            {
              "startLine": 383,
              "endLine": 383
            },
            {
              "startLine": 385,
              "endLine": 385
            },
            {
              "startLine": 387,
              "endLine": 391
            },
            {
              "startLine": 393,
              "endLine": 394
            },
            {
              "startLine": 396,
              "endLine": 402
            },
            {
              "startLine": 404,
              "endLine": 404
            },
            {
              "startLine": 406,
              "endLine": 406
            },
            {
              "startLine": 408,
              "endLine": 408
            },
            {
              "startLine": 412,
              "endLine": 413
            },
            {
              "startLine": 415,
              "endLine": 419
            },
            {
              "startLine": 422,
              "endLine": 425
            },
            {
              "startLine": 429,
              "endLine": 430
            },
            {
              "startLine": 433,
              "endLine": 433
            },
            {
              "startLine": 436,
              "endLine": 436
            },
            {
              "startLine": 438,
              "endLine": 441
            },
            {
              "startLine": 446,
              "endLine": 446
            },
            {
              "startLine": 448,
              "endLine": 454
            },
            {
              "startLine": 456,
              "endLine": 457
            },
            {
              "startLine": 461,
              "endLine": 461
            },
            {
              "startLine": 463,
              "endLine": 467
            },
            {
              "startLine": 469,
              "endLine": 473
            },
            {
              "startLine": 477,
              "endLine": 477
            },
            {
              "startLine": 479,
              "endLine": 479
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/admin.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "make_blueprint",
          "filePath": "journalist_app/admin.py",
          "uncoveredLines": [
            {
              "startLine": 46,
              "endLine": 46
            },
            {
              "startLine": 48,
              "endLine": 52
            },
            {
              "startLine": 54,
              "endLine": 58
            },
            {
              "startLine": 60,
              "endLine": 60
            },
            {
              "startLine": 63,
              "endLine": 63
            },
            {
              "startLine": 69,
              "endLine": 69
            },
            {
              "startLine": 72,
              "endLine": 74
            },
            {
              "startLine": 76,
              "endLine": 83
            },
            {
              "startLine": 89,
              "endLine": 89
            },
            {
              "startLine": 91,
              "endLine": 94
            },
            {
              "startLine": 102,
              "endLine": 106
            },
            {
              "startLine": 108,
              "endLine": 108
            },
            {
              "startLine": 110,
              "endLine": 111
            },
            {
              "startLine": 113,
              "endLine": 113
            },
            {
              "startLine": 115,
              "endLine": 115
            },
            {
              "startLine": 117,
              "endLine": 119
            },
            {
              "startLine": 121,
              "endLine": 123
            },
            {
              "startLine": 127,
              "endLine": 127
            },
            {
              "startLine": 129,
              "endLine": 140
            },
            {
              "startLine": 142,
              "endLine": 145
            },
            {
              "startLine": 147,
              "endLine": 157
            },
            {
              "startLine": 159,
              "endLine": 164
            },
            {
              "startLine": 172,
              "endLine": 175
            },
            {
              "startLine": 182,
              "endLine": 185
            },
            {
              "startLine": 193,
              "endLine": 193
            },
            {
              "startLine": 197,
              "endLine": 199
            },
            {
              "startLine": 201,
              "endLine": 206
            },
            {
              "startLine": 211,
              "endLine": 211
            },
            {
              "startLine": 219,
              "endLine": 219
            },
            {
              "startLine": 221,
              "endLine": 223
            },
            {
              "startLine": 232,
              "endLine": 232
            },
            {
              "startLine": 236,
              "endLine": 236
            },
            {
              "startLine": 240,
              "endLine": 241
            },
            {
              "startLine": 243,
              "endLine": 245
            },
            {
              "startLine": 253,
              "endLine": 253
            },
            {
              "startLine": 257,
              "endLine": 260
            },
            {
              "startLine": 263,
              "endLine": 264
            },
            {
              "startLine": 270,
              "endLine": 270
            },
            {
              "startLine": 272,
              "endLine": 273
            },
            {
              "startLine": 278,
              "endLine": 278
            },
            {
              "startLine": 286,
              "endLine": 294
            },
            {
              "startLine": 302,
              "endLine": 304
            },
            {
              "startLine": 311,
              "endLine": 312
            },
            {
              "startLine": 314,
              "endLine": 314
            },
            {
              "startLine": 316,
              "endLine": 319
            },
            {
              "startLine": 325,
              "endLine": 325
            },
            {
              "startLine": 327,
              "endLine": 328
            },
            {
              "startLine": 332,
              "endLine": 332
            },
            {
              "startLine": 334,
              "endLine": 335
            },
            {
              "startLine": 340,
              "endLine": 340
            },
            {
              "startLine": 342,
              "endLine": 352
            },
            {
              "startLine": 354,
              "endLine": 354
            },
            {
              "startLine": 356,
              "endLine": 359
            },
            {
              "startLine": 361,
              "endLine": 363
            },
            {
              "startLine": 365,
              "endLine": 368
            },
            {
              "startLine": 372,
              "endLine": 372
            },
            {
              "startLine": 374,
              "endLine": 377
            },
            {
              "startLine": 383,
              "endLine": 383
            },
            {
              "startLine": 385,
              "endLine": 385
            },
            {
              "startLine": 387,
              "endLine": 391
            },
            {
              "startLine": 393,
              "endLine": 394
            },
            {
              "startLine": 396,
              "endLine": 402
            },
            {
              "startLine": 404,
              "endLine": 404
            },
            {
              "startLine": 406,
              "endLine": 406
            },
            {
              "startLine": 408,
              "endLine": 408
            },
            {
              "startLine": 412,
              "endLine": 413
            },
            {
              "startLine": 415,
              "endLine": 419
            },
            {
              "startLine": 422,
              "endLine": 425
            },
            {
              "startLine": 429,
              "endLine": 430
            },
            {
              "startLine": 433,
              "endLine": 433
            },
            {
              "startLine": 436,
              "endLine": 436
            },
            {
              "startLine": 438,
              "endLine": 441
            },
            {
              "startLine": 446,
              "endLine": 446
            },
            {
              "startLine": 448,
              "endLine": 454
            },
            {
              "startLine": 456,
              "endLine": 457
            },
            {
              "startLine": 461,
              "endLine": 461
            },
            {
              "startLine": 463,
              "endLine": 467
            },
            {
              "startLine": 469,
              "endLine": 473
            },
            {
              "startLine": 477,
              "endLine": 477
            },
            {
              "startLine": 479,
              "endLine": 479
            }
          ]
        },
        "uncoveredFnBody": "def make_blueprint() -> Blueprint:\n    view = Blueprint(\"admin\", __name__)\n\n    @view.route(\"/\", methods=(\"GET\", \"POST\"))\n    @admin_required\n    def index() -> str:\n        users = Journalist.query.filter(Journalist.username != \"deleted\").all()\n        return render_template(\"admin.html\", users=users)\n\n    @view.route(\"/config\", methods=(\"GET\", \"POST\"))\n    @admin_required\n    def manage_config() -> Union[str, werkzeug.Response]:\n        if InstanceConfig.get_default().initial_message_min_len > 0:\n            prevent_short_messages = True\n        else:\n            prevent_short_messages = False\n\n        # The UI document upload prompt (\"prevent\") is the opposite of the setting (\"allow\")\n        submission_preferences_form = SubmissionPreferencesForm(\n            prevent_document_uploads=not InstanceConfig.get_default().allow_document_uploads,\n            prevent_short_messages=prevent_short_messages,\n            min_message_length=InstanceConfig.get_default().initial_message_min_len,\n            reject_codename_messages=InstanceConfig.get_default().reject_message_with_codename,\n        )\n        organization_name_form = OrgNameForm(\n            organization_name=InstanceConfig.get_default().organization_name\n        )\n        logo_form = LogoForm()\n        if logo_form.validate_on_submit():\n            f = logo_form.logo.data\n\n            if current_app.static_folder is None:\n                abort(500)\n            custom_logo_filepath = os.path.join(current_app.static_folder, \"i\", \"custom_logo.png\")\n            try:\n                f.save(custom_logo_filepath)\n                flash(gettext(\"Image updated.\"), \"logo-success\")\n            except Exception:\n                flash(\n                    # Translators: This error is shown when an uploaded image cannot be used.\n                    gettext(\"Unable to process the image file. Please try another one.\"),\n                    \"logo-error\",\n                )\n            finally:\n                return redirect(url_for(\"admin.manage_config\") + \"#config-logoimage\")\n        else:\n            for field, errors in list(logo_form.errors.items()):\n                for error in errors:\n                    flash(error, \"logo-error\")\n            return render_template(\n                \"config.html\",\n                submission_preferences_form=submission_preferences_form,\n                organization_name_form=organization_name_form,\n                max_len=Submission.MAX_MESSAGE_LEN,\n                logo_form=logo_form,\n            )\n\n    @view.route(\"/update-submission-preferences\", methods=[\"POST\"])\n    @admin_required\n    def update_submission_preferences() -> Optional[werkzeug.Response]:\n        form = SubmissionPreferencesForm()\n        if form.validate_on_submit():\n            # The UI prompt (\"prevent\") is the opposite of the setting (\"allow\"):\n            allow_uploads = not form.prevent_document_uploads.data\n\n            if form.prevent_short_messages.data:\n                msg_length = form.min_message_length.data\n            else:\n                msg_length = 0\n\n            reject_codenames = form.reject_codename_messages.data\n\n            InstanceConfig.update_submission_prefs(allow_uploads, msg_length, reject_codenames)\n            flash(gettext(\"Preferences saved.\"), \"submission-preferences-success\")\n            return redirect(url_for(\"admin.manage_config\") + \"#config-preventuploads\")\n        else:\n            for field, errors in list(form.errors.items()):\n                for error in errors:\n                    flash(\n                        gettext(\"Preferences not updated.\") + \" \" + error,\n                        \"submission-preferences-error\",\n                    )\n        return redirect(url_for(\"admin.manage_config\") + \"#config-preventuploads\")\n\n    @view.route(\"/update-org-name\", methods=[\"POST\"]) # Untested\n    @admin_required # Untested\n    def update_org_name() -> Union[str, werkzeug.Response]: # Untested\n        form = OrgNameForm() # Untested\n        if form.validate_on_submit(): # Untested\n            try: # Untested\n                value = request.form[\"organization_name\"] # Untested\n                InstanceConfig.set_organization_name(value) # Untested\n                flash(gettext(\"Preferences saved.\"), \"org-name-success\") # Untested\n            except Exception: # Untested\n                flash(gettext(\"Failed to update organization name.\"), \"org-name-error\") # Untested\n            return redirect(url_for(\"admin.manage_config\") + \"#config-orgname\") # Untested\n        else:\n            for field, errors in list(form.errors.items()):\n                for error in errors:\n                    flash(error, \"org-name-error\")\n        return redirect(url_for(\"admin.manage_config\") + \"#config-orgname\")\n\n    @view.route(\"/add\", methods=(\"GET\", \"POST\"))\n    @admin_required\n    def add_user() -> Union[str, werkzeug.Response]:\n        form = NewUserForm()\n        if form.validate_on_submit():\n            form_valid = True\n            username = request.form[\"username\"]\n            first_name = request.form[\"first_name\"]\n            last_name = request.form[\"last_name\"]\n            password = request.form[\"password\"]\n            is_admin = bool(request.form.get(\"is_admin\"))\n\n            try:\n                otp_secret = None\n                if request.form.get(\"is_hotp\", False):\n                    otp_secret = request.form.get(\"otp_secret\", \"\")\n                verify_pending_password(for_=\"new\", passphrase=password)\n                new_user = Journalist(\n                    username=username,\n                    password=password,\n                    first_name=first_name,\n                    last_name=last_name,\n                    is_admin=is_admin,\n                    otp_secret=otp_secret,\n                )\n                db.session.add(new_user)\n                db.session.commit()\n            except PasswordError:\n                flash(\n                    gettext(\n                        \"There was an error with the autogenerated password. \"\n                        \"User not created. Please try again.\"\n                    ),\n                    \"error\",\n                )\n                form_valid = False\n            except (binascii.Error, TypeError) as e:\n                if \"Non-hexadecimal digit found\" in str(e):\n                    flash(\n                        gettext(\n                            \"Invalid HOTP secret format: \"\n                            \"please only submit letters A-F and numbers 0-9.\"\n                        ),\n                        \"error\",\n                    )\n                else:\n                    flash(\n                        gettext(\"An unexpected error occurred! \" \"Please inform your admin.\"),\n                        \"error\",\n                    )\n                form_valid = False\n            except InvalidUsernameException as e:\n                form_valid = False\n                # Translators: Here, \"{message}\" explains the problem with the username.\n                flash(gettext(\"Invalid username: {message}\").format(message=e), \"error\")\n            except IntegrityError as e:\n                db.session.rollback()\n                form_valid = False\n                if \"UNIQUE constraint failed: journalists.username\" in str(e):\n                    flash(\n                        gettext('Username \"{username}\" already taken.').format(username=username),\n                        \"error\",\n                    )\n                else:\n                    flash(\n                        gettext(\n                            \"An error occurred saving this user\"\n                            \" to the database.\"\n                            \" Please inform your admin.\"\n                        ),\n                        \"error\",\n                    )\n                    current_app.logger.error(\"Adding user \" f\"'{username}' failed: {e}\")\n\n            if form_valid:\n                if new_user.is_totp:\n                    return render_template(\n                        \"admin_new_user_two_factor_totp.html\",\n                        qrcode=Markup(new_user.totp.qrcode_svg(new_user.username).decode()),\n                        otp_secret=new_user.otp_secret,\n                        formatted_otp_secret=new_user.formatted_otp_secret,\n                        userid=str(new_user.id),\n                    )\n\n                else:\n                    return render_template(\n                        \"admin_new_user_two_factor_hotp.html\",\n                        user=new_user,\n                    )\n        password = PassphraseGenerator.get_default().generate_passphrase(\n            preferred_language=g.localeinfo.language\n        )\n        # Store password in session for future verification\n        set_pending_password(\"new\", password)\n        return render_template(\"admin_add_user.html\", password=password, form=form)\n\n    @view.route(\"/verify-2fa-totp\", methods=(\"POST\",))\n    @admin_required\n    def new_user_two_factor_totp() -> Union[str, werkzeug.Response]:\n        \"\"\"\n        After (re)setting a user's 2FA TOTP, allow the admin to verify the newly generated code.\n\n        We don't want admins to be able to look up arbitrary users' TOTP secrets, so it must\n        be supplied in the form body, generated by another endpoint. The provided token is\n        then verified against the supplied secret.\n        \"\"\"\n        token = request.form[\"token\"]\n        # NOTE: This ID comes from the user and should be only used to look up the username\n        # for embedding in the QR code and success messages. We don't load any other state\n        # from the database to prevent IDOR attacks.\n        username = Journalist.query.get(request.form[\"userid\"]).username\n        otp_secret = request.form[\"otp_secret\"]\n        totp = two_factor.TOTP(otp_secret)\n        try:\n            # Note: this intentionally doesn't prevent replay attacks, since we just want\n            # to make sure they have the right token\n            totp.verify(token, datetime.utcnow())\n            flash(\n                gettext(\n                    'The two-factor code for user \"{user}\" was verified ' \"successfully.\"\n                ).format(user=username),\n                \"notification\",\n            )\n            return redirect(url_for(\"admin.index\"))\n\n        except two_factor.OtpTokenInvalid:\n            flash(\n                gettext(\"There was a problem verifying the two-factor code. Please try again.\"),\n                \"error\",\n            )\n\n        return render_template(\n            \"admin_new_user_two_factor_totp.html\",\n            qrcode=Markup(totp.qrcode_svg(username).decode()),\n            otp_secret=otp_secret,\n            formatted_otp_secret=two_factor.format_secret(otp_secret),\n            userid=request.form[\"userid\"],\n        )\n\n    @view.route(\"/reset-2fa-totp\", methods=[\"POST\"])\n    @admin_required\n    def reset_two_factor_totp() -> str:\n        uid = request.form[\"uid\"]\n        user = Journalist.query.get(uid)\n        user.is_totp = True\n        user.regenerate_totp_shared_secret()\n        db.session.commit()\n        return render_template(\n            \"admin_new_user_two_factor_totp.html\",\n            qrcode=Markup(user.totp.qrcode_svg(user.username).decode()),\n            otp_secret=user.otp_secret,\n            formatted_otp_secret=user.formatted_otp_secret,\n            userid=str(user.id),\n        )\n\n    @view.route(\"/verify-2fa-hotp\", methods=(\"POST\",))\n    @admin_required\n    def new_user_two_factor_hotp() -> Union[str, werkzeug.Response]:\n        \"\"\"\n        After (re)setting a user's 2FA HOTP, allow the admin to verify the newly generated code.\n\n        This works differently than the analogous TOTP endpoint, as here we do verify against\n        the database secret because we need to compare with and increment the counter.\n        \"\"\"\n        user = Journalist.query.get(request.form[\"uid\"])\n        token = request.form[\"token\"]\n\n        error = False\n\n        if not user.is_totp:\n            try:\n                user.verify_2fa_token(token)\n                flash(\n                    gettext(\n                        'The two-factor code for user \"{user}\" was verified ' \"successfully.\"\n                    ).format(user=user.username),\n                    \"notification\",\n                )\n                return redirect(url_for(\"admin.index\"))\n\n            except two_factor.OtpTokenInvalid:\n                error = True\n        else:\n            # XXX: Consider using a different error message here, or do we not want to reveal\n            # if the user is using HOTP vs TOTP\n            error = True\n\n        if error:\n            flash(\n                gettext(\"There was a problem verifying the two-factor code. Please try again.\"),\n                \"error\",\n            )\n\n        return render_template(\"admin_new_user_two_factor_hotp.html\", user=user)\n\n    @view.route(\"/reset-2fa-hotp\", methods=[\"POST\"])\n    @admin_required\n    def reset_two_factor_hotp() -> Union[str, werkzeug.Response]:\n        uid = request.form[\"uid\"]\n        user = Journalist.query.get(uid)\n        otp_secret = request.form.get(\"otp_secret\", None)\n        if otp_secret:\n            if not validate_hotp_secret(user, otp_secret):\n                return render_template(\"admin_edit_hotp_secret.html\", uid=user.id)\n            db.session.commit()\n            return render_template(\"admin_new_user_two_factor_hotp.html\", user=user)\n        else:\n            return render_template(\"admin_edit_hotp_secret.html\", uid=user.id)\n\n    @view.route(\"/edit/<int:user_id>\", methods=(\"GET\", \"POST\"))\n    @admin_required\n    def edit_user(user_id: int) -> Union[str, werkzeug.Response]:\n        user = Journalist.query.get(user_id)\n\n        if request.method == \"POST\":\n            if request.form.get(\"username\", None):\n                new_username = request.form[\"username\"]\n\n                try:\n                    Journalist.check_username_acceptable(new_username)\n                except InvalidUsernameException as e:\n                    flash(\n                        gettext(\"Invalid username: {message}\").format(message=e),\n                        \"error\",\n                    )\n                    return redirect(url_for(\"admin.edit_user\", user_id=user_id))\n\n                if new_username == user.username:\n                    pass\n                elif Journalist.query.filter_by(username=new_username).one_or_none():\n                    flash(\n                        gettext('Username \"{username}\" already taken.').format(\n                            username=new_username\n                        ),\n                        \"error\",\n                    )\n                    return redirect(url_for(\"admin.edit_user\", user_id=user_id))\n                else:\n                    user.username = new_username\n\n            try:\n                first_name = request.form[\"first_name\"]\n                Journalist.check_name_acceptable(first_name)\n                user.first_name = first_name\n            except FirstOrLastNameError as e:\n                # Translators: Here, \"{message}\" explains the problem with the name.\n                flash(gettext(\"Name not updated: {message}\").format(message=e), \"error\")\n                return redirect(url_for(\"admin.edit_user\", user_id=user_id))\n\n            try:\n                last_name = request.form[\"last_name\"]\n                Journalist.check_name_acceptable(last_name)\n                user.last_name = last_name\n            except FirstOrLastNameError as e:\n                flash(gettext(\"Name not updated: {message}\").format(message=e), \"error\")\n                return redirect(url_for(\"admin.edit_user\", user_id=user_id))\n\n            user.is_admin = bool(request.form.get(\"is_admin\"))\n\n            commit_account_changes(user)\n\n        password = PassphraseGenerator.get_default().generate_passphrase(\n            preferred_language=g.localeinfo.language\n        )\n        # Store password in session for future verification\n        set_pending_password(user, password)\n        return render_template(\"edit_account.html\", user=user, password=password)\n\n    @view.route(\"/delete/<int:user_id>\", methods=(\"POST\",))\n    @admin_required\n    def delete_user(user_id: int) -> werkzeug.Response:\n        user = Journalist.query.get(user_id)\n        if user_id == session.get_uid():\n            # Do not flash because the interface already has safe guards.\n            # It can only happen by manually crafting a POST request\n            current_app.logger.error(f\"Admin {session.get_user().username} tried to delete itself\")\n            abort(403)\n        elif not user:\n            current_app.logger.error(\n                f\"Admin {session.get_user().username} tried to delete nonexistent user with \"\n                f\"pk={user_id}\"\n            )\n            abort(404)\n        elif user.is_deleted_user():\n            # Do not flash because the interface does not expose this.\n            # It can only happen by manually crafting a POST request\n            current_app.logger.error(\n                f'Admin {session.get_user().username} tried to delete \"deleted\" user'\n            )\n            abort(403)\n        else:\n            user.delete()\n            current_app.session_interface.logout_user(user.id)  # type: ignore\n            db.session.commit()\n            flash(\n                gettext(\"Deleted user '{user}'.\").format(user=user.username),\n                \"notification\",\n            )\n\n        return redirect(url_for(\"admin.index\"))\n\n    @view.route(\"/edit/<int:user_id>/new-password\", methods=(\"POST\",))\n    @admin_required\n    def new_password(user_id: int) -> werkzeug.Response:\n        try:\n            user = Journalist.query.get(user_id)\n        except NoResultFound:\n            abort(404)\n\n        if user.id == session.get_uid():\n            current_app.logger.error(\n                f\"Admin {session.get_user().username} tried to change their password without \"\n                \"validation.\"\n            )\n            abort(403)\n\n        password = request.form.get(\"password\")\n        if set_diceware_password(user, password, admin=True) is not False:\n            current_app.session_interface.logout_user(user.id)  # type: ignore\n            db.session.commit()\n        return redirect(url_for(\"admin.edit_user\", user_id=user_id))\n\n    @view.route(\"/ossec-test\", methods=(\"POST\",))\n    @admin_required\n    def ossec_test() -> werkzeug.Response:\n        current_app.logger.error(\"This is a test OSSEC alert\")\n        flash(\n            gettext(\"Test alert sent. Please check your email.\"),\n            \"testalert-notification\",\n        )\n        return redirect(url_for(\"admin.manage_config\") + \"#config-testalert\")\n\n    return view",
        "callGraphToTestedFunction": [
          "make_blueprint"
        ]
      }
    },
    {
      "functionName": "filesizeformat",
      "replayTestFileNames": [],
      "file": "template_filters.py",
      "callGraph": [
        {
          "file": "template_filters.py",
          "functionName": "filesizeformat",
          "lines": [
            {
              "startLine": 29,
              "endLine": 29
            },
            {
              "startLine": 35,
              "endLine": 36
            },
            {
              "startLine": 42,
              "endLine": 43
            },
            {
              "startLine": 45,
              "endLine": 48
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "template_filters.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "filesizeformat",
          "filePath": "template_filters.py",
          "uncoveredLines": [
            {
              "startLine": 29,
              "endLine": 29
            },
            {
              "startLine": 35,
              "endLine": 36
            },
            {
              "startLine": 42,
              "endLine": 43
            },
            {
              "startLine": 45,
              "endLine": 48
            }
          ]
        },
        "uncoveredFnBody": "def filesizeformat(value: int) -> str:\n    prefixes = [\n        \"digital-kilobyte\",\n        \"digital-megabyte\",\n        \"digital-gigabyte\",\n        \"digital-terabyte\",\n    ]\n    locale = get_locale()\n    base = 1024\n    #\n    # we are using the long length because the short length has no\n    # plural variant and it reads like a bug instead of something\n    # on purpose\n    #\n    if value < base:\n        return units.format_unit(value, \"byte\", locale=locale, length=\"long\")\n    else:\n        i = min(int(math.log(value, base)), len(prefixes)) - 1 # Untested\n        prefix = prefixes[i] # Untested\n        bytes = float(value) / base ** (i + 1) # Untested\n        return units.format_unit(bytes, prefix, locale=locale, length=\"short\") # Untested",
        "callGraphToTestedFunction": [
          "filesizeformat"
        ]
      }
    },
    {
      "functionName": "add_reply",
      "replayTestFileNames": [],
      "file": "loaddata.py",
      "callGraph": [
        {
          "file": "loaddata.py",
          "functionName": "add_reply",
          "lines": [
            {
              "startLine": 229,
              "endLine": 229
            },
            {
              "startLine": 235,
              "endLine": 237
            },
            {
              "startLine": 242,
              "endLine": 243
            },
            {
              "startLine": 246,
              "endLine": 247
            },
            {
              "startLine": 249,
              "endLine": 251
            },
            {
              "startLine": 253,
              "endLine": 253
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "loaddata.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "add_reply",
          "filePath": "loaddata.py",
          "uncoveredLines": [
            {
              "startLine": 229,
              "endLine": 229
            },
            {
              "startLine": 235,
              "endLine": 237
            },
            {
              "startLine": 242,
              "endLine": 243
            },
            {
              "startLine": 246,
              "endLine": 247
            },
            {
              "startLine": 249,
              "endLine": 251
            },
            {
              "startLine": 253,
              "endLine": 253
            }
          ]
        },
        "uncoveredFnBody": "def add_reply(\n    source: Source, journalist: Journalist, journalist_who_saw: Optional[Journalist]\n) -> None:\n    \"\"\"\n    Adds a single reply to a source.\n    \"\"\"\n    record_source_interaction(source)\n    fname = f\"{source.interaction_count}-{source.journalist_filename}-reply.gpg\"\n    EncryptionManager.get_default().encrypt_journalist_reply(\n        for_source=source,\n        reply_in=next(replies),\n        encrypted_reply_path_out=Path(Storage.get_default().path(source.filesystem_id, fname)),\n    )\n    reply = Reply(journalist, source, fname, Storage.get_default())\n    db.session.add(reply)\n\n    # Journalist who replied has seen the reply\n    author_seen_reply = SeenReply(reply=reply, journalist=journalist)\n    db.session.add(author_seen_reply)\n\n    if journalist_who_saw: # Untested\n        other_seen_reply = SeenReply(reply=reply, journalist=journalist_who_saw) # Untested\n        db.session.add(other_seen_reply) # Untested\n\n    db.session.commit()",
        "callGraphToTestedFunction": [
          "add_reply"
        ]
      }
    },
    {
      "functionName": "validate_user",
      "replayTestFileNames": [],
      "file": "journalist_app/utils.py",
      "callGraph": [
        {
          "file": "journalist_app/utils.py",
          "functionName": "validate_user",
          "lines": [
            {
              "startLine": 81,
              "endLine": 83
            },
            {
              "startLine": 91,
              "endLine": 92
            },
            {
              "startLine": 94,
              "endLine": 96
            },
            {
              "startLine": 99,
              "endLine": 99
            },
            {
              "startLine": 104,
              "endLine": 106
            },
            {
              "startLine": 110,
              "endLine": 114
            },
            {
              "startLine": 118,
              "endLine": 119
            },
            {
              "startLine": 121,
              "endLine": 122
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "validate_user",
          "filePath": "journalist_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 81,
              "endLine": 83
            },
            {
              "startLine": 91,
              "endLine": 92
            },
            {
              "startLine": 94,
              "endLine": 96
            },
            {
              "startLine": 99,
              "endLine": 99
            },
            {
              "startLine": 104,
              "endLine": 106
            },
            {
              "startLine": 110,
              "endLine": 114
            },
            {
              "startLine": 118,
              "endLine": 119
            },
            {
              "startLine": 121,
              "endLine": 122
            }
          ]
        },
        "uncoveredFnBody": "def validate_user(\n    username: str,\n    password: Optional[str],\n    token: Optional[str],\n    error_message: Optional[str] = None,\n) -> Optional[Journalist]:\n    \"\"\"\n    Validates the user by calling the login and handling exceptions\n    :param username: Username\n    :param password: Password\n    :param token: Two-factor authentication token\n    :param error_message: Localized error message string to use on failure\n    :return: Journalist user object if successful, None otherwise.\n    \"\"\"\n    try:\n        return Journalist.login(username, password, token)\n    except (\n        InvalidUsernameException,\n        OtpSecretInvalid,\n        OtpTokenInvalid,\n        WrongPasswordException,\n        LoginThrottledException,\n        InvalidPasswordLength,\n    ) as e:\n        current_app.logger.error(f\"Login for '{username}' failed: {e}\")\n        login_flashed_msg = error_message if error_message else gettext(\"Login failed.\")\n\n        if isinstance(e, LoginThrottledException):\n            login_flashed_msg += \" \"\n            period = Journalist._LOGIN_ATTEMPT_PERIOD\n            # ngettext is needed although we always have period > 1\n            # see https://github.com/freedomofpress/securedrop/issues/2422\n            login_flashed_msg += ngettext(\n                \"Please wait at least {num} second before logging in again.\",\n                \"Please wait at least {num} seconds before logging in again.\",\n                period,\n            ).format(num=period)\n        elif isinstance(e, OtpSecretInvalid):\n            login_flashed_msg += \" \"\n            login_flashed_msg += gettext(\n                \"Your 2FA details are invalid\" \" - please contact an administrator to reset them.\"\n            )\n        else:\n            try: # Untested\n                user = Journalist.query.filter_by(username=username).one() # Untested\n                if user.is_totp: # Untested\n                    login_flashed_msg += \" \" # Untested\n                    login_flashed_msg += gettext( # Untested\n                        \"Please wait for a new code from your two-factor mobile\"\n                        \" app or security key before trying again.\"\n                    )\n            except Exception:\n                pass\n\n        flash(login_flashed_msg, \"error\")\n        return None",
        "callGraphToTestedFunction": [
          "validate_user"
        ]
      }
    },
    {
      "functionName": "to_json",
      "replayTestFileNames": [],
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "to_json",
          "lines": [
            {
              "startLine": 132,
              "endLine": 132
            },
            {
              "startLine": 134,
              "endLine": 135
            },
            {
              "startLine": 137,
              "endLine": 137
            },
            {
              "startLine": 139,
              "endLine": 140
            },
            {
              "startLine": 142,
              "endLine": 142
            },
            {
              "startLine": 144,
              "endLine": 144
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "to_json",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 132,
              "endLine": 132
            },
            {
              "startLine": 134,
              "endLine": 135
            },
            {
              "startLine": 137,
              "endLine": 137
            },
            {
              "startLine": 139,
              "endLine": 140
            },
            {
              "startLine": 142,
              "endLine": 142
            },
            {
              "startLine": 144,
              "endLine": 144
            }
          ]
        },
        "uncoveredFnBody": "class Source(db.Model):\n    __tablename__ = \"sources\"\n    id = Column(Integer, primary_key=True)\n    uuid = Column(String(36), unique=True, nullable=False)\n    filesystem_id = Column(String(96), unique=True, nullable=False)\n    journalist_designation = Column(String(255), nullable=False)\n    last_updated = Column(DateTime)\n    star = relationship(\"SourceStar\", uselist=False, backref=\"source\")\n\n    # sources are \"pending\" and don't get displayed to journalists until they\n    # submit something\n    pending = Column(Boolean, default=True)\n\n    # keep track of how many interactions have happened, for filenames\n    interaction_count = Column(Integer, default=0, nullable=False)\n\n    # when deletion of the source was requested\n    deleted_at = Column(DateTime)\n\n    # PGP key material\n    pgp_public_key = Column(Text, nullable=True)\n    pgp_secret_key = Column(Text, nullable=True)\n    pgp_fingerprint = Column(String(40), nullable=True)\n\n    def __init__(\n        self,\n        filesystem_id: str,\n        journalist_designation: str,\n        public_key: str,\n        secret_key: str,\n        fingerprint: str,\n    ) -> None:\n        self.filesystem_id = filesystem_id\n        self.journalist_designation = journalist_designation\n        self.pgp_public_key = public_key\n        self.pgp_secret_key = secret_key\n        self.pgp_fingerprint = fingerprint\n        self.uuid = str(uuid.uuid4())\n\n    def __repr__(self) -> str:\n        return f\"<Source {self.journalist_designation!r}>\"\n\n    @property\n    def journalist_filename(self) -> str:\n        valid_chars = \"abcdefghijklmnopqrstuvwxyz1234567890-_\"\n        return \"\".join(\n            [c for c in self.journalist_designation.lower().replace(\" \", \"_\") if c in valid_chars]\n        )\n\n    def documents_messages_count(self) -> \"Dict[str, int]\":\n        self.docs_msgs_count = {\"messages\": 0, \"documents\": 0}\n        for submission in self.submissions:\n            if submission.is_message:\n                self.docs_msgs_count[\"messages\"] += 1\n            elif submission.is_file:\n                self.docs_msgs_count[\"documents\"] += 1\n        return self.docs_msgs_count\n\n    @property\n    def collection(self) -> \"List[Union[Submission, Reply]]\":\n        \"\"\"Return the list of submissions and replies for this source, sorted\n        in ascending order by the filename/interaction count.\"\"\"\n        collection: List[Union[Submission, Reply]] = []\n        collection.extend(self.submissions)\n        collection.extend(self.replies)\n        collection.sort(key=lambda x: int(x.filename.split(\"-\")[0]))\n        return collection\n\n    @property\n    def fingerprint(self) -> Optional[str]:\n        if self.pgp_fingerprint is not None:\n            return self.pgp_fingerprint\n        try:\n            return EncryptionManager.get_default().get_source_key_fingerprint(self.filesystem_id)\n        except GpgKeyNotFoundError:\n            return None\n\n    @property\n    def public_key(self) -> Optional[str]:\n        if self.pgp_public_key:\n            return self.pgp_public_key\n        try:\n            return EncryptionManager.get_default().get_source_public_key(self.filesystem_id)\n        except GpgKeyNotFoundError:\n            return None\n\n    def to_json(self) -> \"Dict[str, object]\":\n        docs_msg_count = self.documents_messages_count()\n\n        if self.last_updated:\n            last_updated = self.last_updated\n        else:\n            last_updated = datetime.datetime.now(tz=datetime.timezone.utc)\n\n        if self.star and self.star.starred: # Untested\n            starred = True # Untested\n        else:\n            starred = False\n\n        return {\n            \"uuid\": self.uuid,\n            \"url\": url_for(\"api.single_source\", source_uuid=self.uuid),\n            \"journalist_designation\": self.journalist_designation,\n            \"is_flagged\": False,\n            \"is_starred\": starred,\n            \"last_updated\": last_updated,\n            \"interaction_count\": self.interaction_count,\n            \"key\": {\n                \"type\": \"PGP\",\n                \"public\": self.public_key,\n                \"fingerprint\": self.fingerprint,\n            },\n            \"number_of_documents\": docs_msg_count[\"documents\"],\n            \"number_of_messages\": docs_msg_count[\"messages\"],\n            \"submissions_url\": url_for(\"api.all_source_submissions\", source_uuid=self.uuid),\n            \"add_star_url\": url_for(\"api.add_star\", source_uuid=self.uuid),\n            \"remove_star_url\": url_for(\"api.remove_star\", source_uuid=self.uuid),\n            \"replies_url\": url_for(\"api.all_source_replies\", source_uuid=self.uuid),\n        }",
        "callGraphToTestedFunction": [
          "to_json"
        ]
      }
    },
    {
      "functionName": "set_organization_name",
      "replayTestFileNames": [],
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "set_organization_name",
          "lines": [
            {
              "startLine": 917,
              "endLine": 919
            },
            {
              "startLine": 921,
              "endLine": 924
            },
            {
              "startLine": 926,
              "endLine": 926
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "set_organization_name",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 917,
              "endLine": 919
            },
            {
              "startLine": 921,
              "endLine": 924
            },
            {
              "startLine": 926,
              "endLine": 926
            }
          ]
        },
        "uncoveredFnBody": "class InstanceConfig(db.Model):\n    \"\"\"Versioned key-value store of settings configurable from the journalist\n    interface.  The current version has valid_until=0 (unix epoch start)\n    \"\"\"\n\n    # Limits length of org name used in SI and JI titles, image alt texts etc.\n    MAX_ORG_NAME_LEN = 64\n\n    __tablename__ = \"instance_config\"\n    version = Column(Integer, primary_key=True)\n    valid_until = Column(\n        DateTime,\n        default=datetime.datetime.fromtimestamp(0),\n        nullable=False,\n        unique=True,\n    )\n    allow_document_uploads = Column(Boolean, default=True)\n    organization_name = Column(String(255), nullable=True, default=\"SecureDrop\")\n    initial_message_min_len = Column(Integer, nullable=False, default=0, server_default=\"0\")\n    reject_message_with_codename = Column(\n        Boolean, nullable=False, default=False, server_default=\"0\"\n    )\n\n    # Columns not listed here will be included by InstanceConfig.copy() when\n    # updating the configuration.\n    metadata_cols = [\"version\", \"valid_until\"]\n\n    def __repr__(self) -> str:\n        return (\n            f\"<InstanceConfig(version={self.version}, valid_until={self.valid_until}, \"\n            f\"allow_document_uploads={self.allow_document_uploads}, \"\n            f\"organization_name={self.organization_name}, \"\n            f\"initial_message_min_len={self.initial_message_min_len}, \"\n            f\"reject_message_with_codename={self.reject_message_with_codename})>\"\n        )\n\n    def copy(self) -> \"InstanceConfig\":\n        \"\"\"Make a copy of only the configuration columns of the given\n        InstanceConfig object: i.e., excluding metadata_cols.\n        \"\"\"\n\n        new = type(self)()\n        for col in self.__table__.columns:\n            if col.name in self.metadata_cols:\n                continue\n\n            setattr(new, col.name, getattr(self, col.name))\n\n        return new\n\n    @classmethod\n    def get_default(cls, refresh: bool = False) -> \"InstanceConfig\":\n        global _default_instance_config\n        if (_default_instance_config is None) or (refresh is True):\n            _default_instance_config = InstanceConfig.get_current()\n        return _default_instance_config\n\n    @classmethod\n    def get_current(cls) -> \"InstanceConfig\":\n        \"\"\"If the database was created via db.create_all(), data migrations\n        weren't run, and the \"instance_config\" table is empty.  In this case,\n        save and return a base configuration derived from each setting's\n        column-level default.\n        \"\"\"\n\n        try:\n            return cls.query.filter(cls.valid_until == datetime.datetime.fromtimestamp(0)).one()\n        except NoResultFound:\n            try:\n                current = cls()\n                db.session.add(current)\n                db.session.commit()\n                return current\n            except IntegrityError:\n                return cls.query.filter(cls.valid_until == datetime.datetime.fromtimestamp(0)).one()\n\n    @classmethod\n    def check_name_acceptable(cls, name: str) -> None:\n        # Enforce a reasonable maximum length for names\n        if name is None or len(name) == 0:\n            raise InvalidNameLength()\n        if len(name) > cls.MAX_ORG_NAME_LEN:\n            raise InvalidNameLength()\n\n    @classmethod\n    def set_organization_name(cls, name: str) -> None:\n        \"\"\"Invalidate the current configuration and append a new one with the\n        new organization name.\n        \"\"\"\n\n        old = cls.get_current()\n        old.valid_until = datetime.datetime.utcnow()\n        db.session.add(old)\n\n        new = old.copy() # Untested\n        cls.check_name_acceptable(name) # Untested\n        new.organization_name = name # Untested\n        db.session.add(new) # Untested\n\n        db.session.commit()\n\n    @classmethod\n    def update_submission_prefs(\n        cls, allow_uploads: bool, min_length: int, reject_codenames: bool\n    ) -> None:\n        \"\"\"Invalidate the current configuration and append a new one with the\n        updated submission preferences.\n        \"\"\"\n\n        old = cls.get_current()\n        old.valid_until = datetime.datetime.utcnow()\n        db.session.add(old)\n\n        new = old.copy()\n        new.allow_document_uploads = allow_uploads\n        new.initial_message_min_len = min_length\n        new.reject_message_with_codename = reject_codenames\n        db.session.add(new)\n\n        db.session.commit()",
        "callGraphToTestedFunction": [
          "set_organization_name"
        ]
      }
    },
    {
      "functionName": "make_blueprint",
      "replayTestFileNames": [],
      "file": "journalist_app/account.py",
      "callGraph": [
        {
          "file": "journalist_app/account.py",
          "functionName": "make_blueprint",
          "lines": [
            {
              "startLine": 22,
              "endLine": 22
            },
            {
              "startLine": 24,
              "endLine": 26
            },
            {
              "startLine": 30,
              "endLine": 31
            },
            {
              "startLine": 33,
              "endLine": 38
            },
            {
              "startLine": 40,
              "endLine": 45
            },
            {
              "startLine": 47,
              "endLine": 52
            },
            {
              "startLine": 54,
              "endLine": 55
            },
            {
              "startLine": 63,
              "endLine": 63
            },
            {
              "startLine": 66,
              "endLine": 69
            },
            {
              "startLine": 72,
              "endLine": 73
            },
            {
              "startLine": 77,
              "endLine": 77
            },
            {
              "startLine": 79,
              "endLine": 80
            },
            {
              "startLine": 85,
              "endLine": 85
            },
            {
              "startLine": 92,
              "endLine": 98
            },
            {
              "startLine": 105,
              "endLine": 106
            },
            {
              "startLine": 113,
              "endLine": 114
            },
            {
              "startLine": 116,
              "endLine": 116
            },
            {
              "startLine": 118,
              "endLine": 121
            },
            {
              "startLine": 125,
              "endLine": 125
            },
            {
              "startLine": 127,
              "endLine": 128
            },
            {
              "startLine": 132,
              "endLine": 132
            },
            {
              "startLine": 134,
              "endLine": 135
            },
            {
              "startLine": 140,
              "endLine": 140
            },
            {
              "startLine": 142,
              "endLine": 150
            },
            {
              "startLine": 152,
              "endLine": 152
            },
            {
              "startLine": 154,
              "endLine": 154
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/account.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "make_blueprint",
          "filePath": "journalist_app/account.py",
          "uncoveredLines": [
            {
              "startLine": 22,
              "endLine": 22
            },
            {
              "startLine": 24,
              "endLine": 26
            },
            {
              "startLine": 30,
              "endLine": 31
            },
            {
              "startLine": 33,
              "endLine": 38
            },
            {
              "startLine": 40,
              "endLine": 45
            },
            {
              "startLine": 47,
              "endLine": 52
            },
            {
              "startLine": 54,
              "endLine": 55
            },
            {
              "startLine": 63,
              "endLine": 63
            },
            {
              "startLine": 66,
              "endLine": 69
            },
            {
              "startLine": 72,
              "endLine": 73
            },
            {
              "startLine": 77,
              "endLine": 77
            },
            {
              "startLine": 79,
              "endLine": 80
            },
            {
              "startLine": 85,
              "endLine": 85
            },
            {
              "startLine": 92,
              "endLine": 98
            },
            {
              "startLine": 105,
              "endLine": 106
            },
            {
              "startLine": 113,
              "endLine": 114
            },
            {
              "startLine": 116,
              "endLine": 116
            },
            {
              "startLine": 118,
              "endLine": 121
            },
            {
              "startLine": 125,
              "endLine": 125
            },
            {
              "startLine": 127,
              "endLine": 128
            },
            {
              "startLine": 132,
              "endLine": 132
            },
            {
              "startLine": 134,
              "endLine": 135
            },
            {
              "startLine": 140,
              "endLine": 140
            },
            {
              "startLine": 142,
              "endLine": 150
            },
            {
              "startLine": 152,
              "endLine": 152
            },
            {
              "startLine": 154,
              "endLine": 154
            }
          ]
        },
        "uncoveredFnBody": "def make_blueprint() -> Blueprint:\n    view = Blueprint(\"account\", __name__)\n\n    @view.route(\"/account\", methods=(\"GET\",))\n    def edit() -> str:\n        password = PassphraseGenerator.get_default().generate_passphrase(\n            preferred_language=g.localeinfo.language\n        )\n        # Store password in session for future verification\n        set_pending_password(session.get_user(), password)\n        return render_template(\"edit_account.html\", password=password)\n\n    @view.route(\"/change-name\", methods=(\"POST\",))\n    def change_name() -> werkzeug.Response:\n        first_name = request.form.get(\"first_name\")\n        last_name = request.form.get(\"last_name\")\n        set_name(session.get_user(), first_name, last_name)\n        return redirect(url_for(\"account.edit\"))\n\n    @view.route(\"/new-password\", methods=(\"POST\",))\n    def new_password() -> werkzeug.Response:\n        user = session.get_user()\n        current_password = request.form.get(\"current_password\")\n        token = request.form.get(\"token\")\n        error_message = gettext(\"Incorrect password or two-factor code.\")\n        # If the user is validated, change their password\n        if validate_user(user.username, current_password, token, error_message):\n            password = request.form.get(\"password\")\n            if set_diceware_password(user, password):\n                current_app.session_interface.logout_user(user.id)  # type: ignore\n                return redirect(url_for(\"main.login\"))\n        return redirect(url_for(\"account.edit\"))\n\n    @view.route(\"/verify-2fa-totp\", methods=(\"POST\",))\n    def new_two_factor_totp() -> Union[str, werkzeug.Response]:\n        \"\"\"\n        After (re)setting a user's 2FA TOTP, allow them to verify the newly generated code.\n\n        We don't want users to be able to see their TOTP secret after generation, so it must\n        be supplied in the form body, generated by another endpoint. The provided token is\n        then verified against the supplied secret.\n        \"\"\"\n        token = request.form[\"token\"]\n        # NOTE: We only use the session for getting the user's name for the QR code\n        # and don't fetch any secrets from it.\n        username = session.get_user().username\n        otp_secret = request.form[\"otp_secret\"]\n        totp = two_factor.TOTP(otp_secret)\n        try:\n            # Note: this intentionally doesn't prevent replay attacks, since we just want\n            # to make sure they have the right token\n            totp.verify(token, datetime.utcnow())\n            flash(\n                gettext(\"Your two-factor credentials have been reset successfully.\"),\n                \"notification\",\n            )\n            return redirect(url_for(\"account.edit\"))\n\n        except two_factor.OtpTokenInvalid:\n            flash(\n                gettext(\"There was a problem verifying the two-factor code. Please try again.\"),\n                \"error\",\n            )\n\n        return render_template(\n            \"account_new_two_factor_totp.html\",\n            qrcode=Markup(totp.qrcode_svg(username).decode()),\n            otp_secret=otp_secret,\n            formatted_otp_secret=two_factor.format_secret(otp_secret),\n        )\n\n    @view.route(\"/reset-2fa-totp\", methods=[\"POST\"])\n    def reset_two_factor_totp() -> str:\n        session.get_user().is_totp = True\n        session.get_user().regenerate_totp_shared_secret()\n        db.session.commit()\n        new_otp_secret = session.get_user().otp_secret\n        return render_template(\n            \"account_new_two_factor_totp.html\",\n            qrcode=Markup(session.get_user().totp.qrcode_svg(session.get_user().username).decode()),\n            otp_secret=new_otp_secret,\n            formatted_otp_secret=two_factor.format_secret(new_otp_secret),\n        )\n\n    @view.route(\"/verify-2fa-hotp\", methods=(\"POST\",))\n    def new_two_factor_hotp() -> Union[str, werkzeug.Response]:\n        \"\"\"\n        After (re)setting a user's 2FA HOTP, allow them to verify the newly generated code.\n\n        This works differently than the analogous TOTP endpoint, as here we do verify against\n        the database secret because we need to compare with and increment the counter.\n        \"\"\"\n        user = session.get_user()\n        token = request.form[\"token\"]\n\n        error = False\n\n        if not user.is_totp:\n            try:\n                user.verify_2fa_token(token)\n                flash(\n                    gettext(\"Your two-factor credentials have been reset successfully.\"),\n                    \"notification\",\n                )\n                return redirect(url_for(\"account.edit\"))\n\n            except two_factor.OtpTokenInvalid:\n                error = True\n        else:\n            # XXX: Consider using a different error message here, or do we not want to reveal\n            # if the user is using HOTP vs TOTP\n            error = True\n\n        if error:\n            flash(\n                gettext(\"There was a problem verifying the two-factor code. Please try again.\"),\n                \"error\",\n            )\n\n        return render_template(\"account_new_two_factor_hotp.html\", user=user)\n\n    @view.route(\"/reset-2fa-hotp\", methods=[\"POST\"]) # Untested\n    def reset_two_factor_hotp() -> Union[str, werkzeug.Response]: # Untested\n        otp_secret = request.form.get(\"otp_secret\", None) # Untested\n        if otp_secret: # Untested\n            if not validate_hotp_secret(session.get_user(), otp_secret): # Untested\n                return render_template(\"account_edit_hotp_secret.html\") # Untested\n            session.get_user().set_hotp_secret(otp_secret) # Untested\n            db.session.commit() # Untested\n            return render_template(\"account_new_two_factor_hotp.html\", user=session.get_user()) # Untested\n        else:\n            return render_template(\"account_edit_hotp_secret.html\")\n\n    return view",
        "callGraphToTestedFunction": [
          "make_blueprint"
        ]
      }
    },
    {
      "functionName": "open_session",
      "replayTestFileNames": [],
      "file": "journalist_app/sessions.py",
      "callGraph": [
        {
          "file": "journalist_app/sessions.py",
          "functionName": "open_session",
          "lines": [
            {
              "startLine": 133,
              "endLine": 133
            },
            {
              "startLine": 135,
              "endLine": 143
            },
            {
              "startLine": 145,
              "endLine": 145
            },
            {
              "startLine": 147,
              "endLine": 154
            },
            {
              "startLine": 156,
              "endLine": 163
            },
            {
              "startLine": 166,
              "endLine": 167
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/sessions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "open_session",
          "filePath": "journalist_app/sessions.py",
          "uncoveredLines": [
            {
              "startLine": 133,
              "endLine": 133
            },
            {
              "startLine": 135,
              "endLine": 143
            },
            {
              "startLine": 145,
              "endLine": 145
            },
            {
              "startLine": 147,
              "endLine": 154
            },
            {
              "startLine": 156,
              "endLine": 163
            },
            {
              "startLine": 166,
              "endLine": 167
            }
          ]
        },
        "uncoveredFnBody": "class SessionInterface(FlaskSessionInterface):\n    def _generate_sid(self) -> str:\n        return token_urlsafe(32)\n\n    def _get_signer(self, app: Flask) -> URLSafeTimedSerializer:\n        if not app.secret_key:\n            raise RuntimeError(\"No secret key set\")\n        return URLSafeTimedSerializer(app.secret_key, salt=self.salt)\n\n    \"\"\"Uses the Redis key-value store as a session backend.\n\n    :param redis: A ``redis.Redis`` instance.\n    :param key_prefix: A prefix that is added to all Redis store keys.\n    :param salt: Allows to set the signer salt from the calling interface\n    :param header_name: if use_header, set the header name to parse\n    \"\"\"\n\n    def __init__(\n        self,\n        lifetime: int,\n        renew_count: int,\n        redis: Redis,\n        key_prefix: str,\n        salt: str,\n        header_name: str,\n    ) -> None:\n        self.serializer = session_json_serializer\n        self.redis = redis\n        self.lifetime = lifetime\n        self.renew_count = renew_count\n        self.key_prefix = key_prefix\n        self.api_key_prefix = \"api_\" + key_prefix\n        self.salt = salt\n        self.api_salt = \"api_\" + salt\n        self.header_name = header_name\n        self.new = False\n\n    def _new_session(self, is_api: bool = False, initial: Any = None) -> ServerSideSession:\n        sid = self._generate_sid()\n        token: str = self._get_signer(app).dumps(sid)  # type: ignore\n        session = ServerSideSession(sid=sid, token=token, lifetime=self.lifetime, initial=initial)\n        session.new = True\n        session.is_api = is_api\n        return session\n\n    def open_session(self, app: Flask, request: Request) -> Optional[ServerSideSession]:\n        \"\"\"This function is called by the flask session interface at the\n        beginning of each request.\n        \"\"\"\n        is_api = request.path.split(\"/\")[1] == \"api\"\n\n        if is_api: # Untested\n            self.key_prefix = self.api_key_prefix # Untested\n            self.salt = self.api_salt # Untested\n            auth_header = request.headers.get(self.header_name) # Untested\n            if auth_header: # Untested\n                split = auth_header.split(\" \") # Untested\n                if len(split) != 2 or split[0] != \"Token\": # Untested\n                    return self._new_session(is_api) # Untested\n                sid: Optional[str] = split[1] # Untested\n            else:\n                return self._new_session(is_api)\n        else:\n            sid = request.cookies.get(app.session_cookie_name)\n        if sid:\n            try:\n                sid = self._get_signer(app).loads(sid)\n            except BadSignature:\n                sid = None\n        if not sid:\n            return self._new_session(is_api)\n\n        val = self.redis.get(self.key_prefix + sid)\n        if val is not None:\n            try:\n                data = self.serializer.loads(val.decode(\"utf-8\"))\n                token: str = self._get_signer(app).dumps(sid)  # type: ignore\n                return ServerSideSession(sid=sid, token=token, initial=data)\n            except (JSONDecodeError, NotImplementedError):\n                return self._new_session(is_api)\n        # signed session_id provided in cookie is valid, but the session is not on the server\n        # anymore so maybe here is the code path for a meaningful error message\n        msg = gettext(\"You have been logged out due to inactivity.\")\n        return self._new_session(is_api, initial={\"_flashes\": [(\"error\", msg)]})\n\n    def save_session(  # type: ignore[override]\n        self, app: Flask, session: ServerSideSession, response: Response\n    ) -> None:\n        \"\"\"This is called at the end of each request, just\n        before sending the response.\n        \"\"\"\n        domain = self.get_cookie_domain(app)\n        path = self.get_cookie_path(app)\n        if session.to_destroy:\n            initial: Dict[str, Any] = {\"locale\": session.locale}\n            if session.flash:\n                initial[\"_flashes\"] = [session.flash]\n            self.redis.delete(self.key_prefix + session.sid)\n            if not session.is_api:\n                # Instead of deleting the cookie and send a new sid with the next request\n                # create the new session already, so we can pass along messages and locale\n                session = self._new_session(False, initial=initial)\n        expires = self.redis.ttl(name=self.key_prefix + session.sid)\n        if session.new:\n            session[\"renew_count\"] = self.renew_count\n            expires = self.lifetime\n        elif expires < (30 * 60) and session[\"renew_count\"] > 0:\n            session[\"renew_count\"] -= 1\n            expires += self.lifetime\n            session.modified = True\n        httponly = self.get_cookie_httponly(app)\n        secure = self.get_cookie_secure(app)\n        samesite = self.get_cookie_samesite(app)\n        val = self.serializer.dumps(dict(session))\n        if session.to_regenerate:\n            self.redis.delete(self.key_prefix + session.sid)\n            session.sid = self._generate_sid()\n            session.token = self._get_signer(app).dumps(session.sid)  # type: ignore\n        if session.new or session.to_regenerate:\n            self.redis.setex(name=self.key_prefix + session.sid, value=val, time=expires)\n        elif session.modified:\n            # To prevent race conditions where session is delete by an admin in the middle of a req\n            # accept to save the session object if and only if already exists using the xx flag\n            self.redis.set(name=self.key_prefix + session.sid, value=val, ex=expires, xx=True)\n        if not session.is_api and (session.new or session.to_regenerate):\n            response.headers.add(\"Vary\", \"Cookie\")\n            response.set_cookie(\n                app.session_cookie_name,\n                session.token,\n                httponly=httponly,\n                domain=domain,\n                path=path,\n                secure=secure,\n                samesite=samesite,\n            )\n\n    def logout_user(self, uid: int) -> None:\n        for key in self.redis.keys(self.key_prefix + \"*\") + self.redis.keys(\n            \"api_\" + self.key_prefix + \"*\"\n        ):\n            found = self.redis.get(key)\n            if found:\n                sess = session_json_serializer.loads(found.decode(\"utf-8\"))\n                if \"uid\" in sess and sess[\"uid\"] == uid:\n                    self.redis.delete(key)",
        "callGraphToTestedFunction": [
          "open_session"
        ]
      }
    },
    {
      "functionName": "init_db",
      "replayTestFileNames": [],
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "init_db",
          "lines": [
            {
              "startLine": 313,
              "endLine": 319
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "init_db",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 313,
              "endLine": 319
            }
          ]
        },
        "uncoveredFnBody": "def init_db(args: argparse.Namespace) -> None: # Untested\n    config = SecureDropConfig.get_current() # Untested\n    user = pwd.getpwnam(args.user) # Untested\n    subprocess.check_call([\"sqlite3\", config.DATABASE_FILE, \".databases\"]) # Untested\n    os.chown(config.DATABASE_FILE, user.pw_uid, user.pw_gid) # Untested\n    os.chmod(config.DATABASE_FILE, 0o0640) # Untested\n    subprocess.check_call([\"alembic\", \"upgrade\", \"head\"]) # Untested",
        "callGraphToTestedFunction": [
          "init_db"
        ]
      }
    },
    {
      "functionName": "create_app",
      "replayTestFileNames": [],
      "file": "journalist_app/__init__.py",
      "callGraph": [
        {
          "file": "journalist_app/__init__.py",
          "functionName": "create_app",
          "lines": [
            {
              "startLine": 43,
              "endLine": 43
            },
            {
              "startLine": 49,
              "endLine": 49
            },
            {
              "startLine": 51,
              "endLine": 53
            },
            {
              "startLine": 55,
              "endLine": 57
            },
            {
              "startLine": 59,
              "endLine": 59
            },
            {
              "startLine": 62,
              "endLine": 65
            },
            {
              "startLine": 67,
              "endLine": 67
            },
            {
              "startLine": 69,
              "endLine": 74
            },
            {
              "startLine": 76,
              "endLine": 76
            },
            {
              "startLine": 84,
              "endLine": 86
            },
            {
              "startLine": 88,
              "endLine": 88
            },
            {
              "startLine": 90,
              "endLine": 91
            },
            {
              "startLine": 93,
              "endLine": 93
            },
            {
              "startLine": 95,
              "endLine": 101
            },
            {
              "startLine": 103,
              "endLine": 105
            },
            {
              "startLine": 107,
              "endLine": 108
            },
            {
              "startLine": 111,
              "endLine": 111
            },
            {
              "startLine": 113,
              "endLine": 114
            },
            {
              "startLine": 118,
              "endLine": 118
            },
            {
              "startLine": 120,
              "endLine": 123
            },
            {
              "startLine": 125,
              "endLine": 129
            },
            {
              "startLine": 131,
              "endLine": 135
            },
            {
              "startLine": 137,
              "endLine": 137
            },
            {
              "startLine": 139,
              "endLine": 145
            },
            {
              "startLine": 147,
              "endLine": 147
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/__init__.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "create_app",
          "filePath": "journalist_app/__init__.py",
          "uncoveredLines": [
            {
              "startLine": 43,
              "endLine": 43
            },
            {
              "startLine": 49,
              "endLine": 49
            },
            {
              "startLine": 51,
              "endLine": 53
            },
            {
              "startLine": 55,
              "endLine": 57
            },
            {
              "startLine": 59,
              "endLine": 59
            },
            {
              "startLine": 62,
              "endLine": 65
            },
            {
              "startLine": 67,
              "endLine": 67
            },
            {
              "startLine": 69,
              "endLine": 74
            },
            {
              "startLine": 76,
              "endLine": 76
            },
            {
              "startLine": 84,
              "endLine": 86
            },
            {
              "startLine": 88,
              "endLine": 88
            },
            {
              "startLine": 90,
              "endLine": 91
            },
            {
              "startLine": 93,
              "endLine": 93
            },
            {
              "startLine": 95,
              "endLine": 101
            },
            {
              "startLine": 103,
              "endLine": 105
            },
            {
              "startLine": 107,
              "endLine": 108
            },
            {
              "startLine": 111,
              "endLine": 111
            },
            {
              "startLine": 113,
              "endLine": 114
            },
            {
              "startLine": 118,
              "endLine": 118
            },
            {
              "startLine": 120,
              "endLine": 123
            },
            {
              "startLine": 125,
              "endLine": 129
            },
            {
              "startLine": 131,
              "endLine": 135
            },
            {
              "startLine": 137,
              "endLine": 137
            },
            {
              "startLine": 139,
              "endLine": 145
            },
            {
              "startLine": 147,
              "endLine": 147
            }
          ]
        },
        "uncoveredFnBody": "def create_app(config: SecureDropConfig) -> Flask:\n    app = Flask(\n        __name__,\n        template_folder=str(config.JOURNALIST_TEMPLATES_DIR.absolute()),\n        static_folder=config.STATIC_DIR.absolute(),\n    )\n\n    app.config.from_object(config.JOURNALIST_APP_FLASK_CONFIG_CLS)\n\n    Session(app, config)\n    csrf = CSRFProtect(app)\n    app.config[\"SESSION_COOKIE_SAMESITE\"] = \"Strict\"\n\n    app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\n    app.config[\"SQLALCHEMY_DATABASE_URI\"] = config.DATABASE_URI\n    db.init_app(app)\n\n    class JSONEncoder(json.JSONEncoder):\n        \"\"\"Custom JSON encoder to use our preferred timestamp format\"\"\"\n\n        def default(self, obj: \"Any\") -> \"Any\":\n            if isinstance(obj, datetime):\n                return obj.strftime(API_DATETIME_FORMAT)\n            super().default(obj)\n\n    app.json_encoder = JSONEncoder\n\n    @app.errorhandler(CSRFError)\n    def handle_csrf_error(e: CSRFError) -> \"Response\":\n        app.logger.error(\"The CSRF token is invalid.\")\n        msg = gettext(\"You have been logged out due to inactivity or a problem with your session.\")\n        session.destroy((\"error\", msg), session.get(\"locale\"))\n        return redirect(url_for(\"main.login\"))\n\n    def _handle_http_exception(\n        error: HTTPException,\n    ) -> Tuple[Union[Response, str], Optional[int]]:\n        # Workaround for no blueprint-level 404/5 error handlers, see:\n        # https://github.com/pallets/flask/issues/503#issuecomment-71383286\n        # TODO: clean up API error handling such that all except 404/5s are\n        # registered in the blueprint and 404/5s are handled at the application\n        # level.\n        if request.path.startswith(\"/api/\"):\n            handler = list(app.error_handler_spec[\"api\"][error.code].values())[0]\n            return handler(error)  # type: ignore\n\n        return render_template(\"error.html\", error=error), error.code\n\n    for code in default_exceptions:\n        app.errorhandler(code)(_handle_http_exception)\n\n    i18n.configure(config, app)\n\n    app.jinja_env.trim_blocks = True\n    app.jinja_env.lstrip_blocks = True\n    app.jinja_env.globals[\"version\"] = version.__version__\n    app.jinja_env.filters[\"rel_datetime_format\"] = template_filters.rel_datetime_format\n    app.jinja_env.filters[\"filesizeformat\"] = template_filters.filesizeformat\n    app.jinja_env.filters[\"html_datetime_format\"] = template_filters.html_datetime_format\n    app.jinja_env.add_extension(\"jinja2.ext.do\")\n\n    @app.before_request\n    def update_instance_config() -> None:\n        InstanceConfig.get_default(refresh=True)\n\n    @app.before_request\n    def setup_g() -> Optional[Response]:\n        \"\"\"Store commonly used values in Flask's special g object\"\"\"\n\n        i18n.set_locale(config)\n\n        if InstanceConfig.get_default().organization_name:\n            g.organization_name = (  # pylint: disable=assigning-non-slot\n                InstanceConfig.get_default().organization_name\n            )\n        else:\n            g.organization_name = gettext(\"SecureDrop\")  # pylint: disable=assigning-non-slot\n\n        try:\n            g.logo = get_logo_url(app)  # pylint: disable=assigning-non-slot\n        except FileNotFoundError:\n            app.logger.error(\"Site logo not found.\")\n\n        if request.path.split(\"/\")[1] == \"api\":\n            if request.endpoint not in _insecure_api_views and not session.logged_in():\n                abort(403)\n        elif request.endpoint not in _insecure_views and not session.logged_in():\n            return redirect(url_for(\"main.login\"))\n\n        if request.method == \"POST\":\n            filesystem_id = request.form.get(\"filesystem_id\")\n            if filesystem_id:\n                g.filesystem_id = filesystem_id  # pylint: disable=assigning-non-slot\n                g.source = get_source(filesystem_id)  # pylint: disable=assigning-non-slot\n\n        return None\n\n    app.register_blueprint(main.make_blueprint()) # Untested\n    app.register_blueprint(account.make_blueprint(), url_prefix=\"/account\") # Untested\n    app.register_blueprint(admin.make_blueprint(), url_prefix=\"/admin\") # Untested\n    app.register_blueprint(col.make_blueprint(), url_prefix=\"/col\") # Untested\n    api_blueprint = api.make_blueprint() # Untested\n    app.register_blueprint(api_blueprint, url_prefix=\"/api/v1\") # Untested\n    csrf.exempt(api_blueprint) # Untested\n\n    return app",
        "callGraphToTestedFunction": [
          "create_app"
        ]
      }
    },
    {
      "functionName": "add_checksum_for_file",
      "replayTestFileNames": [],
      "file": "store.py",
      "callGraph": [
        {
          "file": "store.py",
          "functionName": "add_checksum_for_file",
          "lines": [
            {
              "startLine": 393,
              "endLine": 394
            },
            {
              "startLine": 396,
              "endLine": 399
            },
            {
              "startLine": 401,
              "endLine": 403
            },
            {
              "startLine": 405,
              "endLine": 406
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "store.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "add_checksum_for_file",
          "filePath": "store.py",
          "uncoveredLines": [
            {
              "startLine": 393,
              "endLine": 394
            },
            {
              "startLine": 396,
              "endLine": 399
            },
            {
              "startLine": 401,
              "endLine": 403
            },
            {
              "startLine": 405,
              "endLine": 406
            }
          ]
        },
        "uncoveredFnBody": "def add_checksum_for_file(\n    session: \"Session\", db_obj: \"Union[Submission, Reply]\", file_path: str\n) -> None:\n    hasher = sha256()\n    with open(file_path, \"rb\") as f:\n        while True:\n            read_bytes = f.read(4096) # Untested\n            if not read_bytes: # Untested\n                break # Untested\n            hasher.update(read_bytes) # Untested\n\n    digest = binascii.hexlify(hasher.digest()).decode(\"utf-8\")\n    digest_str = \"sha256:\" + digest\n    db_obj.checksum = digest_str\n\n    session.add(db_obj)\n    session.commit()",
        "callGraphToTestedFunction": [
          "add_checksum_for_file"
        ]
      }
    },
    {
      "functionName": "sign",
      "replayTestFileNames": [],
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "sign",
          "lines": [
            {
              "startLine": 227,
              "endLine": 228
            },
            {
              "startLine": 230,
              "endLine": 230
            },
            {
              "startLine": 232,
              "endLine": 237
            },
            {
              "startLine": 239,
              "endLine": 241
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "sign",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 227,
              "endLine": 228
            },
            {
              "startLine": 230,
              "endLine": 230
            },
            {
              "startLine": 232,
              "endLine": 237
            },
            {
              "startLine": 239,
              "endLine": 241
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"): # Untested\n            result = self._sign_file(data, **kwargs) # Untested\n        elif not _is_stream(data): # Untested\n            stream = _make_binary_stream(data, self._encoding) # Untested\n            result = self._sign_file(stream, **kwargs) # Untested\n            stream.close() # Untested\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "sign"
        ]
      }
    }
  ],
  "existingTestTargets": [
    {
      "functionName": "get_source_secret_key_from_gpg",
      "file": "encryption.py",
      "callGraph": [
        {
          "file": "encryption.py",
          "functionName": "get_source_secret_key_from_gpg",
          "lines": [
            {
              "startLine": 135,
              "endLine": 135
            },
            {
              "startLine": 139,
              "endLine": 139
            },
            {
              "startLine": 142,
              "endLine": 142
            },
            {
              "startLine": 145,
              "endLine": 145
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_encryption.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "encryption.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_source_secret_key_from_gpg",
          "filePath": "encryption.py",
          "uncoveredLines": [
            {
              "startLine": 135,
              "endLine": 135
            },
            {
              "startLine": 139,
              "endLine": 139
            },
            {
              "startLine": 142,
              "endLine": 142
            },
            {
              "startLine": 145,
              "endLine": 145
            }
          ]
        },
        "uncoveredFnBody": "class EncryptionManager:\n    \"\"\"EncryptionManager provides a high-level interface for each PGP operation we do\"\"\"\n\n    REDIS_FINGERPRINT_HASH = \"sd/crypto-util/fingerprints\"\n    REDIS_KEY_HASH = \"sd/crypto-util/keys\"\n\n    SOURCE_KEY_UID_RE = re.compile(r\"(Source|Autogenerated) Key <([-A-Za-z0-9+/=_]+)>\")\n\n    def __init__(self, gpg_key_dir: Path, journalist_pub_key: Path, redis: Redis) -> None:\n        self._gpg_key_dir = gpg_key_dir\n        self.journalist_pub_key = journalist_pub_key\n        if not self.journalist_pub_key.exists():\n            raise RuntimeError(\n                f\"The journalist public key does not exist at {self.journalist_pub_key}\"\n            )\n        self._redis = redis\n\n        # Instantiate the \"main\" GPG binary\n        self._gpg = None\n\n        # Instantiate the GPG binary to be used for key deletion: always delete keys without\n        # invoking pinentry-mode=loopback\n        # see: https://lists.gnupg.org/pipermail/gnupg-users/2016-May/055965.html\n        self._gpg_for_key_deletion = None\n\n    def gpg(self, for_deletion: Optional[bool] = False) -> gnupg.GPG:\n        if for_deletion:\n            if self._gpg_for_key_deletion is None:\n                # GPG binary to be used for key deletion: always delete keys without\n                # invoking pinentry-mode=loopback\n                # see: https://lists.gnupg.org/pipermail/gnupg-users/2016-May/055965.html\n                self._gpg_for_key_deletion = gnupg.GPG(\n                    binary=\"gpg2\",\n                    homedir=str(self._gpg_key_dir),\n                    options=[\"--yes\", \"--trust-model direct\"],\n                )\n            return self._gpg_for_key_deletion\n        else:\n            if self._gpg is None:\n                self._gpg = gnupg.GPG(\n                    binary=\"gpg2\",\n                    homedir=str(self._gpg_key_dir),\n                    options=[\"--pinentry-mode loopback\", \"--trust-model direct\"],\n                )\n            return self._gpg\n\n    @classmethod\n    def get_default(cls) -> \"EncryptionManager\":\n        global _default_encryption_mgr\n        if _default_encryption_mgr is None:\n            config = SecureDropConfig.get_current()\n            _default_encryption_mgr = cls(\n                gpg_key_dir=config.GPG_KEY_DIR,\n                journalist_pub_key=(config.SECUREDROP_DATA_ROOT / \"journalist.pub\"),\n                redis=Redis(decode_responses=True, **config.REDIS_KWARGS),\n            )\n        return _default_encryption_mgr\n\n    def delete_source_key_pair(self, source_filesystem_id: str) -> None:\n        \"\"\"\n        Try to delete the source's key from the filesystem.  If it's not found, either:\n        (a) it doesn't exist or\n        (b) the source is Sequoia-based and has its key stored in Source.pgp_public_key,\n            which will be deleted when the Source instance itself is deleted.\n        \"\"\"\n        try:\n            source_key_fingerprint = self.get_source_key_fingerprint(source_filesystem_id)\n        except GpgKeyNotFoundError:\n            # If the source is entirely Sequoia-based, there is nothing to delete\n            return\n\n        # The subkeys keyword argument deletes both secret and public keys\n        self.gpg(for_deletion=True).delete_keys(source_key_fingerprint, secret=True, subkeys=True)\n\n        self._redis.hdel(self.REDIS_KEY_HASH, source_key_fingerprint)\n        self._redis.hdel(self.REDIS_FINGERPRINT_HASH, source_filesystem_id)\n\n    def get_journalist_public_key(self) -> str:\n        return self.journalist_pub_key.read_text()\n\n    def get_source_public_key(self, source_filesystem_id: str) -> str:\n        source_key_fingerprint = self.get_source_key_fingerprint(source_filesystem_id)\n        return self._get_public_key(source_key_fingerprint)\n\n    def get_source_key_fingerprint(self, source_filesystem_id: str) -> str:\n        source_key_fingerprint = self._redis.hget(self.REDIS_FINGERPRINT_HASH, source_filesystem_id)\n        if source_key_fingerprint:\n            return source_key_fingerprint\n\n        # If the fingerprint was not in Redis, get it directly from GPG\n        source_key_details = self._get_source_key_details(source_filesystem_id)\n        source_key_fingerprint = source_key_details[\"fingerprint\"]\n        self._save_key_fingerprint_to_redis(source_filesystem_id, source_key_fingerprint)\n        return source_key_fingerprint\n\n    def get_source_secret_key_from_gpg(self, fingerprint: str, passphrase: str) -> str:\n        secret_key = self.gpg().export_keys(fingerprint, secret=True, passphrase=passphrase)\n        if not secret_key:\n            raise GpgKeyNotFoundError()\n        # Verify the secret key we got can be read and decrypted by redwood\n        try:\n            actual_fingerprint = redwood.is_valid_secret_key(secret_key, passphrase)\n        except redwood.RedwoodError:\n            # Either Sequoia can't extract the secret key or the passphrase\n            # is incorrect.\n            raise GpgKeyNotFoundError()\n        if fingerprint != actual_fingerprint:\n            # Somehow we exported the wrong key?\n            raise GpgKeyNotFoundError() # Untested\n        return secret_key\n\n    def encrypt_source_message(self, message_in: str, encrypted_message_path_out: Path) -> None:\n        redwood.encrypt_message(\n            # A submission is only encrypted for the journalist key\n            recipients=[self.get_journalist_public_key()],\n            plaintext=message_in,\n            destination=encrypted_message_path_out,\n        )\n\n    def encrypt_source_file(self, file_in: BinaryIO, encrypted_file_path_out: Path) -> None:\n        redwood.encrypt_stream(\n            # A submission is only encrypted for the journalist key\n            recipients=[self.get_journalist_public_key()],\n            plaintext=file_in,\n            destination=encrypted_file_path_out,\n        )\n\n    def encrypt_journalist_reply(\n        self, for_source: \"Source\", reply_in: str, encrypted_reply_path_out: Path\n    ) -> None:\n        redwood.encrypt_message(\n            # A reply is encrypted for both the journalist key and the source key\n            recipients=[for_source.public_key, self.get_journalist_public_key()],\n            plaintext=reply_in,\n            destination=encrypted_reply_path_out,\n        )\n\n    def decrypt_journalist_reply(self, for_source_user: \"SourceUser\", ciphertext_in: bytes) -> str:\n        \"\"\"Decrypt a reply sent by a journalist.\"\"\"\n        # TODO: Avoid making a database query here\n        for_source = for_source_user.get_db_record()\n        if for_source.pgp_secret_key is not None:\n            return redwood.decrypt(\n                ciphertext_in,\n                secret_key=for_source.pgp_secret_key,\n                passphrase=for_source_user.gpg_secret,\n            ).decode()\n        # In practice this should be uncreachable unless the Sequoia secret key migration failed\n        ciphertext_as_stream = BytesIO(ciphertext_in)\n        out = self.gpg().decrypt_file(ciphertext_as_stream, passphrase=for_source_user.gpg_secret)\n        if not out.ok:\n            raise GpgDecryptError(out.stderr)\n\n        return out.data.decode(\"utf-8\")\n\n    def _get_source_key_details(self, source_filesystem_id: str) -> Dict[str, str]:\n        for key in self.gpg().list_keys():\n            for uid in key[\"uids\"]:\n                if source_filesystem_id in uid and self.SOURCE_KEY_UID_RE.match(uid):\n                    return key\n        raise GpgKeyNotFoundError()\n\n    def _save_key_fingerprint_to_redis(\n        self, source_filesystem_id: str, source_key_fingerprint: str\n    ) -> None:\n        self._redis.hset(self.REDIS_FINGERPRINT_HASH, source_filesystem_id, source_key_fingerprint)\n\n    def _get_public_key(self, key_fingerprint: str) -> str:\n        # First try to fetch the public key from Redis\n        public_key = self._redis.hget(self.REDIS_KEY_HASH, key_fingerprint)\n        if public_key:\n            return public_key\n\n        # Then directly from GPG\n        public_key = self.gpg().export_keys(key_fingerprint)\n        if not public_key:\n            raise GpgKeyNotFoundError()\n\n        self._redis.hset(self.REDIS_KEY_HASH, key_fingerprint, public_key)\n        return public_key",
        "callGraphToTestedFunction": [
          "get_source_secret_key_from_gpg"
        ]
      },
      "unitTestFilePath": "tests/test_encryption.py"
    },
    {
      "functionName": "decrypt_journalist_reply",
      "file": "encryption.py",
      "callGraph": [
        {
          "file": "encryption.py",
          "functionName": "decrypt_journalist_reply",
          "lines": [
            {
              "startLine": 185,
              "endLine": 188
            },
            {
              "startLine": 190,
              "endLine": 190
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_encryption.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "encryption.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "decrypt_journalist_reply",
          "filePath": "encryption.py",
          "uncoveredLines": [
            {
              "startLine": 185,
              "endLine": 188
            },
            {
              "startLine": 190,
              "endLine": 190
            }
          ]
        },
        "uncoveredFnBody": "class EncryptionManager:\n    \"\"\"EncryptionManager provides a high-level interface for each PGP operation we do\"\"\"\n\n    REDIS_FINGERPRINT_HASH = \"sd/crypto-util/fingerprints\"\n    REDIS_KEY_HASH = \"sd/crypto-util/keys\"\n\n    SOURCE_KEY_UID_RE = re.compile(r\"(Source|Autogenerated) Key <([-A-Za-z0-9+/=_]+)>\")\n\n    def __init__(self, gpg_key_dir: Path, journalist_pub_key: Path, redis: Redis) -> None:\n        self._gpg_key_dir = gpg_key_dir\n        self.journalist_pub_key = journalist_pub_key\n        if not self.journalist_pub_key.exists():\n            raise RuntimeError(\n                f\"The journalist public key does not exist at {self.journalist_pub_key}\"\n            )\n        self._redis = redis\n\n        # Instantiate the \"main\" GPG binary\n        self._gpg = None\n\n        # Instantiate the GPG binary to be used for key deletion: always delete keys without\n        # invoking pinentry-mode=loopback\n        # see: https://lists.gnupg.org/pipermail/gnupg-users/2016-May/055965.html\n        self._gpg_for_key_deletion = None\n\n    def gpg(self, for_deletion: Optional[bool] = False) -> gnupg.GPG:\n        if for_deletion:\n            if self._gpg_for_key_deletion is None:\n                # GPG binary to be used for key deletion: always delete keys without\n                # invoking pinentry-mode=loopback\n                # see: https://lists.gnupg.org/pipermail/gnupg-users/2016-May/055965.html\n                self._gpg_for_key_deletion = gnupg.GPG(\n                    binary=\"gpg2\",\n                    homedir=str(self._gpg_key_dir),\n                    options=[\"--yes\", \"--trust-model direct\"],\n                )\n            return self._gpg_for_key_deletion\n        else:\n            if self._gpg is None:\n                self._gpg = gnupg.GPG(\n                    binary=\"gpg2\",\n                    homedir=str(self._gpg_key_dir),\n                    options=[\"--pinentry-mode loopback\", \"--trust-model direct\"],\n                )\n            return self._gpg\n\n    @classmethod\n    def get_default(cls) -> \"EncryptionManager\":\n        global _default_encryption_mgr\n        if _default_encryption_mgr is None:\n            config = SecureDropConfig.get_current()\n            _default_encryption_mgr = cls(\n                gpg_key_dir=config.GPG_KEY_DIR,\n                journalist_pub_key=(config.SECUREDROP_DATA_ROOT / \"journalist.pub\"),\n                redis=Redis(decode_responses=True, **config.REDIS_KWARGS),\n            )\n        return _default_encryption_mgr\n\n    def delete_source_key_pair(self, source_filesystem_id: str) -> None:\n        \"\"\"\n        Try to delete the source's key from the filesystem.  If it's not found, either:\n        (a) it doesn't exist or\n        (b) the source is Sequoia-based and has its key stored in Source.pgp_public_key,\n            which will be deleted when the Source instance itself is deleted.\n        \"\"\"\n        try:\n            source_key_fingerprint = self.get_source_key_fingerprint(source_filesystem_id)\n        except GpgKeyNotFoundError:\n            # If the source is entirely Sequoia-based, there is nothing to delete\n            return\n\n        # The subkeys keyword argument deletes both secret and public keys\n        self.gpg(for_deletion=True).delete_keys(source_key_fingerprint, secret=True, subkeys=True)\n\n        self._redis.hdel(self.REDIS_KEY_HASH, source_key_fingerprint)\n        self._redis.hdel(self.REDIS_FINGERPRINT_HASH, source_filesystem_id)\n\n    def get_journalist_public_key(self) -> str:\n        return self.journalist_pub_key.read_text()\n\n    def get_source_public_key(self, source_filesystem_id: str) -> str:\n        source_key_fingerprint = self.get_source_key_fingerprint(source_filesystem_id)\n        return self._get_public_key(source_key_fingerprint)\n\n    def get_source_key_fingerprint(self, source_filesystem_id: str) -> str:\n        source_key_fingerprint = self._redis.hget(self.REDIS_FINGERPRINT_HASH, source_filesystem_id)\n        if source_key_fingerprint:\n            return source_key_fingerprint\n\n        # If the fingerprint was not in Redis, get it directly from GPG\n        source_key_details = self._get_source_key_details(source_filesystem_id)\n        source_key_fingerprint = source_key_details[\"fingerprint\"]\n        self._save_key_fingerprint_to_redis(source_filesystem_id, source_key_fingerprint)\n        return source_key_fingerprint\n\n    def get_source_secret_key_from_gpg(self, fingerprint: str, passphrase: str) -> str:\n        secret_key = self.gpg().export_keys(fingerprint, secret=True, passphrase=passphrase)\n        if not secret_key:\n            raise GpgKeyNotFoundError()\n        # Verify the secret key we got can be read and decrypted by redwood\n        try:\n            actual_fingerprint = redwood.is_valid_secret_key(secret_key, passphrase)\n        except redwood.RedwoodError:\n            # Either Sequoia can't extract the secret key or the passphrase\n            # is incorrect.\n            raise GpgKeyNotFoundError()\n        if fingerprint != actual_fingerprint:\n            # Somehow we exported the wrong key?\n            raise GpgKeyNotFoundError()\n        return secret_key\n\n    def encrypt_source_message(self, message_in: str, encrypted_message_path_out: Path) -> None:\n        redwood.encrypt_message(\n            # A submission is only encrypted for the journalist key\n            recipients=[self.get_journalist_public_key()],\n            plaintext=message_in,\n            destination=encrypted_message_path_out,\n        )\n\n    def encrypt_source_file(self, file_in: BinaryIO, encrypted_file_path_out: Path) -> None:\n        redwood.encrypt_stream(\n            # A submission is only encrypted for the journalist key\n            recipients=[self.get_journalist_public_key()],\n            plaintext=file_in,\n            destination=encrypted_file_path_out,\n        )\n\n    def encrypt_journalist_reply(\n        self, for_source: \"Source\", reply_in: str, encrypted_reply_path_out: Path\n    ) -> None:\n        redwood.encrypt_message(\n            # A reply is encrypted for both the journalist key and the source key\n            recipients=[for_source.public_key, self.get_journalist_public_key()],\n            plaintext=reply_in,\n            destination=encrypted_reply_path_out,\n        )\n\n    def decrypt_journalist_reply(self, for_source_user: \"SourceUser\", ciphertext_in: bytes) -> str:\n        \"\"\"Decrypt a reply sent by a journalist.\"\"\"\n        # TODO: Avoid making a database query here\n        for_source = for_source_user.get_db_record()\n        if for_source.pgp_secret_key is not None:\n            return redwood.decrypt(\n                ciphertext_in,\n                secret_key=for_source.pgp_secret_key,\n                passphrase=for_source_user.gpg_secret,\n            ).decode()\n        # In practice this should be uncreachable unless the Sequoia secret key migration failed\n        ciphertext_as_stream = BytesIO(ciphertext_in) # Untested\n        out = self.gpg().decrypt_file(ciphertext_as_stream, passphrase=for_source_user.gpg_secret) # Untested\n        if not out.ok: # Untested\n            raise GpgDecryptError(out.stderr) # Untested\n\n        return out.data.decode(\"utf-8\")\n\n    def _get_source_key_details(self, source_filesystem_id: str) -> Dict[str, str]:\n        for key in self.gpg().list_keys():\n            for uid in key[\"uids\"]:\n                if source_filesystem_id in uid and self.SOURCE_KEY_UID_RE.match(uid):\n                    return key\n        raise GpgKeyNotFoundError()\n\n    def _save_key_fingerprint_to_redis(\n        self, source_filesystem_id: str, source_key_fingerprint: str\n    ) -> None:\n        self._redis.hset(self.REDIS_FINGERPRINT_HASH, source_filesystem_id, source_key_fingerprint)\n\n    def _get_public_key(self, key_fingerprint: str) -> str:\n        # First try to fetch the public key from Redis\n        public_key = self._redis.hget(self.REDIS_KEY_HASH, key_fingerprint)\n        if public_key:\n            return public_key\n\n        # Then directly from GPG\n        public_key = self.gpg().export_keys(key_fingerprint)\n        if not public_key:\n            raise GpgKeyNotFoundError()\n\n        self._redis.hset(self.REDIS_KEY_HASH, key_fingerprint, public_key)\n        return public_key",
        "callGraphToTestedFunction": [
          "decrypt_journalist_reply"
        ]
      },
      "unitTestFilePath": "tests/test_encryption.py"
    },
    {
      "functionName": "get_user",
      "file": "journalist_app/sessions.py",
      "callGraph": [
        {
          "file": "journalist_app/sessions.py",
          "functionName": "get_user",
          "lines": [
            {
              "startLine": 58,
              "endLine": 58
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_two_factor_in_apps.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "journalist_app/sessions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_user",
          "filePath": "journalist_app/sessions.py",
          "uncoveredLines": [
            {
              "startLine": 58,
              "endLine": 58
            }
          ]
        },
        "uncoveredFnBody": "class ServerSideSession(CallbackDict, SessionMixin):\n    \"\"\"Baseclass for server-side based sessions.\"\"\"\n\n    def __init__(self, sid: str, token: str, lifetime: int = 0, initial: Any = None) -> None:\n        def on_update(self: ServerSideSession) -> None:\n            self.modified = True\n\n        if initial and \"uid\" in initial:\n            self.set_uid(initial[\"uid\"])\n            self.set_user()\n        else:\n            self.uid: Optional[int] = None\n            self.user = None\n        CallbackDict.__init__(self, initial, on_update)\n        self.sid = sid\n        self.token: str = token\n        self.lifetime = lifetime\n        self.is_api = False\n        self.to_destroy = False\n        self.to_regenerate = False\n        self.modified = False\n        self.flash: Optional[Tuple[str, str]] = None\n        self.locale: Optional[str] = None\n\n    def get_token(self) -> Optional[str]:\n        return self.token\n\n    def get_lifetime(self) -> datetime:\n        return datetime.now(timezone.utc) + timedelta(seconds=self.lifetime)\n\n    def set_user(self) -> None:\n        if self.uid is not None:\n            self.user = Journalist.query.get(self.uid)\n        if self.user is None:\n            # The uid has no match in the database, and this should really not happen\n            self.uid = None\n            self.to_destroy = True\n\n    def get_user(self) -> Optional[Journalist]:\n        return self.user # Untested\n\n    def get_uid(self) -> Optional[int]:\n        return self.uid\n\n    def set_uid(self, uid: int) -> None:\n        self.user = None\n        self.uid = uid\n\n    def logged_in(self) -> bool:\n        return self.uid is not None\n\n    def destroy(\n        self, flash: Optional[Tuple[str, str]] = None, locale: Optional[str] = None\n    ) -> None:\n        # The parameters are needed to pass the information to the new session\n        self.locale = locale\n        self.flash = flash\n        self.uid = None\n        self.user = None\n        self.to_destroy = True\n\n    def regenerate(self) -> None:\n        self.to_regenerate = True",
        "callGraphToTestedFunction": [
          "get_user"
        ]
      },
      "unitTestFilePath": "tests/test_two_factor_in_apps.py"
    },
    {
      "functionName": "reset",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "reset",
          "lines": [
            {
              "startLine": 54,
              "endLine": 54
            },
            {
              "startLine": 65,
              "endLine": 65
            },
            {
              "startLine": 68,
              "endLine": 69
            },
            {
              "startLine": 75,
              "endLine": 81
            },
            {
              "startLine": 83,
              "endLine": 86
            },
            {
              "startLine": 90,
              "endLine": 90
            },
            {
              "startLine": 92,
              "endLine": 93
            },
            {
              "startLine": 95,
              "endLine": 95
            },
            {
              "startLine": 99,
              "endLine": 100
            },
            {
              "startLine": 103,
              "endLine": 103
            },
            {
              "startLine": 106,
              "endLine": 109
            },
            {
              "startLine": 111,
              "endLine": 112
            },
            {
              "startLine": 115,
              "endLine": 118
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "reset",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 54,
              "endLine": 54
            },
            {
              "startLine": 65,
              "endLine": 65
            },
            {
              "startLine": 68,
              "endLine": 69
            },
            {
              "startLine": 75,
              "endLine": 81
            },
            {
              "startLine": 83,
              "endLine": 86
            },
            {
              "startLine": 90,
              "endLine": 90
            },
            {
              "startLine": 92,
              "endLine": 93
            },
            {
              "startLine": 95,
              "endLine": 95
            },
            {
              "startLine": 99,
              "endLine": 100
            },
            {
              "startLine": 103,
              "endLine": 103
            },
            {
              "startLine": 106,
              "endLine": 109
            },
            {
              "startLine": 111,
              "endLine": 112
            },
            {
              "startLine": 115,
              "endLine": 118
            }
          ]
        },
        "uncoveredFnBody": "def reset(\n    args: argparse.Namespace,\n    alembic_ini_path: Path = Path(\"alembic.ini\"),\n    context: Optional[AppContext] = None,\n) -> int:\n    \"\"\"Clears the SecureDrop development applications' state, restoring them to\n    the way they were immediately after running `setup_dev.sh`. This command:\n    1. Erases the development sqlite database file.\n    2. Regenerates the database.\n    3. Erases stored submissions and replies from the store dir.\n    \"\"\"\n    config = SecureDropConfig.get_current()\n\n    # Erase the development db file\n    if not hasattr(config, \"DATABASE_FILE\"):\n        raise Exception(\n            \"./manage.py doesn't know how to clear the db \" \"if the backend is not sqlite\"\n        )\n\n    # we need to save some data about the old DB file so we can recreate it\n    # with the same state\n    try: # Untested\n        stat_res = os.stat(config.DATABASE_FILE) # Untested\n        uid = stat_res.st_uid # Untested\n        gid = stat_res.st_gid # Untested\n    except OSError: # Untested\n        uid = os.getuid() # Untested\n        gid = os.getgid() # Untested\n\n    try:\n        os.remove(config.DATABASE_FILE)\n    except OSError:\n        pass\n\n    # Regenerate the database\n    # 1. Create it\n    subprocess.check_call([\"sqlite3\", config.DATABASE_FILE, \".databases\"])\n    # 2. Set permissions on it\n    os.chown(config.DATABASE_FILE, uid, gid)\n    os.chmod(config.DATABASE_FILE, 0o0640)\n\n    if os.environ.get(\"SECUREDROP_ENV\") == \"dev\":\n        # 3. Create the DB from the metadata directly when in 'dev' so\n        # developers can test application changes without first writing\n        # alembic migration.\n        with context or app_context():\n            db.create_all()\n    else:\n        # 3. Migrate it to 'head'\n        subprocess.check_call([\"alembic\", \"upgrade\", \"head\"], cwd=alembic_ini_path.parent)\n\n    # Clear submission/reply storage\n    try:\n        os.stat(args.store_dir)\n    except OSError:\n        pass\n    else:\n        for source_dir in os.listdir(args.store_dir):\n            try:\n                # Each entry in STORE_DIR is a directory corresponding\n                # to a source\n                shutil.rmtree(os.path.join(args.store_dir, source_dir))\n            except OSError:\n                pass\n    return 0",
        "callGraphToTestedFunction": [
          "reset"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "_get_username",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "_get_username",
          "lines": [
            {
              "startLine": 129,
              "endLine": 129
            },
            {
              "startLine": 131,
              "endLine": 135
            },
            {
              "startLine": 137,
              "endLine": 137
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "_get_username",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 129,
              "endLine": 129
            },
            {
              "startLine": 131,
              "endLine": 135
            },
            {
              "startLine": 137,
              "endLine": 137
            }
          ]
        },
        "uncoveredFnBody": "def _get_username() -> str:\n    while True:\n        username = obtain_input(\"Username: \") # Untested\n        try: # Untested\n            Journalist.check_username_acceptable(username) # Untested\n        except InvalidUsernameException as e: # Untested\n            print(\"Invalid username: \" + str(e)) # Untested\n        else:\n            return username",
        "callGraphToTestedFunction": [
          "_get_username"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "_get_first_name",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "_get_first_name",
          "lines": [
            {
              "startLine": 140,
              "endLine": 140
            },
            {
              "startLine": 142,
              "endLine": 149
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "_get_first_name",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 140,
              "endLine": 140
            },
            {
              "startLine": 142,
              "endLine": 149
            }
          ]
        },
        "uncoveredFnBody": "def _get_first_name() -> Optional[str]:\n    while True:\n        first_name = obtain_input(\"First name: \") # Untested\n        if not first_name: # Untested\n            return None # Untested\n        try: # Untested\n            Journalist.check_name_acceptable(first_name) # Untested\n            return first_name # Untested\n        except FirstOrLastNameError as e: # Untested\n            print(\"Invalid name: \" + str(e)) # Untested",
        "callGraphToTestedFunction": [
          "_get_first_name"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "_get_last_name",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "_get_last_name",
          "lines": [
            {
              "startLine": 152,
              "endLine": 152
            },
            {
              "startLine": 154,
              "endLine": 161
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "_get_last_name",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 152,
              "endLine": 152
            },
            {
              "startLine": 154,
              "endLine": 161
            }
          ]
        },
        "uncoveredFnBody": "def _get_last_name() -> Optional[str]:\n    while True:\n        last_name = obtain_input(\"Last name: \") # Untested\n        if not last_name: # Untested\n            return None # Untested\n        try: # Untested\n            Journalist.check_name_acceptable(last_name) # Untested\n            return last_name # Untested\n        except FirstOrLastNameError as e: # Untested\n            print(\"Invalid name: \" + str(e)) # Untested",
        "callGraphToTestedFunction": [
          "_get_last_name"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "_get_yubikey_usage",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "_get_yubikey_usage",
          "lines": [
            {
              "startLine": 164,
              "endLine": 164
            },
            {
              "startLine": 167,
              "endLine": 167
            },
            {
              "startLine": 170,
              "endLine": 173
            },
            {
              "startLine": 175,
              "endLine": 175
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "_get_yubikey_usage",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 164,
              "endLine": 164
            },
            {
              "startLine": 167,
              "endLine": 167
            },
            {
              "startLine": 170,
              "endLine": 173
            },
            {
              "startLine": 175,
              "endLine": 175
            }
          ]
        },
        "uncoveredFnBody": "def _get_yubikey_usage() -> bool:\n    \"\"\"Function used to allow for test suite mocking\"\"\"\n    while True:\n        answer = (\n            obtain_input(\"Will this user be using a YubiKey [HOTP]? \" \"(y/N): \").lower().strip()\n        )\n        if answer in (\"y\", \"yes\"): # Untested\n            return True # Untested\n        elif answer in (\"\", \"n\", \"no\"): # Untested\n            return False # Untested\n        else:\n            print('Invalid answer. Please type \"y\" or \"n\"')",
        "callGraphToTestedFunction": [
          "_get_yubikey_usage"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "_add_user",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "_add_user",
          "lines": [
            {
              "startLine": 178,
              "endLine": 182
            },
            {
              "startLine": 184,
              "endLine": 186
            },
            {
              "startLine": 188,
              "endLine": 190
            },
            {
              "startLine": 192,
              "endLine": 192
            },
            {
              "startLine": 195,
              "endLine": 198
            },
            {
              "startLine": 203,
              "endLine": 205
            },
            {
              "startLine": 207,
              "endLine": 208
            },
            {
              "startLine": 216,
              "endLine": 221
            },
            {
              "startLine": 223,
              "endLine": 225
            },
            {
              "startLine": 227,
              "endLine": 228
            },
            {
              "startLine": 230,
              "endLine": 235
            },
            {
              "startLine": 244,
              "endLine": 244
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "_add_user",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 178,
              "endLine": 182
            },
            {
              "startLine": 184,
              "endLine": 186
            },
            {
              "startLine": 188,
              "endLine": 190
            },
            {
              "startLine": 192,
              "endLine": 192
            },
            {
              "startLine": 195,
              "endLine": 198
            },
            {
              "startLine": 203,
              "endLine": 205
            },
            {
              "startLine": 207,
              "endLine": 208
            },
            {
              "startLine": 216,
              "endLine": 221
            },
            {
              "startLine": 223,
              "endLine": 225
            },
            {
              "startLine": 227,
              "endLine": 228
            },
            {
              "startLine": 230,
              "endLine": 235
            },
            {
              "startLine": 244,
              "endLine": 244
            }
          ]
        },
        "uncoveredFnBody": "def _add_user(is_admin: bool = False, context: Optional[AppContext] = None) -> int:\n    with context or app_context():\n        username = _get_username()\n        first_name = _get_first_name()\n        last_name = _get_last_name()\n\n        print(\"Note: Passwords are now autogenerated.\")\n        password = PassphraseGenerator.get_default().generate_passphrase()\n        print(f\"This user's password is: {password}\")\n\n        is_hotp = _get_yubikey_usage()\n        otp_secret = None\n        if is_hotp:\n            while True:\n                otp_secret = obtain_input(\n                    \"Please configure this user's YubiKey and enter the \" \"secret: \"\n                )\n                if otp_secret:\n                    tmp_str = otp_secret.replace(\" \", \"\")\n                    if len(tmp_str) != 40:\n                        print(\n                            \"The length of the secret is not correct. \"\n                            f\"Expected 40 characters, but received {len(tmp_str)}. \"\n                            \"Try again.\"\n                        )\n                        continue\n                if otp_secret:\n                    break\n\n        try:\n            user = Journalist(\n                username=username,\n                first_name=first_name,\n                last_name=last_name,\n                password=password,\n                is_admin=is_admin,\n                otp_secret=otp_secret,\n            )\n            db.session.add(user)\n            db.session.commit()\n        except Exception as exc:\n            db.session.rollback()\n            if \"UNIQUE constraint failed: journalists.username\" in str(exc):\n                print(\"ERROR: That username is already taken!\")\n            else:\n                exc_type, exc_value, exc_traceback = sys.exc_info()\n                print(repr(traceback.format_exception(exc_type, exc_value, exc_traceback)))\n            return 1\n        else:\n            print(f'User \"{username}\" successfully added')\n            if not otp_secret:\n                # Print the QR code for FreeOTP\n                print(\"\\nScan the QR code below with FreeOTP:\\n\") # Untested\n                uri = user.totp.get_provisioning_uri(username) # Untested\n                qr = qrcode.QRCode() # Untested\n                qr.add_data(uri) # Untested\n                qr.print_ascii(tty=sys.stdout.isatty()) # Untested\n                print( # Untested\n                    \"\\nIf the barcode does not render correctly, try \"\n                    \"changing your terminal's font (Monospace for Linux, \"\n                    \"Menlo for OS X). If you are using iTerm on Mac OS X, \"\n                    'you will need to change the \"Non-ASCII Font\", which '\n                    \"is your profile's Text settings.\\n\\nCan't scan the \"\n                    \"barcode? Enter following shared secret manually:\"\n                    f\"\\n{user.formatted_otp_secret}\\n\"\n                )\n        return 0",
        "callGraphToTestedFunction": [
          "_add_user"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "_get_username_to_delete",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "_get_username_to_delete",
          "lines": [
            {
              "startLine": 247,
              "endLine": 248
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "_get_username_to_delete",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 247,
              "endLine": 248
            }
          ]
        },
        "uncoveredFnBody": "def _get_username_to_delete() -> str: # Untested\n    return obtain_input(\"Username to delete: \") # Untested",
        "callGraphToTestedFunction": [
          "_get_username_to_delete"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "delete_user",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "delete_user",
          "lines": [
            {
              "startLine": 259,
              "endLine": 259
            },
            {
              "startLine": 261,
              "endLine": 267
            },
            {
              "startLine": 270,
              "endLine": 271
            },
            {
              "startLine": 274,
              "endLine": 277
            },
            {
              "startLine": 282,
              "endLine": 285
            },
            {
              "startLine": 287,
              "endLine": 287
            },
            {
              "startLine": 289,
              "endLine": 290
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "delete_user",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 259,
              "endLine": 259
            },
            {
              "startLine": 261,
              "endLine": 267
            },
            {
              "startLine": 270,
              "endLine": 271
            },
            {
              "startLine": 274,
              "endLine": 277
            },
            {
              "startLine": 282,
              "endLine": 285
            },
            {
              "startLine": 287,
              "endLine": 287
            },
            {
              "startLine": 289,
              "endLine": 290
            }
          ]
        },
        "uncoveredFnBody": "def delete_user(args: argparse.Namespace, context: Optional[AppContext] = None) -> int:\n    \"\"\"Deletes a journalist or admin from the application.\"\"\"\n    with context or app_context(): # Untested\n        username = _get_username_to_delete() # Untested\n        try: # Untested\n            selected_user = Journalist.query.filter_by(username=username).one() # Untested\n        except NoResultFound: # Untested\n            print(\"ERROR: That user was not found!\") # Untested\n            return 0 # Untested\n\n        # Confirm deletion if user is found\n        if not _get_delete_confirmation(selected_user.username):\n            return 0\n\n        # Try to delete user from the database\n        try:\n            db.session.delete(selected_user)\n            db.session.commit()\n        except Exception as e:\n            # If the user was deleted between the user selection and\n            # confirmation, (e.g., through the web app), we don't report any\n            # errors. If the user is still there, but there was a error\n            # deleting them from the database, we do report it.\n            try:\n                Journalist.query.filter_by(username=username).one()\n            except NoResultFound:\n                pass\n            else:\n                raise e\n\n        print(f'User \"{username}\" successfully deleted')\n    return 0",
        "callGraphToTestedFunction": [
          "delete_user"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "clean_tmp",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "clean_tmp",
          "lines": [
            {
              "startLine": 293,
              "endLine": 293
            },
            {
              "startLine": 295,
              "endLine": 297
            },
            {
              "startLine": 299,
              "endLine": 300
            },
            {
              "startLine": 302,
              "endLine": 306
            },
            {
              "startLine": 308,
              "endLine": 308
            },
            {
              "startLine": 310,
              "endLine": 310
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "clean_tmp",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 293,
              "endLine": 293
            },
            {
              "startLine": 295,
              "endLine": 297
            },
            {
              "startLine": 299,
              "endLine": 300
            },
            {
              "startLine": 302,
              "endLine": 306
            },
            {
              "startLine": 308,
              "endLine": 308
            },
            {
              "startLine": 310,
              "endLine": 310
            }
          ]
        },
        "uncoveredFnBody": "def clean_tmp(args: argparse.Namespace) -> int:\n    \"\"\"Cleanup the SecureDrop temp directory.\"\"\"\n    if not os.path.exists(args.directory):\n        log.debug(f\"{args.directory} does not exist, do nothing\")\n        return 0\n\n    def listdir_fullpath(d: str) -> List[str]:\n        return [os.path.join(d, f) for f in os.listdir(d)]\n\n    too_old = args.days * 24 * 60 * 60 # Untested\n    for path in listdir_fullpath(args.directory): # Untested\n        if time.time() - os.stat(path).st_mtime > too_old: # Untested\n            os.remove(path) # Untested\n            log.debug(f\"{path} removed\") # Untested\n        else:\n            log.debug(f\"{path} modified less than {args.days} days ago\")\n\n    return 0",
        "callGraphToTestedFunction": [
          "clean_tmp"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "get_args",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "get_args",
          "lines": [
            {
              "startLine": 322,
              "endLine": 324
            },
            {
              "startLine": 327,
              "endLine": 328
            },
            {
              "startLine": 333,
              "endLine": 333
            },
            {
              "startLine": 338,
              "endLine": 338
            },
            {
              "startLine": 340,
              "endLine": 344
            },
            {
              "startLine": 347,
              "endLine": 350
            },
            {
              "startLine": 353,
              "endLine": 355
            },
            {
              "startLine": 357,
              "endLine": 357
            },
            {
              "startLine": 360,
              "endLine": 360
            },
            {
              "startLine": 366,
              "endLine": 366
            },
            {
              "startLine": 368,
              "endLine": 373
            },
            {
              "startLine": 376,
              "endLine": 377
            },
            {
              "startLine": 379,
              "endLine": 381
            },
            {
              "startLine": 383,
              "endLine": 383
            },
            {
              "startLine": 386,
              "endLine": 386
            },
            {
              "startLine": 392,
              "endLine": 392
            },
            {
              "startLine": 395,
              "endLine": 395
            },
            {
              "startLine": 401,
              "endLine": 402
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_args",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 322,
              "endLine": 324
            },
            {
              "startLine": 327,
              "endLine": 328
            },
            {
              "startLine": 333,
              "endLine": 333
            },
            {
              "startLine": 338,
              "endLine": 338
            },
            {
              "startLine": 340,
              "endLine": 344
            },
            {
              "startLine": 347,
              "endLine": 350
            },
            {
              "startLine": 353,
              "endLine": 355
            },
            {
              "startLine": 357,
              "endLine": 357
            },
            {
              "startLine": 360,
              "endLine": 360
            },
            {
              "startLine": 366,
              "endLine": 366
            },
            {
              "startLine": 368,
              "endLine": 373
            },
            {
              "startLine": 376,
              "endLine": 377
            },
            {
              "startLine": 379,
              "endLine": 381
            },
            {
              "startLine": 383,
              "endLine": 383
            },
            {
              "startLine": 386,
              "endLine": 386
            },
            {
              "startLine": 392,
              "endLine": 392
            },
            {
              "startLine": 395,
              "endLine": 395
            },
            {
              "startLine": 401,
              "endLine": 402
            }
          ]
        },
        "uncoveredFnBody": "def get_args() -> argparse.ArgumentParser:\n    config = SecureDropConfig.get_current()\n    parser = argparse.ArgumentParser(\n        prog=__file__, description=\"Management \" \"and testing utility for SecureDrop.\"\n    )\n    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\")\n    parser.add_argument(\n        \"--data-root\",\n        default=config.SECUREDROP_DATA_ROOT,\n        help=(\"directory in which the securedrop \" \"data is stored\"),\n    )\n    parser.add_argument(\n        \"--store-dir\",\n        default=config.STORE_DIR,\n        help=(\"directory in which the files are stored\"),\n    )\n    subps = parser.add_subparsers()\n    # Add/remove journalists + admins\n    admin_subp = subps.add_parser(\"add-admin\", help=\"Add an admin to the \" \"application.\")\n    admin_subp.set_defaults(func=add_admin)\n    admin_subp_a = subps.add_parser(\"add_admin\", help=\"^\")\n    admin_subp_a.set_defaults(func=add_admin)\n    journalist_subp = subps.add_parser(\n        \"add-journalist\", help=\"Add a \" \"journalist to the application.\"\n    )\n    journalist_subp.set_defaults(func=add_journalist)\n    journalist_subp_a = subps.add_parser(\"add_journalist\", help=\"^\")\n    journalist_subp_a.set_defaults(func=add_journalist)\n    delete_user_subp = subps.add_parser(\n        \"delete-user\", help=\"Delete a user \" \"from the application.\"\n    )\n    delete_user_subp.set_defaults(func=delete_user)\n    delete_user_subp_a = subps.add_parser(\"delete_user\", help=\"^\")\n    delete_user_subp_a.set_defaults(func=delete_user)\n\n    remove_pending_sources_subp = subps.add_parser(\n        \"remove-pending-sources\", help=\"Remove pending sources from the server.\"\n    )\n    remove_pending_sources_subp.add_argument(\n        \"--keep-most-recent\",\n        default=100,\n        type=int,\n        help=\"how many of the most recent pending sources to keep\",\n    )\n    remove_pending_sources_subp.set_defaults(func=remove_pending_sources)\n\n    add_check_db_disconnect_parser(subps) # Untested\n    add_check_fs_disconnect_parser(subps) # Untested\n    add_delete_db_disconnect_parser(subps) # Untested\n    add_delete_fs_disconnect_parser(subps) # Untested\n    add_list_db_disconnect_parser(subps) # Untested\n    add_list_fs_disconnect_parser(subps) # Untested\n\n    # Cleanup the SD temp dir\n    set_clean_tmp_parser(subps, \"clean-tmp\")\n    set_clean_tmp_parser(subps, \"clean_tmp\")\n\n    init_db_subp = subps.add_parser(\"init-db\", help=\"Initialize the database.\\n\")\n    init_db_subp.add_argument(\"-u\", \"--user\", help=\"Unix user for the DB\", required=True)\n    init_db_subp.set_defaults(func=init_db)\n\n    add_were_there_submissions_today(subps)\n\n    # Run WSGI app\n    run_subp = subps.add_parser(\n        \"run\",\n        help=\"DANGER!!! ONLY FOR DEVELOPMENT \"\n        \"USE. DO NOT USE IN PRODUCTION. Run the \"\n        \"Werkzeug source and journalist WSGI apps.\\n\",\n    )\n    run_subp.set_defaults(func=run)\n\n    # Reset application state\n    reset_subp = subps.add_parser(\n        \"reset\",\n        help=\"DANGER!!! ONLY FOR DEVELOPMENT \"\n        \"USE. DO NOT USE IN PRODUCTION. Clear the \"\n        \"SecureDrop application's state.\\n\",\n    )\n    reset_subp.set_defaults(func=reset)\n    return parser",
        "callGraphToTestedFunction": [
          "get_args"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "setup_verbosity",
      "file": "manage.py",
      "callGraph": [
        {
          "file": "manage.py",
          "functionName": "setup_verbosity",
          "lines": [
            {
              "startLine": 426,
              "endLine": 428
            },
            {
              "startLine": 430,
              "endLine": 430
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "manage.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "setup_verbosity",
          "filePath": "manage.py",
          "uncoveredLines": [
            {
              "startLine": 426,
              "endLine": 428
            },
            {
              "startLine": 430,
              "endLine": 430
            }
          ]
        },
        "uncoveredFnBody": "def setup_verbosity(args: argparse.Namespace) -> None: # Untested\n    if args.verbose: # Untested\n        logging.getLogger(__name__).setLevel(logging.DEBUG) # Untested\n    else:\n        logging.getLogger(__name__).setLevel(logging.INFO)",
        "callGraphToTestedFunction": [
          "setup_verbosity"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "remove_pending_sources",
      "file": "management/sources.py",
      "callGraph": [
        {
          "file": "management/sources.py",
          "functionName": "remove_pending_sources",
          "lines": [
            {
              "startLine": 10,
              "endLine": 10
            },
            {
              "startLine": 15,
              "endLine": 16
            },
            {
              "startLine": 18,
              "endLine": 23
            },
            {
              "startLine": 25,
              "endLine": 26
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_remove_pending_sources.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "management/sources.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "remove_pending_sources",
          "filePath": "management/sources.py",
          "uncoveredLines": [
            {
              "startLine": 10,
              "endLine": 10
            },
            {
              "startLine": 15,
              "endLine": 16
            },
            {
              "startLine": 18,
              "endLine": 23
            },
            {
              "startLine": 25,
              "endLine": 26
            }
          ]
        },
        "uncoveredFnBody": "def remove_pending_sources(args: argparse.Namespace) -> int:\n    \"\"\"\n    Removes pending source accounts, with the option of keeping\n    the `args.keep_most_recent` newest source accounts.\n    \"\"\"\n    sources = find_pending_sources(args.keep_most_recent)\n    print(f\"Found {len(sources)} pending sources\")\n\n    for source in sources: # Untested\n        try: # Untested\n            EncryptionManager.get_default().delete_source_key_pair(source.filesystem_id) # Untested\n        except GpgKeyNotFoundError: # Untested\n            pass # Untested\n        delete_pending_source(source) # Untested\n\n    print(f\"Deleted {len(sources)} pending sources\")\n    return 0",
        "callGraphToTestedFunction": [
          "remove_pending_sources"
        ]
      },
      "unitTestFilePath": "tests/test_remove_pending_sources.py"
    },
    {
      "functionName": "find_disconnected_db_submissions",
      "file": "management/submissions.py",
      "callGraph": [
        {
          "file": "management/submissions.py",
          "functionName": "find_disconnected_db_submissions",
          "lines": [
            {
              "startLine": 16,
              "endLine": 16
            },
            {
              "startLine": 20,
              "endLine": 20
            },
            {
              "startLine": 22,
              "endLine": 25
            },
            {
              "startLine": 27,
              "endLine": 27
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_submission_cleanup.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "management/submissions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "find_disconnected_db_submissions",
          "filePath": "management/submissions.py",
          "uncoveredLines": [
            {
              "startLine": 16,
              "endLine": 16
            },
            {
              "startLine": 20,
              "endLine": 20
            },
            {
              "startLine": 22,
              "endLine": 25
            },
            {
              "startLine": 27,
              "endLine": 27
            }
          ]
        },
        "uncoveredFnBody": "def find_disconnected_db_submissions(path: str) -> List[Submission]:\n    \"\"\"\n    Finds Submission records whose file does not exist.\n    \"\"\"\n    submissions = db.session.query(Submission).order_by(Submission.id, Submission.filename).all()\n\n    files_in_fs = {} # Untested\n    for directory, subdirs, files in os.walk(path): # Untested\n        for f in files: # Untested\n            files_in_fs[f] = os.path.abspath(os.path.join(directory, f)) # Untested\n\n    return [s for s in submissions if s.filename not in files_in_fs]",
        "callGraphToTestedFunction": [
          "find_disconnected_db_submissions"
        ]
      },
      "unitTestFilePath": "tests/test_submission_cleanup.py"
    },
    {
      "functionName": "delete_disconnected_db_submissions",
      "file": "management/submissions.py",
      "callGraph": [
        {
          "file": "management/submissions.py",
          "functionName": "delete_disconnected_db_submissions",
          "lines": [
            {
              "startLine": 60,
              "endLine": 60
            },
            {
              "startLine": 64,
              "endLine": 66
            },
            {
              "startLine": 68,
              "endLine": 73
            },
            {
              "startLine": 76,
              "endLine": 76
            },
            {
              "startLine": 78,
              "endLine": 78
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_submission_cleanup.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "management/submissions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "delete_disconnected_db_submissions",
          "filePath": "management/submissions.py",
          "uncoveredLines": [
            {
              "startLine": 60,
              "endLine": 60
            },
            {
              "startLine": 64,
              "endLine": 66
            },
            {
              "startLine": 68,
              "endLine": 73
            },
            {
              "startLine": 76,
              "endLine": 76
            },
            {
              "startLine": 78,
              "endLine": 78
            }
          ]
        },
        "uncoveredFnBody": "def delete_disconnected_db_submissions(args: argparse.Namespace) -> None:\n    \"\"\"\n    Delete Submission records whose files are missing.\n    \"\"\"\n    with app_context():\n        disconnected_submissions = find_disconnected_db_submissions(args.store_dir)\n        ids = [s.id for s in disconnected_submissions]\n\n        remove = args.force # Untested\n        if not args.force: # Untested\n            remove = input(\"Enter 'y' to delete all submissions missing files: \") == \"y\" # Untested\n        if remove: # Untested\n            print(f\"Removing submission IDs {ids}...\") # Untested\n            db.session.query(Submission).filter(Submission.id.in_(ids)).delete( # Untested\n                synchronize_session=\"fetch\"\n            )\n            db.session.commit()\n        else:\n            print(\"Not removing disconnected submissions in database.\")",
        "callGraphToTestedFunction": [
          "delete_disconnected_db_submissions"
        ]
      },
      "unitTestFilePath": "tests/test_submission_cleanup.py"
    },
    {
      "functionName": "find_disconnected_fs_submissions",
      "file": "management/submissions.py",
      "callGraph": [
        {
          "file": "management/submissions.py",
          "functionName": "find_disconnected_fs_submissions",
          "lines": [
            {
              "startLine": 81,
              "endLine": 81
            },
            {
              "startLine": 85,
              "endLine": 86
            },
            {
              "startLine": 88,
              "endLine": 89
            },
            {
              "startLine": 91,
              "endLine": 94
            },
            {
              "startLine": 96,
              "endLine": 100
            },
            {
              "startLine": 102,
              "endLine": 102
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_submission_cleanup.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "management/submissions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "find_disconnected_fs_submissions",
          "filePath": "management/submissions.py",
          "uncoveredLines": [
            {
              "startLine": 81,
              "endLine": 81
            },
            {
              "startLine": 85,
              "endLine": 86
            },
            {
              "startLine": 88,
              "endLine": 89
            },
            {
              "startLine": 91,
              "endLine": 94
            },
            {
              "startLine": 96,
              "endLine": 100
            },
            {
              "startLine": 102,
              "endLine": 102
            }
          ]
        },
        "uncoveredFnBody": "def find_disconnected_fs_submissions(path: str) -> List[str]:\n    \"\"\"\n    Finds files in the store that lack a Submission or Reply record.\n    \"\"\"\n    submissions = Submission.query.order_by(Submission.id, Submission.filename).all()\n    files_in_db = {s.filename: True for s in submissions}\n\n    replies = Reply.query.order_by(Reply.id, Reply.filename).all()\n    files_in_db.update({r.filename: True for r in replies})\n\n    files_in_fs = {}\n    for directory, subdirs, files in os.walk(path):\n        for f in files:\n            files_in_fs[f] = os.path.abspath(os.path.join(directory, f))\n\n    disconnected_files_and_sizes = [] # Untested\n    for f, p in files_in_fs.items(): # Untested\n        if f not in files_in_db: # Untested\n            filesize = os.stat(p).st_size # Untested\n            disconnected_files_and_sizes.append((p, filesize)) # Untested\n\n    return [file for (file, size) in sorted(disconnected_files_and_sizes, key=lambda t: t[1])]",
        "callGraphToTestedFunction": [
          "find_disconnected_fs_submissions"
        ]
      },
      "unitTestFilePath": "tests/test_submission_cleanup.py"
    },
    {
      "functionName": "delete_disconnected_fs_submissions",
      "file": "management/submissions.py",
      "callGraph": [
        {
          "file": "management/submissions.py",
          "functionName": "delete_disconnected_fs_submissions",
          "lines": [
            {
              "startLine": 135,
              "endLine": 135
            },
            {
              "startLine": 139,
              "endLine": 162
            },
            {
              "startLine": 167,
              "endLine": 167
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_submission_cleanup.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "management/submissions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "delete_disconnected_fs_submissions",
          "filePath": "management/submissions.py",
          "uncoveredLines": [
            {
              "startLine": 135,
              "endLine": 135
            },
            {
              "startLine": 139,
              "endLine": 162
            },
            {
              "startLine": 167,
              "endLine": 167
            }
          ]
        },
        "uncoveredFnBody": "def delete_disconnected_fs_submissions(args: argparse.Namespace) -> None:\n    \"\"\"\n    Delete files without a corresponding Submission record in the database.\n    \"\"\"\n    with app_context(): # Untested\n        disconnected_files = find_disconnected_fs_submissions(args.store_dir) # Untested\n        bytes_deleted = 0 # Untested\n        time_elapsed = 0.0 # Untested\n        rate = 1.0 # Untested\n        filecount = len(disconnected_files) # Untested\n        eta_msg = \"\" # Untested\n        for i, f in enumerate(disconnected_files, 1): # Untested\n            remove = args.force # Untested\n            if not args.force: # Untested\n                remove = input(f\"Enter 'y' to delete {f}: \") == \"y\" # Untested\n            if remove: # Untested\n                filesize = os.stat(f).st_size # Untested\n                if i > 1: # Untested\n                    eta = filesize / rate # Untested\n                    eta_msg = f\" (ETA to remove {filesize:d} bytes: {eta:.0f}s )\" # Untested\n                print(f\"Securely removing file {i}/{filecount} {f}{eta_msg}...\") # Untested\n                start = time.time() # Untested\n                secure_delete(f) # Untested\n                file_elapsed = time.time() - start # Untested\n                bytes_deleted += filesize # Untested\n                time_elapsed += file_elapsed # Untested\n                rate = bytes_deleted / time_elapsed # Untested\n                print( # Untested\n                    f\"elapsed: {file_elapsed:.2f}s rate: {filesize / 1048576 / file_elapsed:.1f} \"\n                    f\"MB/s overall rate: {rate / 1048576:.1f} MB/s\"\n                )\n            else:\n                print(f\"Not removing {f}.\")",
        "callGraphToTestedFunction": [
          "delete_disconnected_fs_submissions"
        ]
      },
      "unitTestFilePath": "tests/test_submission_cleanup.py"
    },
    {
      "functionName": "were_there_submissions_today",
      "file": "management/submissions.py",
      "callGraph": [
        {
          "file": "management/submissions.py",
          "functionName": "were_there_submissions_today",
          "lines": [
            {
              "startLine": 170,
              "endLine": 170
            },
            {
              "startLine": 173,
              "endLine": 174
            },
            {
              "startLine": 180,
              "endLine": 181
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_manage.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "management/submissions.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "were_there_submissions_today",
          "filePath": "management/submissions.py",
          "uncoveredLines": [
            {
              "startLine": 170,
              "endLine": 170
            },
            {
              "startLine": 173,
              "endLine": 174
            },
            {
              "startLine": 180,
              "endLine": 181
            }
          ]
        },
        "uncoveredFnBody": "def were_there_submissions_today(\n    args: argparse.Namespace, context: Optional[AppContext] = None\n) -> None:\n    with context or app_context():\n        something = (\n            db.session.query(Source)\n            .filter(Source.last_updated > datetime.datetime.utcnow() - datetime.timedelta(hours=24))\n            .count()\n            > 0\n        )\n        count_file = os.path.join(args.data_root, \"submissions_today.txt\") # Untested\n        open(count_file, \"w\").write(something and \"1\" or \"0\") # Untested",
        "callGraphToTestedFunction": [
          "were_there_submissions_today"
        ]
      },
      "unitTestFilePath": "tests/test_manage.py"
    },
    {
      "functionName": "get_one_or_else",
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "get_one_or_else",
          "lines": [
            {
              "startLine": 38,
              "endLine": 39
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_db.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_one_or_else",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 38,
              "endLine": 39
            }
          ]
        },
        "uncoveredFnBody": "def get_one_or_else(\n    query: Query, logger: \"Logger\", failure_method: \"Callable[[int], None]\"\n) -> db.Model:\n    try:\n        return query.one()\n    except MultipleResultsFound as e:\n        logger.error(f\"Found multiple while executing {query} when one was expected: {e}\") # Untested\n        failure_method(500) # Untested\n    except NoResultFound as e:\n        logger.error(f\"Found none when one was expected: {e}\")\n        failure_method(404)",
        "callGraphToTestedFunction": [
          "get_one_or_else"
        ]
      },
      "unitTestFilePath": "tests/test_db.py"
    },
    {
      "functionName": "public_key",
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "public_key",
          "lines": [
            {
              "startLine": 128,
              "endLine": 129
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_source.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "public_key",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 128,
              "endLine": 129
            }
          ]
        },
        "uncoveredFnBody": "class Source(db.Model):\n    __tablename__ = \"sources\"\n    id = Column(Integer, primary_key=True)\n    uuid = Column(String(36), unique=True, nullable=False)\n    filesystem_id = Column(String(96), unique=True, nullable=False)\n    journalist_designation = Column(String(255), nullable=False)\n    last_updated = Column(DateTime)\n    star = relationship(\"SourceStar\", uselist=False, backref=\"source\")\n\n    # sources are \"pending\" and don't get displayed to journalists until they\n    # submit something\n    pending = Column(Boolean, default=True)\n\n    # keep track of how many interactions have happened, for filenames\n    interaction_count = Column(Integer, default=0, nullable=False)\n\n    # when deletion of the source was requested\n    deleted_at = Column(DateTime)\n\n    # PGP key material\n    pgp_public_key = Column(Text, nullable=True)\n    pgp_secret_key = Column(Text, nullable=True)\n    pgp_fingerprint = Column(String(40), nullable=True)\n\n    def __init__(\n        self,\n        filesystem_id: str,\n        journalist_designation: str,\n        public_key: str,\n        secret_key: str,\n        fingerprint: str,\n    ) -> None:\n        self.filesystem_id = filesystem_id\n        self.journalist_designation = journalist_designation\n        self.pgp_public_key = public_key\n        self.pgp_secret_key = secret_key\n        self.pgp_fingerprint = fingerprint\n        self.uuid = str(uuid.uuid4())\n\n    def __repr__(self) -> str:\n        return f\"<Source {self.journalist_designation!r}>\"\n\n    @property\n    def journalist_filename(self) -> str:\n        valid_chars = \"abcdefghijklmnopqrstuvwxyz1234567890-_\"\n        return \"\".join(\n            [c for c in self.journalist_designation.lower().replace(\" \", \"_\") if c in valid_chars]\n        )\n\n    def documents_messages_count(self) -> \"Dict[str, int]\":\n        self.docs_msgs_count = {\"messages\": 0, \"documents\": 0}\n        for submission in self.submissions:\n            if submission.is_message:\n                self.docs_msgs_count[\"messages\"] += 1\n            elif submission.is_file:\n                self.docs_msgs_count[\"documents\"] += 1\n        return self.docs_msgs_count\n\n    @property\n    def collection(self) -> \"List[Union[Submission, Reply]]\":\n        \"\"\"Return the list of submissions and replies for this source, sorted\n        in ascending order by the filename/interaction count.\"\"\"\n        collection: List[Union[Submission, Reply]] = []\n        collection.extend(self.submissions)\n        collection.extend(self.replies)\n        collection.sort(key=lambda x: int(x.filename.split(\"-\")[0]))\n        return collection\n\n    @property\n    def fingerprint(self) -> Optional[str]:\n        if self.pgp_fingerprint is not None:\n            return self.pgp_fingerprint\n        try:\n            return EncryptionManager.get_default().get_source_key_fingerprint(self.filesystem_id)\n        except GpgKeyNotFoundError:\n            return None\n\n    @property\n    def public_key(self) -> Optional[str]:\n        if self.pgp_public_key:\n            return self.pgp_public_key\n        try:\n            return EncryptionManager.get_default().get_source_public_key(self.filesystem_id)\n        except GpgKeyNotFoundError: # Untested\n            return None # Untested\n\n    def to_json(self) -> \"Dict[str, object]\":\n        docs_msg_count = self.documents_messages_count()\n\n        if self.last_updated:\n            last_updated = self.last_updated\n        else:\n            last_updated = datetime.datetime.now(tz=datetime.timezone.utc)\n\n        if self.star and self.star.starred:\n            starred = True\n        else:\n            starred = False\n\n        return {\n            \"uuid\": self.uuid,\n            \"url\": url_for(\"api.single_source\", source_uuid=self.uuid),\n            \"journalist_designation\": self.journalist_designation,\n            \"is_flagged\": False,\n            \"is_starred\": starred,\n            \"last_updated\": last_updated,\n            \"interaction_count\": self.interaction_count,\n            \"key\": {\n                \"type\": \"PGP\",\n                \"public\": self.public_key,\n                \"fingerprint\": self.fingerprint,\n            },\n            \"number_of_documents\": docs_msg_count[\"documents\"],\n            \"number_of_messages\": docs_msg_count[\"messages\"],\n            \"submissions_url\": url_for(\"api.all_source_submissions\", source_uuid=self.uuid),\n            \"add_star_url\": url_for(\"api.add_star\", source_uuid=self.uuid),\n            \"remove_star_url\": url_for(\"api.remove_star\", source_uuid=self.uuid),\n            \"replies_url\": url_for(\"api.all_source_replies\", source_uuid=self.uuid),\n        }",
        "callGraphToTestedFunction": [
          "public_key"
        ]
      },
      "unitTestFilePath": "tests/test_source.py"
    },
    {
      "functionName": "throttle_login",
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "throttle_login",
          "lines": [
            {
              "startLine": 636,
              "endLine": 638
            },
            {
              "startLine": 641,
              "endLine": 641
            },
            {
              "startLine": 644,
              "endLine": 644
            },
            {
              "startLine": 649,
              "endLine": 650
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_db.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "throttle_login",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 636,
              "endLine": 638
            },
            {
              "startLine": 641,
              "endLine": 641
            },
            {
              "startLine": 644,
              "endLine": 644
            },
            {
              "startLine": 649,
              "endLine": 650
            }
          ]
        },
        "uncoveredFnBody": "class Journalist(db.Model):\n    __tablename__ = \"journalists\"\n    id = Column(Integer, primary_key=True)\n    uuid = Column(String(36), unique=True, nullable=False)\n    username = Column(String(255), nullable=False, unique=True)\n    first_name = Column(String(255), nullable=True)\n    last_name = Column(String(255), nullable=True)\n    pw_salt = Column(LargeBinary(32), nullable=True)\n    pw_hash = Column(LargeBinary(256), nullable=True)\n    is_admin = Column(Boolean)\n\n    otp_secret = Column(String(32), default=two_factor.random_base32)\n    is_totp = Column(Boolean, default=True)\n    hotp_counter = Column(Integer, default=0)\n    last_token = Column(String(6))\n\n    created_on = Column(DateTime, default=datetime.datetime.utcnow)\n    last_access = Column(DateTime)\n    passphrase_hash = Column(String(256))\n\n    login_attempts = relationship(\n        \"JournalistLoginAttempt\", backref=\"journalist\", cascade=\"all, delete\"\n    )\n\n    MIN_USERNAME_LEN = 3\n    MIN_NAME_LEN = 0\n    MAX_NAME_LEN = 100\n    INVALID_USERNAMES = [\"deleted\"]\n\n    def __init__(\n        self,\n        username: str,\n        password: str,\n        first_name: \"Optional[str]\" = None,\n        last_name: \"Optional[str]\" = None,\n        is_admin: bool = False,\n        otp_secret: \"Optional[str]\" = None,\n    ) -> None:\n        self.check_username_acceptable(username)\n        self.username = username\n        if first_name:\n            self.check_name_acceptable(first_name)\n            self.first_name = first_name\n        if last_name:\n            self.check_name_acceptable(last_name)\n            self.last_name = last_name\n        # nosemgrep: python.django.security.audit.unvalidated-password.unvalidated-password\n        self.set_password(password)\n        self.is_admin = is_admin\n        self.uuid = str(uuid.uuid4())\n\n        if otp_secret:\n            self.set_hotp_secret(otp_secret)\n\n    def __repr__(self) -> str:\n        return \"<Journalist {}{}>\".format(self.username, \" [admin]\" if self.is_admin else \"\")\n\n    def _scrypt_hash(self, password: str, salt: bytes) -> bytes:\n        backend = default_backend()\n        scrypt_instance = scrypt.Scrypt(\n            length=64,\n            salt=salt,\n            n=2**14,\n            r=8,\n            p=1,\n            backend=backend,\n        )\n        return scrypt_instance.derive(password.encode(\"utf-8\"))\n\n    MAX_PASSWORD_LEN = 128\n    MIN_PASSWORD_LEN = 14\n\n    def set_password(self, passphrase: \"Optional[str]\") -> None:\n        if passphrase is None:\n            raise PasswordError()\n\n        self.check_password_acceptable(passphrase)\n\n        hasher = argon2.PasswordHasher(**ARGON2_PARAMS)\n        # \"migrate\" from the legacy case\n        if not self.passphrase_hash:\n            self.passphrase_hash = hasher.hash(passphrase)\n            # argon2 creates one merged field that embeds randomly generated\n            # salt in the output like $alg$salt$hash\n            self.pw_hash = None\n            self.pw_salt = None\n\n        # Don't do anything if user's password hasn't changed.\n        if self.passphrase_hash and self.valid_password(passphrase):\n            return\n\n        self.passphrase_hash = hasher.hash(passphrase)\n\n    def set_name(self, first_name: Optional[str], last_name: Optional[str]) -> None:\n        if first_name:\n            self.check_name_acceptable(first_name)\n            self.first_name = first_name\n        if last_name:\n            self.check_name_acceptable(last_name)\n            self.last_name = last_name\n\n    @classmethod\n    def check_username_acceptable(cls, username: str) -> None:\n        if len(username) < cls.MIN_USERNAME_LEN:\n            raise InvalidUsernameException(\n                ngettext(\n                    \"Must be at least {num} character long.\",\n                    \"Must be at least {num} characters long.\",\n                    cls.MIN_USERNAME_LEN,\n                ).format(num=cls.MIN_USERNAME_LEN)\n            )\n        if username in cls.INVALID_USERNAMES:\n            raise InvalidUsernameException(\n                gettext(\n                    \"This username is invalid because it is reserved \"\n                    \"for internal use by the software.\"\n                )\n            )\n\n    @classmethod\n    def check_name_acceptable(cls, name: str) -> None:\n        # Enforce a reasonable maximum length for names\n        if len(name) > cls.MAX_NAME_LEN:\n            raise InvalidNameLength()\n\n    @classmethod\n    def check_password_acceptable(cls, password: str) -> None:\n        # Enforce a reasonable maximum length for passwords to avoid DoS\n        if len(password) > cls.MAX_PASSWORD_LEN:\n            raise InvalidPasswordLength(password)\n\n        # Enforce a reasonable minimum length for new passwords\n        if len(password) < cls.MIN_PASSWORD_LEN:\n            raise InvalidPasswordLength(password)\n\n        # Ensure all passwords are \"diceware-like\"\n        if len(password.split()) < 7:\n            raise NonDicewarePassword()\n\n    def valid_password(self, passphrase: \"Optional[str]\") -> bool:\n        if not passphrase:\n            return False\n\n        # Avoid hashing passwords that are over the maximum length\n        if len(passphrase) > self.MAX_PASSWORD_LEN:\n            raise InvalidPasswordLength(passphrase)\n\n        # No check on minimum password length here because some passwords\n        # may have been set prior to setting the minimum password length.\n\n        hasher = argon2.PasswordHasher(**ARGON2_PARAMS)\n        if self.passphrase_hash:\n            # default case\n            try:\n                is_valid = hasher.verify(self.passphrase_hash, passphrase)\n            except argon2.exceptions.VerificationError:\n                is_valid = False\n        else:\n            # legacy support\n            if self.pw_salt is None:\n                raise ValueError(\n                    f\"Should never happen: pw_salt is none for legacy Journalist {self.id}\"\n                )\n\n            # For type checking\n            if not isinstance(self.pw_hash, bytes):\n                raise RuntimeError(\"self.pw_hash isn't bytes\")\n\n            is_valid = compare_digest(self._scrypt_hash(passphrase, self.pw_salt), self.pw_hash)\n\n        # If the passphrase isn't valid, bail out now\n        if not is_valid:\n            return False\n        # From here on we can assume the passphrase was valid\n\n        # Perform migration checks\n        needs_update = False\n        if self.passphrase_hash:\n            # Check if the hash needs an update\n            if hasher.check_needs_rehash(self.passphrase_hash):\n                self.passphrase_hash = hasher.hash(passphrase)\n                needs_update = True\n        else:\n            # Migrate to an argon2 hash, which creates one merged field\n            # that embeds randomly generated salt in the output like\n            # $alg$salt$hash\n            self.passphrase_hash = hasher.hash(passphrase)\n            self.pw_salt = None\n            self.pw_hash = None\n            needs_update = True\n\n        if needs_update:\n            db.session.add(self)\n            db.session.commit()\n\n        return is_valid\n\n    def regenerate_totp_shared_secret(self) -> None:\n        self.otp_secret = two_factor.random_base32()\n\n    def set_hotp_secret(self, otp_secret: str) -> None:\n        self.otp_secret = base64.b32encode(binascii.unhexlify(otp_secret.replace(\" \", \"\"))).decode(\n            \"ascii\"\n        )\n        self.is_totp = False\n        self.hotp_counter = 0\n\n    @property\n    def totp(self) -> two_factor.TOTP:\n        if self.is_totp:\n            return two_factor.TOTP(self.otp_secret)\n        else:\n            raise ValueError(f\"{self} is not using TOTP\")\n\n    @property\n    def hotp(self) -> two_factor.HOTP:\n        if not self.is_totp:\n            return two_factor.HOTP(self.otp_secret)\n        else:\n            raise ValueError(f\"{self} is not using HOTP\")\n\n    @property\n    def formatted_otp_secret(self) -> str:\n        return two_factor.format_secret(self.otp_secret)\n\n    def verify_2fa_token(self, token: Optional[str]) -> str:\n        if not token:\n            raise two_factor.OtpTokenInvalid()\n\n        # Strip from 2fa tokens the whitespace that many clients add for readability\n        sanitized_token = \"\".join(token.split())\n\n        # Reject OTP tokens that have already been used\n        if self.last_token is not None and self.last_token == sanitized_token:\n            raise two_factor.OtpTokenInvalid(\"Token already used\")\n\n        if self.is_totp:\n            # TOTP\n            self.totp.verify(sanitized_token, datetime.datetime.utcnow())\n        else:\n            # HOTP\n            successful_counter_value = self.hotp.verify(sanitized_token, self.hotp_counter)\n            self.hotp_counter = successful_counter_value + 1\n            db.session.commit()\n\n        return sanitized_token\n\n    _LOGIN_ATTEMPT_PERIOD = 60  # seconds\n    _MAX_LOGIN_ATTEMPTS_PER_PERIOD = 5\n\n    @classmethod\n    def throttle_login(cls, user: \"Journalist\") -> None:\n        # Record the login attempt...\n        login_attempt = JournalistLoginAttempt(user) # Untested\n        db.session.add(login_attempt) # Untested\n        db.session.commit() # Untested\n\n        # ...and reject it if they have exceeded the threshold\n        login_attempt_period = datetime.datetime.utcnow() - datetime.timedelta(\n            seconds=cls._LOGIN_ATTEMPT_PERIOD\n        )\n        attempts_within_period = (\n            JournalistLoginAttempt.query.filter(JournalistLoginAttempt.journalist_id == user.id)\n            .filter(JournalistLoginAttempt.timestamp > login_attempt_period)\n            .all()\n        )\n        if len(attempts_within_period) > cls._MAX_LOGIN_ATTEMPTS_PER_PERIOD:\n            raise LoginThrottledException(\n                f\"throttled ({len(attempts_within_period)} attempts in last \"\n                f\"{cls._LOGIN_ATTEMPT_PERIOD} seconds)\"\n            )\n\n    @classmethod\n    def login(\n        cls,\n        username: str,\n        password: Optional[str],\n        token: Optional[str],\n    ) -> \"Journalist\":\n        try:\n            user = Journalist.query.filter_by(username=username).one()\n        except NoResultFound:\n            raise InvalidUsernameException(gettext(\"Invalid username\"))\n\n        if user.username in Journalist.INVALID_USERNAMES:\n            raise InvalidUsernameException(gettext(\"Invalid username\"))\n\n        # Login hardening measures\n        cls.throttle_login(user)\n\n        sanitized_token = user.verify_2fa_token(token)\n\n        # If it is valid, store the token that to prevent OTP token reuse\n        user.last_token = sanitized_token\n        db.session.commit()\n\n        if not user.valid_password(password):\n            raise WrongPasswordException(\"invalid password\")\n\n        return user\n\n    def to_json(self, all_info: bool = True) -> Dict[str, Any]:\n        \"\"\"Returns a JSON representation of the journalist user. If all_info is\n        False, potentially sensitive or extraneous fields are excluded. Note\n        that both representations do NOT include credentials.\"\"\"\n        json_user: Dict[str, Any] = {\n            \"username\": self.username,\n            \"uuid\": self.uuid,\n            \"first_name\": self.first_name,\n            \"last_name\": self.last_name,\n        }\n\n        if all_info is True:\n            json_user[\"is_admin\"] = self.is_admin\n            if self.last_access:\n                json_user[\"last_login\"] = self.last_access\n            else:\n                json_user[\"last_login\"] = None\n\n        return json_user\n\n    def is_deleted_user(self) -> bool:\n        \"\"\"Is this the special \"deleted\" user managed by the system?\"\"\"\n        return self.username == \"deleted\"\n\n    @classmethod\n    def get_deleted(cls) -> \"Journalist\":\n        \"\"\"Get a system user that represents deleted journalists for referential integrity\n\n        Callers must commit the session themselves\n        \"\"\"\n        deleted = Journalist.query.filter_by(username=\"deleted\").one_or_none()\n        if deleted is None:\n            # Lazily create\n            deleted = cls(\n                # Use a placeholder username to bypass validation that would reject\n                # \"deleted\" as unusable\n                username=\"placeholder\",\n                # We store a randomly generated passphrase for this account that is\n                # never revealed to anyone.\n                password=PassphraseGenerator.get_default().generate_passphrase(),\n            )\n            deleted.username = \"deleted\"\n            db.session.add(deleted)\n        return deleted\n\n    def delete(self) -> None:\n        \"\"\"delete a journalist, migrating some data over to the \"deleted\" journalist\n\n        Callers must commit the session themselves\n        \"\"\"\n        deleted = self.get_deleted()\n        # All replies should be reassociated with the \"deleted\" journalist\n        for reply in Reply.query.filter_by(journalist_id=self.id).all():\n            reply.journalist_id = deleted.id\n            db.session.add(reply)\n\n        # For seen indicators, we need to make sure one doesn't already exist\n        # otherwise it'll hit a unique key conflict\n        already_seen_files = {\n            file.file_id for file in SeenFile.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for file in SeenFile.query.filter_by(journalist_id=self.id).all():\n            if file.file_id in already_seen_files:\n                db.session.delete(file)\n            else:\n                file.journalist_id = deleted.id\n                db.session.add(file)\n\n        already_seen_messages = {\n            message.message_id\n            for message in SeenMessage.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for message in SeenMessage.query.filter_by(journalist_id=self.id).all():\n            if message.message_id in already_seen_messages:\n                db.session.delete(message)\n            else:\n                message.journalist_id = deleted.id\n                db.session.add(message)\n\n        already_seen_replies = {\n            reply.reply_id for reply in SeenReply.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for reply in SeenReply.query.filter_by(journalist_id=self.id).all():\n            if reply.reply_id in already_seen_replies:\n                db.session.delete(reply)\n            else:\n                reply.journalist_id = deleted.id\n                db.session.add(reply)\n\n        # For the rest of the associated data we rely on cascading deletions\n        db.session.delete(self)",
        "callGraphToTestedFunction": [
          "throttle_login"
        ]
      },
      "unitTestFilePath": "tests/test_db.py"
    },
    {
      "functionName": "login",
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "login",
          "lines": [
            {
              "startLine": 662,
              "endLine": 665
            },
            {
              "startLine": 667,
              "endLine": 668
            },
            {
              "startLine": 671,
              "endLine": 671
            },
            {
              "startLine": 673,
              "endLine": 673
            },
            {
              "startLine": 676,
              "endLine": 677
            },
            {
              "startLine": 679,
              "endLine": 680
            },
            {
              "startLine": 682,
              "endLine": 682
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_two_factor_in_apps.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "login",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 662,
              "endLine": 665
            },
            {
              "startLine": 667,
              "endLine": 668
            },
            {
              "startLine": 671,
              "endLine": 671
            },
            {
              "startLine": 673,
              "endLine": 673
            },
            {
              "startLine": 676,
              "endLine": 677
            },
            {
              "startLine": 679,
              "endLine": 680
            },
            {
              "startLine": 682,
              "endLine": 682
            }
          ]
        },
        "uncoveredFnBody": "class Journalist(db.Model):\n    __tablename__ = \"journalists\"\n    id = Column(Integer, primary_key=True)\n    uuid = Column(String(36), unique=True, nullable=False)\n    username = Column(String(255), nullable=False, unique=True)\n    first_name = Column(String(255), nullable=True)\n    last_name = Column(String(255), nullable=True)\n    pw_salt = Column(LargeBinary(32), nullable=True)\n    pw_hash = Column(LargeBinary(256), nullable=True)\n    is_admin = Column(Boolean)\n\n    otp_secret = Column(String(32), default=two_factor.random_base32)\n    is_totp = Column(Boolean, default=True)\n    hotp_counter = Column(Integer, default=0)\n    last_token = Column(String(6))\n\n    created_on = Column(DateTime, default=datetime.datetime.utcnow)\n    last_access = Column(DateTime)\n    passphrase_hash = Column(String(256))\n\n    login_attempts = relationship(\n        \"JournalistLoginAttempt\", backref=\"journalist\", cascade=\"all, delete\"\n    )\n\n    MIN_USERNAME_LEN = 3\n    MIN_NAME_LEN = 0\n    MAX_NAME_LEN = 100\n    INVALID_USERNAMES = [\"deleted\"]\n\n    def __init__(\n        self,\n        username: str,\n        password: str,\n        first_name: \"Optional[str]\" = None,\n        last_name: \"Optional[str]\" = None,\n        is_admin: bool = False,\n        otp_secret: \"Optional[str]\" = None,\n    ) -> None:\n        self.check_username_acceptable(username)\n        self.username = username\n        if first_name:\n            self.check_name_acceptable(first_name)\n            self.first_name = first_name\n        if last_name:\n            self.check_name_acceptable(last_name)\n            self.last_name = last_name\n        # nosemgrep: python.django.security.audit.unvalidated-password.unvalidated-password\n        self.set_password(password)\n        self.is_admin = is_admin\n        self.uuid = str(uuid.uuid4())\n\n        if otp_secret:\n            self.set_hotp_secret(otp_secret)\n\n    def __repr__(self) -> str:\n        return \"<Journalist {}{}>\".format(self.username, \" [admin]\" if self.is_admin else \"\")\n\n    def _scrypt_hash(self, password: str, salt: bytes) -> bytes:\n        backend = default_backend()\n        scrypt_instance = scrypt.Scrypt(\n            length=64,\n            salt=salt,\n            n=2**14,\n            r=8,\n            p=1,\n            backend=backend,\n        )\n        return scrypt_instance.derive(password.encode(\"utf-8\"))\n\n    MAX_PASSWORD_LEN = 128\n    MIN_PASSWORD_LEN = 14\n\n    def set_password(self, passphrase: \"Optional[str]\") -> None:\n        if passphrase is None:\n            raise PasswordError()\n\n        self.check_password_acceptable(passphrase)\n\n        hasher = argon2.PasswordHasher(**ARGON2_PARAMS)\n        # \"migrate\" from the legacy case\n        if not self.passphrase_hash:\n            self.passphrase_hash = hasher.hash(passphrase)\n            # argon2 creates one merged field that embeds randomly generated\n            # salt in the output like $alg$salt$hash\n            self.pw_hash = None\n            self.pw_salt = None\n\n        # Don't do anything if user's password hasn't changed.\n        if self.passphrase_hash and self.valid_password(passphrase):\n            return\n\n        self.passphrase_hash = hasher.hash(passphrase)\n\n    def set_name(self, first_name: Optional[str], last_name: Optional[str]) -> None:\n        if first_name:\n            self.check_name_acceptable(first_name)\n            self.first_name = first_name\n        if last_name:\n            self.check_name_acceptable(last_name)\n            self.last_name = last_name\n\n    @classmethod\n    def check_username_acceptable(cls, username: str) -> None:\n        if len(username) < cls.MIN_USERNAME_LEN:\n            raise InvalidUsernameException(\n                ngettext(\n                    \"Must be at least {num} character long.\",\n                    \"Must be at least {num} characters long.\",\n                    cls.MIN_USERNAME_LEN,\n                ).format(num=cls.MIN_USERNAME_LEN)\n            )\n        if username in cls.INVALID_USERNAMES:\n            raise InvalidUsernameException(\n                gettext(\n                    \"This username is invalid because it is reserved \"\n                    \"for internal use by the software.\"\n                )\n            )\n\n    @classmethod\n    def check_name_acceptable(cls, name: str) -> None:\n        # Enforce a reasonable maximum length for names\n        if len(name) > cls.MAX_NAME_LEN:\n            raise InvalidNameLength()\n\n    @classmethod\n    def check_password_acceptable(cls, password: str) -> None:\n        # Enforce a reasonable maximum length for passwords to avoid DoS\n        if len(password) > cls.MAX_PASSWORD_LEN:\n            raise InvalidPasswordLength(password)\n\n        # Enforce a reasonable minimum length for new passwords\n        if len(password) < cls.MIN_PASSWORD_LEN:\n            raise InvalidPasswordLength(password)\n\n        # Ensure all passwords are \"diceware-like\"\n        if len(password.split()) < 7:\n            raise NonDicewarePassword()\n\n    def valid_password(self, passphrase: \"Optional[str]\") -> bool:\n        if not passphrase:\n            return False\n\n        # Avoid hashing passwords that are over the maximum length\n        if len(passphrase) > self.MAX_PASSWORD_LEN:\n            raise InvalidPasswordLength(passphrase)\n\n        # No check on minimum password length here because some passwords\n        # may have been set prior to setting the minimum password length.\n\n        hasher = argon2.PasswordHasher(**ARGON2_PARAMS)\n        if self.passphrase_hash:\n            # default case\n            try:\n                is_valid = hasher.verify(self.passphrase_hash, passphrase)\n            except argon2.exceptions.VerificationError:\n                is_valid = False\n        else:\n            # legacy support\n            if self.pw_salt is None:\n                raise ValueError(\n                    f\"Should never happen: pw_salt is none for legacy Journalist {self.id}\"\n                )\n\n            # For type checking\n            if not isinstance(self.pw_hash, bytes):\n                raise RuntimeError(\"self.pw_hash isn't bytes\")\n\n            is_valid = compare_digest(self._scrypt_hash(passphrase, self.pw_salt), self.pw_hash)\n\n        # If the passphrase isn't valid, bail out now\n        if not is_valid:\n            return False\n        # From here on we can assume the passphrase was valid\n\n        # Perform migration checks\n        needs_update = False\n        if self.passphrase_hash:\n            # Check if the hash needs an update\n            if hasher.check_needs_rehash(self.passphrase_hash):\n                self.passphrase_hash = hasher.hash(passphrase)\n                needs_update = True\n        else:\n            # Migrate to an argon2 hash, which creates one merged field\n            # that embeds randomly generated salt in the output like\n            # $alg$salt$hash\n            self.passphrase_hash = hasher.hash(passphrase)\n            self.pw_salt = None\n            self.pw_hash = None\n            needs_update = True\n\n        if needs_update:\n            db.session.add(self)\n            db.session.commit()\n\n        return is_valid\n\n    def regenerate_totp_shared_secret(self) -> None:\n        self.otp_secret = two_factor.random_base32()\n\n    def set_hotp_secret(self, otp_secret: str) -> None:\n        self.otp_secret = base64.b32encode(binascii.unhexlify(otp_secret.replace(\" \", \"\"))).decode(\n            \"ascii\"\n        )\n        self.is_totp = False\n        self.hotp_counter = 0\n\n    @property\n    def totp(self) -> two_factor.TOTP:\n        if self.is_totp:\n            return two_factor.TOTP(self.otp_secret)\n        else:\n            raise ValueError(f\"{self} is not using TOTP\")\n\n    @property\n    def hotp(self) -> two_factor.HOTP:\n        if not self.is_totp:\n            return two_factor.HOTP(self.otp_secret)\n        else:\n            raise ValueError(f\"{self} is not using HOTP\")\n\n    @property\n    def formatted_otp_secret(self) -> str:\n        return two_factor.format_secret(self.otp_secret)\n\n    def verify_2fa_token(self, token: Optional[str]) -> str:\n        if not token:\n            raise two_factor.OtpTokenInvalid()\n\n        # Strip from 2fa tokens the whitespace that many clients add for readability\n        sanitized_token = \"\".join(token.split())\n\n        # Reject OTP tokens that have already been used\n        if self.last_token is not None and self.last_token == sanitized_token:\n            raise two_factor.OtpTokenInvalid(\"Token already used\")\n\n        if self.is_totp:\n            # TOTP\n            self.totp.verify(sanitized_token, datetime.datetime.utcnow())\n        else:\n            # HOTP\n            successful_counter_value = self.hotp.verify(sanitized_token, self.hotp_counter)\n            self.hotp_counter = successful_counter_value + 1\n            db.session.commit()\n\n        return sanitized_token\n\n    _LOGIN_ATTEMPT_PERIOD = 60  # seconds\n    _MAX_LOGIN_ATTEMPTS_PER_PERIOD = 5\n\n    @classmethod\n    def throttle_login(cls, user: \"Journalist\") -> None:\n        # Record the login attempt...\n        login_attempt = JournalistLoginAttempt(user)\n        db.session.add(login_attempt)\n        db.session.commit()\n\n        # ...and reject it if they have exceeded the threshold\n        login_attempt_period = datetime.datetime.utcnow() - datetime.timedelta(\n            seconds=cls._LOGIN_ATTEMPT_PERIOD\n        )\n        attempts_within_period = (\n            JournalistLoginAttempt.query.filter(JournalistLoginAttempt.journalist_id == user.id)\n            .filter(JournalistLoginAttempt.timestamp > login_attempt_period)\n            .all()\n        )\n        if len(attempts_within_period) > cls._MAX_LOGIN_ATTEMPTS_PER_PERIOD:\n            raise LoginThrottledException(\n                f\"throttled ({len(attempts_within_period)} attempts in last \"\n                f\"{cls._LOGIN_ATTEMPT_PERIOD} seconds)\"\n            )\n\n    @classmethod\n    def login(\n        cls,\n        username: str,\n        password: Optional[str],\n        token: Optional[str],\n    ) -> \"Journalist\":\n        try: # Untested\n            user = Journalist.query.filter_by(username=username).one() # Untested\n        except NoResultFound: # Untested\n            raise InvalidUsernameException(gettext(\"Invalid username\")) # Untested\n\n        if user.username in Journalist.INVALID_USERNAMES:\n            raise InvalidUsernameException(gettext(\"Invalid username\"))\n\n        # Login hardening measures\n        cls.throttle_login(user)\n\n        sanitized_token = user.verify_2fa_token(token)\n\n        # If it is valid, store the token that to prevent OTP token reuse\n        user.last_token = sanitized_token\n        db.session.commit()\n\n        if not user.valid_password(password):\n            raise WrongPasswordException(\"invalid password\")\n\n        return user\n\n    def to_json(self, all_info: bool = True) -> Dict[str, Any]:\n        \"\"\"Returns a JSON representation of the journalist user. If all_info is\n        False, potentially sensitive or extraneous fields are excluded. Note\n        that both representations do NOT include credentials.\"\"\"\n        json_user: Dict[str, Any] = {\n            \"username\": self.username,\n            \"uuid\": self.uuid,\n            \"first_name\": self.first_name,\n            \"last_name\": self.last_name,\n        }\n\n        if all_info is True:\n            json_user[\"is_admin\"] = self.is_admin\n            if self.last_access:\n                json_user[\"last_login\"] = self.last_access\n            else:\n                json_user[\"last_login\"] = None\n\n        return json_user\n\n    def is_deleted_user(self) -> bool:\n        \"\"\"Is this the special \"deleted\" user managed by the system?\"\"\"\n        return self.username == \"deleted\"\n\n    @classmethod\n    def get_deleted(cls) -> \"Journalist\":\n        \"\"\"Get a system user that represents deleted journalists for referential integrity\n\n        Callers must commit the session themselves\n        \"\"\"\n        deleted = Journalist.query.filter_by(username=\"deleted\").one_or_none()\n        if deleted is None:\n            # Lazily create\n            deleted = cls(\n                # Use a placeholder username to bypass validation that would reject\n                # \"deleted\" as unusable\n                username=\"placeholder\",\n                # We store a randomly generated passphrase for this account that is\n                # never revealed to anyone.\n                password=PassphraseGenerator.get_default().generate_passphrase(),\n            )\n            deleted.username = \"deleted\"\n            db.session.add(deleted)\n        return deleted\n\n    def delete(self) -> None:\n        \"\"\"delete a journalist, migrating some data over to the \"deleted\" journalist\n\n        Callers must commit the session themselves\n        \"\"\"\n        deleted = self.get_deleted()\n        # All replies should be reassociated with the \"deleted\" journalist\n        for reply in Reply.query.filter_by(journalist_id=self.id).all():\n            reply.journalist_id = deleted.id\n            db.session.add(reply)\n\n        # For seen indicators, we need to make sure one doesn't already exist\n        # otherwise it'll hit a unique key conflict\n        already_seen_files = {\n            file.file_id for file in SeenFile.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for file in SeenFile.query.filter_by(journalist_id=self.id).all():\n            if file.file_id in already_seen_files:\n                db.session.delete(file)\n            else:\n                file.journalist_id = deleted.id\n                db.session.add(file)\n\n        already_seen_messages = {\n            message.message_id\n            for message in SeenMessage.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for message in SeenMessage.query.filter_by(journalist_id=self.id).all():\n            if message.message_id in already_seen_messages:\n                db.session.delete(message)\n            else:\n                message.journalist_id = deleted.id\n                db.session.add(message)\n\n        already_seen_replies = {\n            reply.reply_id for reply in SeenReply.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for reply in SeenReply.query.filter_by(journalist_id=self.id).all():\n            if reply.reply_id in already_seen_replies:\n                db.session.delete(reply)\n            else:\n                reply.journalist_id = deleted.id\n                db.session.add(reply)\n\n        # For the rest of the associated data we rely on cascading deletions\n        db.session.delete(self)",
        "callGraphToTestedFunction": [
          "login"
        ]
      },
      "unitTestFilePath": "tests/test_two_factor_in_apps.py"
    },
    {
      "functionName": "get_deleted",
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "get_deleted",
          "lines": [
            {
              "startLine": 714,
              "endLine": 715
            },
            {
              "startLine": 717,
              "endLine": 717
            },
            {
              "startLine": 725,
              "endLine": 727
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_journalist_api.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_deleted",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 714,
              "endLine": 715
            },
            {
              "startLine": 717,
              "endLine": 717
            },
            {
              "startLine": 725,
              "endLine": 727
            }
          ]
        },
        "uncoveredFnBody": "class Journalist(db.Model):\n    __tablename__ = \"journalists\"\n    id = Column(Integer, primary_key=True)\n    uuid = Column(String(36), unique=True, nullable=False)\n    username = Column(String(255), nullable=False, unique=True)\n    first_name = Column(String(255), nullable=True)\n    last_name = Column(String(255), nullable=True)\n    pw_salt = Column(LargeBinary(32), nullable=True)\n    pw_hash = Column(LargeBinary(256), nullable=True)\n    is_admin = Column(Boolean)\n\n    otp_secret = Column(String(32), default=two_factor.random_base32)\n    is_totp = Column(Boolean, default=True)\n    hotp_counter = Column(Integer, default=0)\n    last_token = Column(String(6))\n\n    created_on = Column(DateTime, default=datetime.datetime.utcnow)\n    last_access = Column(DateTime)\n    passphrase_hash = Column(String(256))\n\n    login_attempts = relationship(\n        \"JournalistLoginAttempt\", backref=\"journalist\", cascade=\"all, delete\"\n    )\n\n    MIN_USERNAME_LEN = 3\n    MIN_NAME_LEN = 0\n    MAX_NAME_LEN = 100\n    INVALID_USERNAMES = [\"deleted\"]\n\n    def __init__(\n        self,\n        username: str,\n        password: str,\n        first_name: \"Optional[str]\" = None,\n        last_name: \"Optional[str]\" = None,\n        is_admin: bool = False,\n        otp_secret: \"Optional[str]\" = None,\n    ) -> None:\n        self.check_username_acceptable(username)\n        self.username = username\n        if first_name:\n            self.check_name_acceptable(first_name)\n            self.first_name = first_name\n        if last_name:\n            self.check_name_acceptable(last_name)\n            self.last_name = last_name\n        # nosemgrep: python.django.security.audit.unvalidated-password.unvalidated-password\n        self.set_password(password)\n        self.is_admin = is_admin\n        self.uuid = str(uuid.uuid4())\n\n        if otp_secret:\n            self.set_hotp_secret(otp_secret)\n\n    def __repr__(self) -> str:\n        return \"<Journalist {}{}>\".format(self.username, \" [admin]\" if self.is_admin else \"\")\n\n    def _scrypt_hash(self, password: str, salt: bytes) -> bytes:\n        backend = default_backend()\n        scrypt_instance = scrypt.Scrypt(\n            length=64,\n            salt=salt,\n            n=2**14,\n            r=8,\n            p=1,\n            backend=backend,\n        )\n        return scrypt_instance.derive(password.encode(\"utf-8\"))\n\n    MAX_PASSWORD_LEN = 128\n    MIN_PASSWORD_LEN = 14\n\n    def set_password(self, passphrase: \"Optional[str]\") -> None:\n        if passphrase is None:\n            raise PasswordError()\n\n        self.check_password_acceptable(passphrase)\n\n        hasher = argon2.PasswordHasher(**ARGON2_PARAMS)\n        # \"migrate\" from the legacy case\n        if not self.passphrase_hash:\n            self.passphrase_hash = hasher.hash(passphrase)\n            # argon2 creates one merged field that embeds randomly generated\n            # salt in the output like $alg$salt$hash\n            self.pw_hash = None\n            self.pw_salt = None\n\n        # Don't do anything if user's password hasn't changed.\n        if self.passphrase_hash and self.valid_password(passphrase):\n            return\n\n        self.passphrase_hash = hasher.hash(passphrase)\n\n    def set_name(self, first_name: Optional[str], last_name: Optional[str]) -> None:\n        if first_name:\n            self.check_name_acceptable(first_name)\n            self.first_name = first_name\n        if last_name:\n            self.check_name_acceptable(last_name)\n            self.last_name = last_name\n\n    @classmethod\n    def check_username_acceptable(cls, username: str) -> None:\n        if len(username) < cls.MIN_USERNAME_LEN:\n            raise InvalidUsernameException(\n                ngettext(\n                    \"Must be at least {num} character long.\",\n                    \"Must be at least {num} characters long.\",\n                    cls.MIN_USERNAME_LEN,\n                ).format(num=cls.MIN_USERNAME_LEN)\n            )\n        if username in cls.INVALID_USERNAMES:\n            raise InvalidUsernameException(\n                gettext(\n                    \"This username is invalid because it is reserved \"\n                    \"for internal use by the software.\"\n                )\n            )\n\n    @classmethod\n    def check_name_acceptable(cls, name: str) -> None:\n        # Enforce a reasonable maximum length for names\n        if len(name) > cls.MAX_NAME_LEN:\n            raise InvalidNameLength()\n\n    @classmethod\n    def check_password_acceptable(cls, password: str) -> None:\n        # Enforce a reasonable maximum length for passwords to avoid DoS\n        if len(password) > cls.MAX_PASSWORD_LEN:\n            raise InvalidPasswordLength(password)\n\n        # Enforce a reasonable minimum length for new passwords\n        if len(password) < cls.MIN_PASSWORD_LEN:\n            raise InvalidPasswordLength(password)\n\n        # Ensure all passwords are \"diceware-like\"\n        if len(password.split()) < 7:\n            raise NonDicewarePassword()\n\n    def valid_password(self, passphrase: \"Optional[str]\") -> bool:\n        if not passphrase:\n            return False\n\n        # Avoid hashing passwords that are over the maximum length\n        if len(passphrase) > self.MAX_PASSWORD_LEN:\n            raise InvalidPasswordLength(passphrase)\n\n        # No check on minimum password length here because some passwords\n        # may have been set prior to setting the minimum password length.\n\n        hasher = argon2.PasswordHasher(**ARGON2_PARAMS)\n        if self.passphrase_hash:\n            # default case\n            try:\n                is_valid = hasher.verify(self.passphrase_hash, passphrase)\n            except argon2.exceptions.VerificationError:\n                is_valid = False\n        else:\n            # legacy support\n            if self.pw_salt is None:\n                raise ValueError(\n                    f\"Should never happen: pw_salt is none for legacy Journalist {self.id}\"\n                )\n\n            # For type checking\n            if not isinstance(self.pw_hash, bytes):\n                raise RuntimeError(\"self.pw_hash isn't bytes\")\n\n            is_valid = compare_digest(self._scrypt_hash(passphrase, self.pw_salt), self.pw_hash)\n\n        # If the passphrase isn't valid, bail out now\n        if not is_valid:\n            return False\n        # From here on we can assume the passphrase was valid\n\n        # Perform migration checks\n        needs_update = False\n        if self.passphrase_hash:\n            # Check if the hash needs an update\n            if hasher.check_needs_rehash(self.passphrase_hash):\n                self.passphrase_hash = hasher.hash(passphrase)\n                needs_update = True\n        else:\n            # Migrate to an argon2 hash, which creates one merged field\n            # that embeds randomly generated salt in the output like\n            # $alg$salt$hash\n            self.passphrase_hash = hasher.hash(passphrase)\n            self.pw_salt = None\n            self.pw_hash = None\n            needs_update = True\n\n        if needs_update:\n            db.session.add(self)\n            db.session.commit()\n\n        return is_valid\n\n    def regenerate_totp_shared_secret(self) -> None:\n        self.otp_secret = two_factor.random_base32()\n\n    def set_hotp_secret(self, otp_secret: str) -> None:\n        self.otp_secret = base64.b32encode(binascii.unhexlify(otp_secret.replace(\" \", \"\"))).decode(\n            \"ascii\"\n        )\n        self.is_totp = False\n        self.hotp_counter = 0\n\n    @property\n    def totp(self) -> two_factor.TOTP:\n        if self.is_totp:\n            return two_factor.TOTP(self.otp_secret)\n        else:\n            raise ValueError(f\"{self} is not using TOTP\")\n\n    @property\n    def hotp(self) -> two_factor.HOTP:\n        if not self.is_totp:\n            return two_factor.HOTP(self.otp_secret)\n        else:\n            raise ValueError(f\"{self} is not using HOTP\")\n\n    @property\n    def formatted_otp_secret(self) -> str:\n        return two_factor.format_secret(self.otp_secret)\n\n    def verify_2fa_token(self, token: Optional[str]) -> str:\n        if not token:\n            raise two_factor.OtpTokenInvalid()\n\n        # Strip from 2fa tokens the whitespace that many clients add for readability\n        sanitized_token = \"\".join(token.split())\n\n        # Reject OTP tokens that have already been used\n        if self.last_token is not None and self.last_token == sanitized_token:\n            raise two_factor.OtpTokenInvalid(\"Token already used\")\n\n        if self.is_totp:\n            # TOTP\n            self.totp.verify(sanitized_token, datetime.datetime.utcnow())\n        else:\n            # HOTP\n            successful_counter_value = self.hotp.verify(sanitized_token, self.hotp_counter)\n            self.hotp_counter = successful_counter_value + 1\n            db.session.commit()\n\n        return sanitized_token\n\n    _LOGIN_ATTEMPT_PERIOD = 60  # seconds\n    _MAX_LOGIN_ATTEMPTS_PER_PERIOD = 5\n\n    @classmethod\n    def throttle_login(cls, user: \"Journalist\") -> None:\n        # Record the login attempt...\n        login_attempt = JournalistLoginAttempt(user)\n        db.session.add(login_attempt)\n        db.session.commit()\n\n        # ...and reject it if they have exceeded the threshold\n        login_attempt_period = datetime.datetime.utcnow() - datetime.timedelta(\n            seconds=cls._LOGIN_ATTEMPT_PERIOD\n        )\n        attempts_within_period = (\n            JournalistLoginAttempt.query.filter(JournalistLoginAttempt.journalist_id == user.id)\n            .filter(JournalistLoginAttempt.timestamp > login_attempt_period)\n            .all()\n        )\n        if len(attempts_within_period) > cls._MAX_LOGIN_ATTEMPTS_PER_PERIOD:\n            raise LoginThrottledException(\n                f\"throttled ({len(attempts_within_period)} attempts in last \"\n                f\"{cls._LOGIN_ATTEMPT_PERIOD} seconds)\"\n            )\n\n    @classmethod\n    def login(\n        cls,\n        username: str,\n        password: Optional[str],\n        token: Optional[str],\n    ) -> \"Journalist\":\n        try:\n            user = Journalist.query.filter_by(username=username).one()\n        except NoResultFound:\n            raise InvalidUsernameException(gettext(\"Invalid username\"))\n\n        if user.username in Journalist.INVALID_USERNAMES:\n            raise InvalidUsernameException(gettext(\"Invalid username\"))\n\n        # Login hardening measures\n        cls.throttle_login(user)\n\n        sanitized_token = user.verify_2fa_token(token)\n\n        # If it is valid, store the token that to prevent OTP token reuse\n        user.last_token = sanitized_token\n        db.session.commit()\n\n        if not user.valid_password(password):\n            raise WrongPasswordException(\"invalid password\")\n\n        return user\n\n    def to_json(self, all_info: bool = True) -> Dict[str, Any]:\n        \"\"\"Returns a JSON representation of the journalist user. If all_info is\n        False, potentially sensitive or extraneous fields are excluded. Note\n        that both representations do NOT include credentials.\"\"\"\n        json_user: Dict[str, Any] = {\n            \"username\": self.username,\n            \"uuid\": self.uuid,\n            \"first_name\": self.first_name,\n            \"last_name\": self.last_name,\n        }\n\n        if all_info is True:\n            json_user[\"is_admin\"] = self.is_admin\n            if self.last_access:\n                json_user[\"last_login\"] = self.last_access\n            else:\n                json_user[\"last_login\"] = None\n\n        return json_user\n\n    def is_deleted_user(self) -> bool:\n        \"\"\"Is this the special \"deleted\" user managed by the system?\"\"\"\n        return self.username == \"deleted\"\n\n    @classmethod\n    def get_deleted(cls) -> \"Journalist\":\n        \"\"\"Get a system user that represents deleted journalists for referential integrity\n\n        Callers must commit the session themselves\n        \"\"\"\n        deleted = Journalist.query.filter_by(username=\"deleted\").one_or_none()\n        if deleted is None:\n            # Lazily create\n            deleted = cls(\n                # Use a placeholder username to bypass validation that would reject\n                # \"deleted\" as unusable\n                username=\"placeholder\",\n                # We store a randomly generated passphrase for this account that is\n                # never revealed to anyone.\n                password=PassphraseGenerator.get_default().generate_passphrase(),\n            )\n            deleted.username = \"deleted\" # Untested\n            db.session.add(deleted) # Untested\n        return deleted # Untested\n\n    def delete(self) -> None:\n        \"\"\"delete a journalist, migrating some data over to the \"deleted\" journalist\n\n        Callers must commit the session themselves\n        \"\"\"\n        deleted = self.get_deleted()\n        # All replies should be reassociated with the \"deleted\" journalist\n        for reply in Reply.query.filter_by(journalist_id=self.id).all():\n            reply.journalist_id = deleted.id\n            db.session.add(reply)\n\n        # For seen indicators, we need to make sure one doesn't already exist\n        # otherwise it'll hit a unique key conflict\n        already_seen_files = {\n            file.file_id for file in SeenFile.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for file in SeenFile.query.filter_by(journalist_id=self.id).all():\n            if file.file_id in already_seen_files:\n                db.session.delete(file)\n            else:\n                file.journalist_id = deleted.id\n                db.session.add(file)\n\n        already_seen_messages = {\n            message.message_id\n            for message in SeenMessage.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for message in SeenMessage.query.filter_by(journalist_id=self.id).all():\n            if message.message_id in already_seen_messages:\n                db.session.delete(message)\n            else:\n                message.journalist_id = deleted.id\n                db.session.add(message)\n\n        already_seen_replies = {\n            reply.reply_id for reply in SeenReply.query.filter_by(journalist_id=deleted.id).all()\n        }\n        for reply in SeenReply.query.filter_by(journalist_id=self.id).all():\n            if reply.reply_id in already_seen_replies:\n                db.session.delete(reply)\n            else:\n                reply.journalist_id = deleted.id\n                db.session.add(reply)\n\n        # For the rest of the associated data we rely on cascading deletions\n        db.session.delete(self)",
        "callGraphToTestedFunction": [
          "get_deleted"
        ]
      },
      "unitTestFilePath": "tests/test_journalist_api.py"
    },
    {
      "functionName": "get_current",
      "file": "models.py",
      "callGraph": [
        {
          "file": "models.py",
          "functionName": "get_current",
          "lines": [
            {
              "startLine": 900,
              "endLine": 901
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_db.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "models.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_current",
          "filePath": "models.py",
          "uncoveredLines": [
            {
              "startLine": 900,
              "endLine": 901
            }
          ]
        },
        "uncoveredFnBody": "class InstanceConfig(db.Model):\n    \"\"\"Versioned key-value store of settings configurable from the journalist\n    interface.  The current version has valid_until=0 (unix epoch start)\n    \"\"\"\n\n    # Limits length of org name used in SI and JI titles, image alt texts etc.\n    MAX_ORG_NAME_LEN = 64\n\n    __tablename__ = \"instance_config\"\n    version = Column(Integer, primary_key=True)\n    valid_until = Column(\n        DateTime,\n        default=datetime.datetime.fromtimestamp(0),\n        nullable=False,\n        unique=True,\n    )\n    allow_document_uploads = Column(Boolean, default=True)\n    organization_name = Column(String(255), nullable=True, default=\"SecureDrop\")\n    initial_message_min_len = Column(Integer, nullable=False, default=0, server_default=\"0\")\n    reject_message_with_codename = Column(\n        Boolean, nullable=False, default=False, server_default=\"0\"\n    )\n\n    # Columns not listed here will be included by InstanceConfig.copy() when\n    # updating the configuration.\n    metadata_cols = [\"version\", \"valid_until\"]\n\n    def __repr__(self) -> str:\n        return (\n            f\"<InstanceConfig(version={self.version}, valid_until={self.valid_until}, \"\n            f\"allow_document_uploads={self.allow_document_uploads}, \"\n            f\"organization_name={self.organization_name}, \"\n            f\"initial_message_min_len={self.initial_message_min_len}, \"\n            f\"reject_message_with_codename={self.reject_message_with_codename})>\"\n        )\n\n    def copy(self) -> \"InstanceConfig\":\n        \"\"\"Make a copy of only the configuration columns of the given\n        InstanceConfig object: i.e., excluding metadata_cols.\n        \"\"\"\n\n        new = type(self)()\n        for col in self.__table__.columns:\n            if col.name in self.metadata_cols:\n                continue\n\n            setattr(new, col.name, getattr(self, col.name))\n\n        return new\n\n    @classmethod\n    def get_default(cls, refresh: bool = False) -> \"InstanceConfig\":\n        global _default_instance_config\n        if (_default_instance_config is None) or (refresh is True):\n            _default_instance_config = InstanceConfig.get_current()\n        return _default_instance_config\n\n    @classmethod\n    def get_current(cls) -> \"InstanceConfig\":\n        \"\"\"If the database was created via db.create_all(), data migrations\n        weren't run, and the \"instance_config\" table is empty.  In this case,\n        save and return a base configuration derived from each setting's\n        column-level default.\n        \"\"\"\n\n        try:\n            return cls.query.filter(cls.valid_until == datetime.datetime.fromtimestamp(0)).one()\n        except NoResultFound:\n            try:\n                current = cls()\n                db.session.add(current)\n                db.session.commit()\n                return current\n            except IntegrityError: # Untested\n                return cls.query.filter(cls.valid_until == datetime.datetime.fromtimestamp(0)).one() # Untested\n\n    @classmethod\n    def check_name_acceptable(cls, name: str) -> None:\n        # Enforce a reasonable maximum length for names\n        if name is None or len(name) == 0:\n            raise InvalidNameLength()\n        if len(name) > cls.MAX_ORG_NAME_LEN:\n            raise InvalidNameLength()\n\n    @classmethod\n    def set_organization_name(cls, name: str) -> None:\n        \"\"\"Invalidate the current configuration and append a new one with the\n        new organization name.\n        \"\"\"\n\n        old = cls.get_current()\n        old.valid_until = datetime.datetime.utcnow()\n        db.session.add(old)\n\n        new = old.copy()\n        cls.check_name_acceptable(name)\n        new.organization_name = name\n        db.session.add(new)\n\n        db.session.commit()\n\n    @classmethod\n    def update_submission_prefs(\n        cls, allow_uploads: bool, min_length: int, reject_codenames: bool\n    ) -> None:\n        \"\"\"Invalidate the current configuration and append a new one with the\n        updated submission preferences.\n        \"\"\"\n\n        old = cls.get_current()\n        old.valid_until = datetime.datetime.utcnow()\n        db.session.add(old)\n\n        new = old.copy()\n        new.allow_document_uploads = allow_uploads\n        new.initial_message_min_len = min_length\n        new.reject_message_with_codename = reject_codenames\n        db.session.add(new)\n\n        db.session.commit()",
        "callGraphToTestedFunction": [
          "get_current"
        ]
      },
      "unitTestFilePath": "tests/test_db.py"
    },
    {
      "functionName": "available_languages",
      "file": "passphrases.py",
      "callGraph": [
        {
          "file": "passphrases.py",
          "functionName": "available_languages",
          "lines": [
            {
              "startLine": 99,
              "endLine": 99
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_passphrases.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "passphrases.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "available_languages",
          "filePath": "passphrases.py",
          "uncoveredLines": [
            {
              "startLine": 99,
              "endLine": 99
            }
          ]
        },
        "uncoveredFnBody": "class PassphraseGenerator:\n    PASSPHRASE_WORDS_COUNT = 7\n\n    # Enforce a reasonable maximum length for passphrases to avoid DoS\n    MAX_PASSPHRASE_LENGTH = 128\n    MIN_PASSPHRASE_LENGTH = 20\n\n    _WORD_LIST_MINIMUM_SIZE = 7300  # Minimum number of words in any of the word lists\n\n    def __init__(\n        self, language_to_words: Dict[str, List[str]], fallback_language: str = \"en\"\n    ) -> None:\n        # SystemRandom sources from the system rand (e.g. urandom, CryptGenRandom, etc)\n        # It supplies a CSPRNG but with an interface that supports methods like choice\n        self._random_generator = SystemRandom()\n\n        self._fallback_language = fallback_language\n        self._language_to_words = language_to_words\n        if self._fallback_language not in self._language_to_words:\n            raise InvalidWordListError(\n                f\"Missing words list for fallback language '{self._fallback_language}'\"\n            )\n\n        # Validate each words list\n        for language, word_list in self._language_to_words.items():\n            # Ensure that there are enough words in the list\n            word_list_size = len(word_list)\n            if word_list_size < self._WORD_LIST_MINIMUM_SIZE:\n                raise InvalidWordListError(\n                    f\"The word list for language '{language}' only contains {word_list_size}\"\n                    \" long-enough words;\"\n                    f\" minimum required is {self._WORD_LIST_MINIMUM_SIZE} words.\"\n                )\n\n            # Ensure all words are ascii\n            try:\n                \" \".join(word_list).encode(\"ascii\")\n            except UnicodeEncodeError:\n                raise InvalidWordListError(\n                    \"The word list for language '{}' contains non-ASCII words.\"\n                )\n\n            # Ensure that passphrases longer than what's supported can't be generated\n            longest_word = max(word_list, key=len)\n            longest_passphrase_length = len(longest_word) * self.PASSPHRASE_WORDS_COUNT\n            longest_passphrase_length += self.PASSPHRASE_WORDS_COUNT  # One space between each word\n            if longest_passphrase_length >= self.MAX_PASSPHRASE_LENGTH:\n                raise InvalidWordListError(\n                    f\"Passphrases over the maximum length ({self.MAX_PASSPHRASE_LENGTH}) \"\n                    \"may be generated:\"\n                    f\" longest word in word list for language '{language}' is '{longest_word}' \"\n                    \"and number of words per\"\n                    f\" passphrase is {self.PASSPHRASE_WORDS_COUNT}\"\n                )\n\n            # Ensure that passphrases shorter than what's supported can't be generated\n            shortest_word = min(word_list, key=len)\n            shortest_passphrase_length = len(shortest_word) * self.PASSPHRASE_WORDS_COUNT\n            shortest_passphrase_length += self.PASSPHRASE_WORDS_COUNT\n            if shortest_passphrase_length <= self.MIN_PASSPHRASE_LENGTH:\n                raise InvalidWordListError(\n                    f\"Passphrases under the minimum length ({self.MIN_PASSPHRASE_LENGTH}) \"\n                    \"may be generated:\"\n                    f\" shortest word in word list for language '{language}' is '{shortest_word}' \"\n                    \"and number of words per\"\n                    f\" passphrase is {self.PASSPHRASE_WORDS_COUNT}\"\n                )\n\n    @classmethod\n    def get_default(cls) -> \"PassphraseGenerator\":\n        global _default_generator\n        if _default_generator is None:\n            config = SecureDropConfig.get_current()\n            language_to_words = _parse_available_words_list(config.SECUREDROP_ROOT)\n            _default_generator = cls(language_to_words)\n        return _default_generator\n\n    @property\n    def available_languages(self) -> Set[str]:\n        return set(self._language_to_words.keys()) # Untested\n\n    def generate_passphrase(self, preferred_language: Optional[str] = None) -> DicewarePassphrase:\n        final_language = preferred_language if preferred_language else self._fallback_language\n        try:\n            words_list = self._language_to_words[final_language]\n        except KeyError:\n            # If there is no wordlist for the desired language, fall back to the word list for the\n            # default language\n            words_list = self._language_to_words[self._fallback_language]\n\n        words: List[str] = [\n            self._random_generator.choice(words_list) for _ in range(self.PASSPHRASE_WORDS_COUNT)\n        ]\n        return DicewarePassphrase(\" \".join(words))",
        "callGraphToTestedFunction": [
          "available_languages"
        ]
      },
      "unitTestFilePath": "tests/test_passphrases.py"
    },
    {
      "functionName": "generate_passphrase",
      "file": "passphrases.py",
      "callGraph": [
        {
          "file": "passphrases.py",
          "functionName": "generate_passphrase",
          "lines": [
            {
              "startLine": 105,
              "endLine": 105
            },
            {
              "startLine": 108,
              "endLine": 108
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_passphrases.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "passphrases.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "generate_passphrase",
          "filePath": "passphrases.py",
          "uncoveredLines": [
            {
              "startLine": 105,
              "endLine": 105
            },
            {
              "startLine": 108,
              "endLine": 108
            }
          ]
        },
        "uncoveredFnBody": "class PassphraseGenerator:\n    PASSPHRASE_WORDS_COUNT = 7\n\n    # Enforce a reasonable maximum length for passphrases to avoid DoS\n    MAX_PASSPHRASE_LENGTH = 128\n    MIN_PASSPHRASE_LENGTH = 20\n\n    _WORD_LIST_MINIMUM_SIZE = 7300  # Minimum number of words in any of the word lists\n\n    def __init__(\n        self, language_to_words: Dict[str, List[str]], fallback_language: str = \"en\"\n    ) -> None:\n        # SystemRandom sources from the system rand (e.g. urandom, CryptGenRandom, etc)\n        # It supplies a CSPRNG but with an interface that supports methods like choice\n        self._random_generator = SystemRandom()\n\n        self._fallback_language = fallback_language\n        self._language_to_words = language_to_words\n        if self._fallback_language not in self._language_to_words:\n            raise InvalidWordListError(\n                f\"Missing words list for fallback language '{self._fallback_language}'\"\n            )\n\n        # Validate each words list\n        for language, word_list in self._language_to_words.items():\n            # Ensure that there are enough words in the list\n            word_list_size = len(word_list)\n            if word_list_size < self._WORD_LIST_MINIMUM_SIZE:\n                raise InvalidWordListError(\n                    f\"The word list for language '{language}' only contains {word_list_size}\"\n                    \" long-enough words;\"\n                    f\" minimum required is {self._WORD_LIST_MINIMUM_SIZE} words.\"\n                )\n\n            # Ensure all words are ascii\n            try:\n                \" \".join(word_list).encode(\"ascii\")\n            except UnicodeEncodeError:\n                raise InvalidWordListError(\n                    \"The word list for language '{}' contains non-ASCII words.\"\n                )\n\n            # Ensure that passphrases longer than what's supported can't be generated\n            longest_word = max(word_list, key=len)\n            longest_passphrase_length = len(longest_word) * self.PASSPHRASE_WORDS_COUNT\n            longest_passphrase_length += self.PASSPHRASE_WORDS_COUNT  # One space between each word\n            if longest_passphrase_length >= self.MAX_PASSPHRASE_LENGTH:\n                raise InvalidWordListError(\n                    f\"Passphrases over the maximum length ({self.MAX_PASSPHRASE_LENGTH}) \"\n                    \"may be generated:\"\n                    f\" longest word in word list for language '{language}' is '{longest_word}' \"\n                    \"and number of words per\"\n                    f\" passphrase is {self.PASSPHRASE_WORDS_COUNT}\"\n                )\n\n            # Ensure that passphrases shorter than what's supported can't be generated\n            shortest_word = min(word_list, key=len)\n            shortest_passphrase_length = len(shortest_word) * self.PASSPHRASE_WORDS_COUNT\n            shortest_passphrase_length += self.PASSPHRASE_WORDS_COUNT\n            if shortest_passphrase_length <= self.MIN_PASSPHRASE_LENGTH:\n                raise InvalidWordListError(\n                    f\"Passphrases under the minimum length ({self.MIN_PASSPHRASE_LENGTH}) \"\n                    \"may be generated:\"\n                    f\" shortest word in word list for language '{language}' is '{shortest_word}' \"\n                    \"and number of words per\"\n                    f\" passphrase is {self.PASSPHRASE_WORDS_COUNT}\"\n                )\n\n    @classmethod\n    def get_default(cls) -> \"PassphraseGenerator\":\n        global _default_generator\n        if _default_generator is None:\n            config = SecureDropConfig.get_current()\n            language_to_words = _parse_available_words_list(config.SECUREDROP_ROOT)\n            _default_generator = cls(language_to_words)\n        return _default_generator\n\n    @property\n    def available_languages(self) -> Set[str]:\n        return set(self._language_to_words.keys())\n\n    def generate_passphrase(self, preferred_language: Optional[str] = None) -> DicewarePassphrase:\n        final_language = preferred_language if preferred_language else self._fallback_language\n        try:\n            words_list = self._language_to_words[final_language]\n        except KeyError:\n            # If there is no wordlist for the desired language, fall back to the word list for the\n            # default language\n            words_list = self._language_to_words[self._fallback_language] # Untested\n\n        words: List[str] = [\n            self._random_generator.choice(words_list) for _ in range(self.PASSPHRASE_WORDS_COUNT)\n        ]\n        return DicewarePassphrase(\" \".join(words))",
        "callGraphToTestedFunction": [
          "generate_passphrase"
        ]
      },
      "unitTestFilePath": "tests/test_passphrases.py"
    },
    {
      "functionName": "export_keys",
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "export_keys",
          "lines": [
            {
              "startLine": 413,
              "endLine": 413
            },
            {
              "startLine": 421,
              "endLine": 421
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_pretty_bad_protocol.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "export_keys",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 413,
              "endLine": 413
            },
            {
              "startLine": 421,
              "endLine": 421
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids]) # Untested\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "export_keys"
        ]
      },
      "unitTestFilePath": "tests/test_pretty_bad_protocol.py"
    },
    {
      "functionName": "gen_key",
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "gen_key",
          "lines": [
            {
              "startLine": 644,
              "endLine": 646
            },
            {
              "startLine": 648,
              "endLine": 653
            },
            {
              "startLine": 655,
              "endLine": 660
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_pretty_bad_protocol.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "gen_key",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 644,
              "endLine": 646
            },
            {
              "startLine": 648,
              "endLine": 653
            },
            {
              "startLine": 655,
              "endLine": 660
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring): # Untested\n                prefix = os.path.join(self.temp_secring, fpr) # Untested\n                try: # Untested\n                    os.rename(self.temp_secring, prefix + \".secring\") # Untested\n                except OSError as ose: # Untested\n                    log.error(str(ose)) # Untested\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "gen_key"
        ]
      },
      "unitTestFilePath": "tests/test_pretty_bad_protocol.py"
    },
    {
      "functionName": "gen_key_input",
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "gen_key_input",
          "lines": [
            {
              "startLine": 873,
              "endLine": 873
            },
            {
              "startLine": 883,
              "endLine": 884
            },
            {
              "startLine": 888,
              "endLine": 891
            },
            {
              "startLine": 897,
              "endLine": 897
            },
            {
              "startLine": 899,
              "endLine": 899
            },
            {
              "startLine": 901,
              "endLine": 901
            },
            {
              "startLine": 915,
              "endLine": 919
            },
            {
              "startLine": 925,
              "endLine": 926
            },
            {
              "startLine": 932,
              "endLine": 935
            },
            {
              "startLine": 937,
              "endLine": 938
            },
            {
              "startLine": 944,
              "endLine": 945
            },
            {
              "startLine": 947,
              "endLine": 949
            },
            {
              "startLine": 955,
              "endLine": 956
            },
            {
              "startLine": 958,
              "endLine": 959
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_pretty_bad_protocol.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "gen_key_input",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 873,
              "endLine": 873
            },
            {
              "startLine": 883,
              "endLine": 884
            },
            {
              "startLine": 888,
              "endLine": 891
            },
            {
              "startLine": 897,
              "endLine": 897
            },
            {
              "startLine": 899,
              "endLine": 899
            },
            {
              "startLine": 901,
              "endLine": 901
            },
            {
              "startLine": 915,
              "endLine": 919
            },
            {
              "startLine": 925,
              "endLine": 926
            },
            {
              "startLine": 932,
              "endLine": 935
            },
            {
              "startLine": 937,
              "endLine": 938
            },
            {
              "startLine": 944,
              "endLine": 945
            },
            {
              "startLine": 947,
              "endLine": 949
            },
            {
              "startLine": 955,
              "endLine": 956
            },
            {
              "startLine": 958,
              "endLine": 959
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time()))) # Untested\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\") # Untested\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\") # Untested\n            out += \"%%pubring %s\\n\" % self.temp_keyring # Untested\n            out += \"%%secring %s\\n\" % self.temp_secring # Untested\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding)\n        result = self.decrypt_file(stream, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "gen_key_input"
        ]
      },
      "unitTestFilePath": "tests/test_pretty_bad_protocol.py"
    },
    {
      "functionName": "decrypt",
      "file": "pretty_bad_protocol/gnupg.py",
      "callGraph": [
        {
          "file": "pretty_bad_protocol/gnupg.py",
          "functionName": "decrypt",
          "lines": [
            {
              "startLine": 1065,
              "endLine": 1068
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_encryption.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "pretty_bad_protocol/gnupg.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "decrypt",
          "filePath": "pretty_bad_protocol/gnupg.py",
          "uncoveredLines": [
            {
              "startLine": 1065,
              "endLine": 1068
            }
          ]
        },
        "uncoveredFnBody": "class GPG(GPGBase):\n    \"\"\"Python interface for handling interactions with GnuPG, including keyfile\n    generation, keyring maintainance, import and export, encryption and\n    decryption, sending to and recieving from keyservers, and signing and\n    verification.\n    \"\"\"\n\n    #: The number of simultaneous keyids we should list operations like\n    #: '--list-sigs' to:\n    _batch_limit = 25\n\n    def __init__(  # type: ignore[no-untyped-def]\n        self,\n        binary=None,\n        homedir=None,\n        verbose=False,\n        use_agent=False,\n        keyring=None,\n        secring=None,\n        ignore_homedir_permissions=False,\n        options=None,\n    ):\n        \"\"\"Initialize a GnuPG process wrapper.\n\n        :param str binary: Name for GnuPG binary executable. If the absolute\n                           path is not given, the environment variable\n                           ``$PATH`` is searched for the executable and\n                           checked that the real uid/gid of the user has\n                           sufficient permissions.\n\n        :param str homedir: Full pathname to directory containing the public\n                            and private keyrings. Default is\n                            `~/.config/python-gnupg`.\n\n        :type ignore_homedir_permissions: :obj:`bool`\n        :param ignore_homedir_permissions: If true, bypass check that homedir\n                                           be writable.\n\n        :type verbose: :obj:`str` or :obj:`int` or :obj:`bool`\n        :param verbose: String or numeric value to pass to GnuPG's\n                        ``--debug-level`` option. See the GnuPG man page for\n                        the list of valid options. If False, debug output is\n                        not generated by the GnuPG binary. If True, defaults\n                        to ``--debug-level basic.``\n\n        :param str keyring: Name of keyring file containing public key data.\n                            If unspecified, defaults to :file:`pubring.gpg` in\n                            the **homedir** directory.\n\n        :param str secring: Name of alternative secret keyring file to use. If\n                            left unspecified, this will default to using\n                            :file:`secring.gpg` in the **homedir** directory,\n                            and create that file if it does not exist.\n\n        :param list options: A list of additional options to pass to the GnuPG\n                             binary.\n\n        :raises: A :exc:`~exceptions.RuntimeError` with explanation message\n                 if there is a problem invoking GnuPG.\n\n        Example:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> gpg.keyring\n        './doctests/pubring.gpg'\n        >>> gpg.secring\n        './doctests/secring.gpg'\n        >>> gpg.use_agent\n        False\n        >>> gpg.binary\n        '/usr/bin/gpg'\n        \"\"\"\n\n        super().__init__(\n            binary=binary,\n            home=homedir,\n            keyring=keyring,\n            secring=secring,\n            options=options,\n            verbose=verbose,\n            use_agent=use_agent,\n            ignore_homedir_permissions=ignore_homedir_permissions,\n        )\n\n        log.info(\n            textwrap.dedent(\n                f\"\"\"\n        Initialised settings:\n        binary: {self.binary}\n        binary version: {self.binary_version}\n        homedir: {self.homedir}\n        ignore_homedir_permissions: {self.ignore_homedir_permissions}\n        keyring: {self.keyring}\n        secring: {self.secring}\n        default_preference_list: {self.default_preference_list}\n        keyserver: {self.keyserver}\n        options: {self.options}\n        verbose: {str(self.verbose)}\n        use_agent: {str(self.use_agent)}\n        \"\"\"\n            )\n        )\n\n        self._batch_dir = os.path.join(self.homedir, \"batch-files\")\n        self._key_dir = os.path.join(self.homedir, \"generated-keys\")\n\n        #: The keyring used in the most recently created batch file\n        self.temp_keyring = None\n        #: The secring used in the most recently created batch file\n        self.temp_secring = None\n\n        # Make sure that the trustdb exists, or else GnuPG will exit with a\n        # fatal error (at least it does with GnuPG>=2.0.0):\n        self.create_trustdb()\n\n        # The --no-use-agent and --use-agent options were deprecated in GnuPG\n        # 2.x, so we should set use_agent to None here to avoid having\n        # GPGBase._make_args() add either one.\n        self.use_agent = None\n\n    @functools.wraps(_trust._create_trustdb)\n    def create_trustdb(self):  # type: ignore[no-untyped-def]\n        _trust._create_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _create_trustdb = create_trustdb\n\n    @functools.wraps(_trust.fix_trustdb)\n    def fix_trustdb(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.fix_trustdb(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _fix_trustdb = fix_trustdb\n\n    @functools.wraps(_trust.import_ownertrust)\n    def import_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.import_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _import_ownertrust = import_ownertrust\n\n    @functools.wraps(_trust.export_ownertrust)\n    def export_ownertrust(self, trustdb=None):  # type: ignore[no-untyped-def]\n        _trust.export_ownertrust(self)\n\n    # For backward compatibility with python-gnupg<=1.3.1:\n    _export_ownertrust = export_ownertrust\n\n    def sign(self, data, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Create a signature for a message string or file.\n\n        Note that this method is not for signing other keys. (In GnuPG's\n        terms, what we all usually call 'keysigning' is actually termed\n        'certification'...) Even though they are cryptographically the same\n        operation, GnuPG differentiates between them, presumedly because these\n        operations are also the same as the decryption operation. If the\n        ``key_usage``s ``C (certification)``, ``S (sign)``, and ``E\n        (encrypt)``, were all the same key, the key would \"wear down\" through\n        frequent signing usage -- since signing data is usually done often --\n        meaning that the secret portion of the keypair, also used for\n        decryption in this scenario, would have a statistically higher\n        probability of an adversary obtaining an oracle for it (or for a\n        portion of the rounds in the cipher algorithm, depending on the family\n        of cryptanalytic attack used).\n\n        In simpler terms: this function isn't for signing your friends' keys,\n        it's for something like signing an email.\n\n        :type data: :obj:`str` or :obj:`file`\n        :param data: A string or file stream to sign.\n        :param str default_key: The key to sign with.\n        :param str passphrase: The passphrase to pipe to stdin.\n        :param bool clearsign: If True, create a cleartext signature.\n        :param bool detach: If True, create a detached signature.\n        :param bool binary: If True, do not ascii armour the output.\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n        \"\"\"\n        if \"default_key\" in kwargs:\n            log.info(\"Signing message '{!r}' with keyid: {}\".format(data, kwargs[\"default_key\"]))\n        else:\n            log.warn(\"No 'default_key' given! Using first key on secring.\")\n\n        if hasattr(data, \"read\"):\n            result = self._sign_file(data, **kwargs)\n        elif not _is_stream(data):\n            stream = _make_binary_stream(data, self._encoding)\n            result = self._sign_file(stream, **kwargs)\n            stream.close()\n        else:\n            log.warn(f\"Unable to sign message '{data}' with type {type(data)}\")\n            result = None\n        return result\n\n    def verify(self, data):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of the string ``data``.\n\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input(Passphrase='foo')\n        >>> key = gpg.gen_key(input)\n        >>> assert key\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='bar')\n        >>> assert not sig\n        >>> sig = gpg.sign('hello',keyid=key.fingerprint,passphrase='foo')\n        >>> assert sig\n        >>> verify = gpg.verify(sig.data)\n        >>> assert verify\n\n        \"\"\"\n        f = _make_binary_stream(data, self._encoding)\n        result = self.verify_file(f)\n        f.close()\n        return result\n\n    def verify_file(self, file, sig_file=None):  # type: ignore[no-untyped-def]\n        \"\"\"Verify the signature on the contents of a file or file-like\n        object. Can handle embedded signatures as well as detached\n        signatures. If using detached signatures, the file containing the\n        detached signature should be specified as the ``sig_file``.\n\n        :param file file: A file descriptor object.\n\n        :param str sig_file: A file containing the GPG signature data for\n            ``file``. If given, ``file`` is verified via this detached\n            signature. Its type will be checked with :func:`_util._is_file`.\n        \"\"\"\n\n        result = self._result_map[\"verify\"](self)\n\n        if sig_file is None:\n            log.debug(\"verify_file(): Handling embedded signature\")\n            args = [\"--verify\"]\n            proc = self._open_subprocess(args)\n            writer = _util._threaded_copy_data(file, proc.stdin)\n            self._collect_output(proc, result, writer, stdin=proc.stdin)\n        else:\n            if not _util._is_file(sig_file):\n                log.debug(\"verify_file(): '%r' is not a file\" % sig_file)\n                return result\n            log.debug(\"verify_file(): Handling detached verification\")\n            sig_fh = None\n            try:\n                sig_fh = open(sig_file, \"rb\")\n                args = [\"--verify %s -\" % sig_fh.name]\n                proc = self._open_subprocess(args)\n                writer = _util._threaded_copy_data(file, proc.stdin)\n                self._collect_output(proc, result, writer, stdin=proc.stdin)\n            finally:\n                if sig_fh and not sig_fh.closed:\n                    sig_fh.close()\n        return result\n\n    def import_keys(self, key_data):  # type: ignore[no-untyped-def]\n        \"\"\"\n        Import the key_data into our keyring.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> inpt = gpg.gen_key_input()\n        >>> key1 = gpg.gen_key(inpt)\n        >>> print1 = str(key1.fingerprint)\n        >>> pubkey1 = gpg.export_keys(print1)\n        >>> seckey1 = gpg.export_keys(print1,secret=True)\n        >>> key2 = gpg.gen_key(inpt)\n        >>> print2 = key2.fingerprint\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> str(gpg.delete_keys(print1))\n        'Must delete secret key first'\n        >>> str(gpg.delete_keys(print1,secret=True))\n        'ok'\n        >>> str(gpg.delete_keys(print1))\n        'ok'\n        >>> pubkeys = gpg.list_keys()\n        >>> assert not print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(pubkey1)\n        >>> pubkeys = gpg.list_keys()\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert not print1 in seckeys.fingerprints\n        >>> assert print1 in pubkeys.fingerprints\n        >>> result = gpg.import_keys(seckey1)\n        >>> assert result\n        >>> seckeys = gpg.list_keys(secret=True)\n        >>> assert print1 in seckeys.fingerprints\n        \"\"\"\n        # xxx need way to validate that key_data is actually a valid GPG key\n        #     it might be possible to use --list-packets and parse the output\n\n        result = self._result_map[\"import\"](self)\n        log.info(\"Importing: %r\", key_data[:256])\n        data = _make_binary_stream(key_data, self._encoding)\n        self._handle_io([\"--import\"], data, result, binary=True)\n        data.close()\n        return result\n\n    def recv_keys(self, *keyids, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Import keys from a keyserver.\n\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key = gpg.recv_keys('3FF0DB166A7476EA', keyserver='hkp://pgp.mit.edu')\n        >>> assert key\n\n        :param str keyids: Each ``keyids`` argument should be a string\n             containing a keyid to request.\n        :param str keyserver: The keyserver to request the ``keyids`` from;\n             defaults to `gnupg.GPG.keyserver`.\n        \"\"\"\n        if keyids:\n            keys = \" \".join([key for key in keyids])\n            return self._recv_keys(keys, **kwargs)\n        else:\n            log.error(\"No keyids requested for --recv-keys!\")\n\n    def delete_keys(self, fingerprints, secret=False, subkeys=False):  # type: ignore[no-untyped-def]\n        \"\"\"Delete a key, or list of keys, from the current keyring.\n\n        The keys must be referred to by their full fingerprints for GnuPG to\n        delete them. If ``secret=True``, the corresponding secret keyring will\n        be deleted from :obj:`.secring`.\n\n        :type fingerprints: :obj:`str` or :obj:`list` or :obj:`tuple`\n        :param fingerprints: A string, or a list/tuple of strings,\n                             representing the fingerprint(s) for the key(s)\n                             to delete.\n\n        :param bool secret: If True, delete the corresponding secret key(s)\n                            also. (default: False)\n\n        :param bool subkeys: If True, delete the secret subkey first, then the\n                             public key. (default: False) Same as:\n                             :command:`$gpg --delete-secret-and-public-key 0x12345678`.\n        \"\"\"\n        which = \"keys\"\n        if secret:\n            which = \"secret-keys\"\n        if subkeys:\n            which = \"secret-and-public-keys\"\n\n        if _is_list_or_tuple(fingerprints):\n            fingerprints = \" \".join(fingerprints)\n\n        args = [\"--batch\"]\n        args.append(f\"--delete-{which} {fingerprints}\")\n\n        result = self._result_map[\"delete\"](self)\n        p = self._open_subprocess(args)\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def export_keys(self, keyids, secret=False, subkeys=False, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"Export the indicated ``keyids``.\n\n        :param str keyids: A keyid or fingerprint in any format that GnuPG will\n            accept.\n        :param bool secret: If True, export only the secret key.\n        :param bool subkeys: If True, export the secret subkeys.\n        :param Optional[str] passphrase: if exporting secret keys, use this\n            passphrase to authenticate\n        \"\"\"\n        which = \"\"\n        if subkeys:\n            which = \"-secret-subkeys\"\n        elif secret:\n            which = \"-secret-keys\"\n        else:\n            # No secret key material, ignore passphrase arg\n            passphrase = None\n\n        if _is_list_or_tuple(keyids):\n            keyids = \" \".join([\"%s\" % k for k in keyids])\n\n        args = [\"--armor\", f\"--export{which} {keyids}\"]\n        result = self._result_map[\"export\"](self)\n\n        # Yes we need to pass in an empty temporary file here,\n        # please don't ask me why. I can't get it to work otherwise.\n        with tempfile.NamedTemporaryFile() as tmp:\n            self._handle_io(args, tmp.name, result, passphrase, binary=True)\n\n        log.debug(f\"Exported:{os.linesep}{result.fingerprints!r}\")\n        return result.data.decode(self._encoding, self._decode_errors)\n\n    def list_keys(self, secret=False):  # type: ignore[no-untyped-def]\n        \"\"\"List the keys currently in the keyring.\n\n        The GnuPG option '--show-photos', according to the GnuPG manual, \"does\n        not work with --with-colons\", but since we can't rely on all versions\n        of GnuPG to explicitly handle this correctly, we should probably\n        include it in the args.\n\n        >>> import shutil\n        >>> shutil.rmtree(\"doctests\")\n        >>> gpg = GPG(homedir=\"doctests\")\n        >>> input = gpg.gen_key_input()\n        >>> result = gpg.gen_key(input)\n        >>> print1 = result.fingerprint\n        >>> result = gpg.gen_key(input)\n        >>> print2 = result.fingerprint\n        >>> pubkeys = gpg.list_keys()\n        >>> assert print1 in pubkeys.fingerprints\n        >>> assert print2 in pubkeys.fingerprints\n        \"\"\"\n        which = \"public-keys\"\n        if secret:\n            which = \"secret-keys\"\n\n        args = []\n        args.append(\"--fixed-list-mode\")\n        args.append(\"--fingerprint\")\n        args.append(\"--with-colons\")\n        args.append(\"--list-options no-show-photos\")\n        args.append(\"--list-%s\" % (which))\n\n        p = self._open_subprocess(args)\n\n        # there might be some status thingumy here I should handle... (amk)\n        # ...nope, unless you care about expired sigs or keys (stevegt)\n\n        # Get the response information\n        result = self._result_map[\"list\"](self)\n        self._collect_output(p, result, stdin=p.stdin)\n        self._parse_keys(result)\n        return result\n\n    def list_packets(self, raw_data):  # type: ignore[no-untyped-def]\n        \"\"\"List the packet contents of a file.\"\"\"\n        args = [\"--list-packets\"]\n        result = self._result_map[\"packets\"](self)\n        self._handle_io(args, _make_binary_stream(raw_data, self._encoding), result)\n        return result\n\n    def sign_key(self, keyid, default_key=None, passphrase=None):  # type: ignore[no-untyped-def]\n        \"\"\"sign (an imported) public key - keyid, with default secret key\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.sign_key(key['fingerprint'])\n        >>> gpg.list_sigs(key['fingerprint'])\n\n        :param str keyid: key shortID, longID, fingerprint or email_address\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n\n        :returns: The result giving status of the key signing...\n                    success can be verified by gpg.list_sigs(keyid)\n        \"\"\"\n\n        args = []\n        input_command = \"\"\n        if passphrase:\n            passphrase_arg = \"--passphrase-fd 0\"\n            input_command = \"%s\\n\" % passphrase\n            args.append(passphrase_arg)\n\n        if default_key:\n            args.append(str(\"--default-key %s\" % default_key))\n\n        args.extend([\"--command-fd 0\", \"--sign-key %s\" % keyid])\n\n        p = self._open_subprocess(args)\n        result = self._result_map[\"signing\"](self)\n        confirm_command = \"%sy\\n\" % input_command\n        p.stdin.write(confirm_command.encode())\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def list_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Get the signatures for each of the ``keyids``.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :rtype: dict\n        :returns: res.sigs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids)\n\n    def check_sigs(self, *keyids):  # type: ignore[no-untyped-def]\n        \"\"\"Validate the signatures for each of the ``keyids``.\n\n        :rtype: dict\n        :returns: res.certs is a dictionary whose keys are the uids and whose\n                values are a set of signature keyids.\n        \"\"\"\n        return self._process_keys(keyids, check_sig=True)\n\n    def _process_keys(self, keyids, check_sig=False):  # type: ignore[no-untyped-def]\n        if len(keyids) > self._batch_limit:\n            raise ValueError(\n                \"List signatures is limited to %d keyids simultaneously\" % self._batch_limit\n            )\n\n        args = [\"--with-colons\", \"--fixed-list-mode\"]\n        arg = \"--check-sigs\" if check_sig else \"--list-sigs\"\n\n        if len(keyids):\n            arg += \" \" + \" \".join(keyids)\n\n        args.append(arg)\n\n        proc = self._open_subprocess(args)\n        result = self._result_map[\"list\"](self)\n        self._collect_output(proc, result, stdin=proc.stdin)\n        self._parse_keys(result)\n        return result\n\n    def _parse_keys(self, result):  # type: ignore[no-untyped-def]\n        lines = result.data.decode(self._encoding, self._decode_errors).splitlines()\n        valid_keywords = \"pub uid sec fpr sub sig rev\".split()\n        for line in lines:\n            if self.verbose:\n                print(line)\n            log.debug(\"%r\", line.rstrip())\n            if not line:\n                break\n            L = line.strip().split(\":\")\n            if not L:\n                continue\n            keyword = L[0]\n            if keyword in valid_keywords:\n                getattr(result, keyword)(L)\n\n    def expire(self, keyid, expiration_time=\"1y\", passphrase=None, expire_subkeys=True):  # type: ignore[no-untyped-def]\n        \"\"\"Changes GnuPG key expiration by passing in new time period (from now) through\n            subprocess's stdin\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> gpg.expire(key.fingerprint, '2w', 'good passphrase')\n\n        :param str keyid: key shortID, longID, email_address or fingerprint\n        :param str expiration_time: 0 or number of days (d), or weeks (*w) , or months (*m)\n                or years (*y) for when to expire the key, from today.\n        :param str passphrase: passphrase used when creating the key, leave None otherwise\n        :param bool expire_subkeys: to indicate whether the subkeys will also change the\n                expiration time by the same period -- default is True\n\n        :returns: The result giving status of the change in expiration...\n                the new expiration date can be obtained by .list_keys()\n        \"\"\"\n\n        passphrase = passphrase.encode(self._encoding) if passphrase else passphrase\n\n        try:\n            sub_keys_number = len(self.list_sigs(keyid)[0][\"subkeys\"]) if expire_subkeys else 0\n        except IndexError:\n            sub_keys_number = 0\n\n        expiration_input = KeyExpirationInterface(\n            expiration_time, passphrase\n        ).gpg_interactive_input(sub_keys_number)\n\n        args = [\"--command-fd 0\", \"--edit-key %s\" % keyid]\n        p = self._open_subprocess(args)\n        p.stdin.write(expiration_input.encode())\n\n        result = self._result_map[\"expire\"](self)\n        p.stdin.write(expiration_input.encode())\n\n        self._collect_output(p, result, stdin=p.stdin)\n        return result\n\n    def gen_key(self, input):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a GnuPG key through batch file key generation. See\n        :meth:`GPG.gen_key_input()` for creating the control input.\n\n        >>> import gnupg\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_input = gpg.gen_key_input()\n        >>> key = gpg.gen_key(key_input)\n        >>> assert key.fingerprint\n\n        :param dict input: A dictionary of parameters and values for the new\n                           key.\n        :returns: The result mapping with details of the new key, which is a\n                  :class:`GenKey <gnupg._parsers.GenKey>` object.\n        \"\"\"\n        args = [\"--gen-key --cert-digest-algo SHA512 --batch\"]\n        key = self._result_map[\"generate\"](self)\n        f = _make_binary_stream(input, self._encoding)\n        self._handle_io(args, f, key, binary=True)\n        f.close()\n\n        fpr = str(key.fingerprint)\n        if len(fpr) == 20:\n            for d in map(lambda x: os.path.dirname(x), [self.temp_keyring, self.temp_secring]):\n                if not os.path.exists(d):\n                    os.makedirs(d)\n\n            if self.temp_keyring and os.path.isfile(self.temp_keyring):\n                prefix = os.path.join(self.temp_keyring, fpr)\n                try:\n                    os.rename(self.temp_keyring, prefix + \".pubring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n            if self.temp_secring and os.path.isfile(self.temp_secring):\n                prefix = os.path.join(self.temp_secring, fpr)\n                try:\n                    os.rename(self.temp_secring, prefix + \".secring\")\n                except OSError as ose:\n                    log.error(str(ose))\n\n        log.info(\"Key created. Fingerprint: %s\" % fpr)\n        key.keyring = self.temp_keyring\n        key.secring = self.temp_secring\n        self.temp_keyring = None\n        self.temp_secring = None\n\n        return key\n\n    def gen_key_input(self, separate_keyring=False, save_batchfile=False, testing=False, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Generate a batch file for input to :meth:`~gnupg.GPG.gen_key`.\n\n        The GnuPG batch file key generation feature allows unattended key\n        generation by creating a file with special syntax and then providing it\n        to: :command:`gpg --gen-key --batch`. Batch files look like this:\n\n        |  Name-Real: Alice\n        |  Name-Email: alice@inter.net\n        |  Expire-Date: 2014-04-01\n        |  Key-Type: RSA\n        |  Key-Length: 4096\n        |  Key-Usage: cert\n        |  Subkey-Type: RSA\n        |  Subkey-Length: 4096\n        |  Subkey-Usage: encrypt,sign,auth\n        |  Passphrase: sekrit\n        |  %pubring foo.gpg\n        |  %secring sec.gpg\n        |  %commit\n\n        which is what this function creates for you. All of the available,\n        non-control parameters are detailed below (control parameters are the\n        ones which begin with a '%'). For example, to generate the batch file\n        example above, use like this:\n\n        >>> import gnupg\n        GnuPG logging disabled...\n        >>> from __future__ import print_function\n        >>> gpg = gnupg.GPG(homedir='doctests')\n        >>> alice = { 'name_real': 'Alice',\n        ...     'name_email': 'alice@inter.net',\n        ...     'expire_date': '2014-04-01',\n        ...     'key_type': 'RSA',\n        ...     'key_length': 4096,\n        ...     'key_usage': '',\n        ...     'subkey_type': 'RSA',\n        ...     'subkey_length': 4096,\n        ...     'subkey_usage': 'encrypt,sign,auth',\n        ...     'passphrase': 'sekrit'}\n        >>> alice_input = gpg.gen_key_input(**alice)\n        >>> print(alice_input)\n        Key-Type: RSA\n        Subkey-Type: RSA\n        Subkey-Usage: encrypt,sign,auth\n        Expire-Date: 2014-04-01\n        Passphrase: sekrit\n        Name-Real: Alice\n        Name-Email: alice@inter.net\n        Key-Length: 4096\n        Subkey-Length: 4096\n        %pubring ./doctests/alice.pubring.gpg\n        %secring ./doctests/alice.secring.gpg\n        %commit\n        <BLANKLINE>\n        >>> alice_key = gpg.gen_key(alice_input)\n        >>> assert alice_key is not None\n        >>> assert alice_key.fingerprint is not None\n        >>> message = \"no one else can read my sekrit message\"\n        >>> encrypted = gpg.encrypt(message, alice_key.fingerprint)\n        >>> assert isinstance(encrypted.data, str)\n\n        :param bool separate_keyring: Specify for the new key to be written to\n            a separate pubring.gpg and secring.gpg. If True,\n            :meth:`~gnupg.GPG.gen_key` will automatically rename the separate\n            keyring and secring to whatever the fingerprint of the generated\n            key ends up being, suffixed with '.pubring' and '.secring'\n            respectively.\n\n        :param bool save_batchfile: Save a copy of the generated batch file to\n            disk in a file named <name_real>.batch, where <name_real> is the\n            ``name_real`` parameter stripped of punctuation, spaces, and\n            non-ascii characters.\n\n        :param bool testing: Uses a faster, albeit insecure random number\n            generator to create keys. This should only be used for testing\n            purposes, for keys which are going to be created and then soon\n            after destroyed, and never for the generation of actual use keys.\n\n        :param str name_real: The name field of the UID in the generated key.\n        :param str name_comment: The comment in the UID of the generated key.\n\n        :param str name_email: The email in the UID of the generated key.\n            (default: ``$USER`` @ :command:`hostname` ) Remember to use UTF-8\n            encoding for the entirety of the UID. At least one of\n            ``name_real``, ``name_comment``, or ``name_email`` must be\n            provided, or else no user ID is created.\n\n        :param str key_type: One of 'RSA', 'DSA', 'ELG-E', or 'default'.\n            (default: 'RSA', if using GnuPG v1.x, otherwise 'default') Starts\n            a new parameter block by giving the type of the primary key. The\n            algorithm must be capable of signing. This is a required\n            parameter. The algorithm may either be an OpenPGP algorithm number\n            or a string with the algorithm name. The special value ‘default’\n            may be used for algo to create the default key type; in this case\n            a ``key_usage`` should not be given and 'default' must also be\n            used for ``subkey_type``.\n\n        :param int key_length: The requested length of the generated key in\n            bits. (Default: 4096)\n\n        :param str key_grip: hexstring This is an optional hexidecimal string\n            which is used to generate a CSR or certificate for an already\n            existing key. ``key_length`` will be ignored if this parameter\n            is given.\n\n        :param str key_usage: Space or comma delimited string of key\n            usages. Allowed values are ‘encrypt’, ‘sign’, and ‘auth’. This is\n            used to generate the key flags. Please make sure that the\n            algorithm is capable of this usage. Note that OpenPGP requires\n            that all primary keys are capable of certification, so no matter\n            what usage is given here, the ‘cert’ flag will be on. If no\n            ‘Key-Usage’ is specified and the ‘Key-Type’ is not ‘default’, all\n            allowed usages for that particular algorithm are used; if it is\n            not given but ‘default’ is used the usage will be ‘sign’.\n\n        :param str subkey_type: This generates a secondary key\n            (subkey). Currently only one subkey can be handled. See also\n            ``key_type`` above.\n\n        :param int subkey_length: The length of the secondary subkey in bits.\n\n        :param str subkey_usage: Key usage for a subkey; similar to\n            ``key_usage``.\n\n        :type expire_date: :obj:`int` or :obj:`str`\n        :param expire_date: Can be specified as an iso-date or as\n            <int>[d|w|m|y] Set the expiration date for the key (and the\n            subkey). It may either be entered in ISO date format (2000-08-15)\n            or as number of days, weeks, month or years. The special notation\n            \"seconds=N\" is also allowed to directly give an Epoch\n            value. Without a letter days are assumed. Note that there is no\n            check done on the overflow of the type used by OpenPGP for\n            timestamps. Thus you better make sure that the given value make\n            sense. Although OpenPGP works with time intervals, GnuPG uses an\n            absolute value internally and thus the last year we can represent\n            is 2105.\n\n        :param str creation_date: Set the creation date of the key as stored\n            in the key information and which is also part of the fingerprint\n            calculation. Either a date like \"1986-04-26\" or a full timestamp\n            like \"19860426T042640\" may be used. The time is considered to be\n            UTC. If it is not given the current time is used.\n\n        :param str passphrase: The passphrase for the new key. The default is\n            to not use any passphrase. Note that GnuPG>=2.1.x will not allow\n            you to specify a passphrase for batch key generation -- GnuPG will\n            ignore the **passphrase** parameter, stop, and ask the user for\n            the new passphrase.  However, we can put the command\n            ``%no-protection`` into the batch key generation file to allow a\n            passwordless key to be created, which can then have its passphrase\n            set later with ``--edit-key``.\n\n        :param str preferences: Set the cipher, hash, and compression\n            preference values for this key. This expects the same type of\n            string as the sub-command ‘setpref’ in the --edit-key menu.\n\n        :param str revoker: Should be given as 'algo:fpr' (case sensitive).\n            Add a designated revoker to the generated key. Algo is the public\n            key algorithm of the designated revoker (i.e. RSA=1, DSA=17, etc.)\n            fpr is the fingerprint of the designated revoker. The optional\n            ‘sensitive’ flag marks the designated revoker as sensitive\n            information. Only v4 keys may be designated revokers.\n\n        :param str keyserver: This is an optional parameter that specifies the\n            preferred keyserver URL for the key.\n\n        :param str handle: This is an optional parameter only used with the\n            status lines ``KEY_CREATED`` and ``KEY_NOT_CREATED``. string may\n            be up to 100 characters and should not contain spaces. It is\n            useful for batch key generation to associate a key parameter block\n            with a status line.\n\n        :rtype: str\n        :returns: A suitable input string for the :meth:`GPG.gen_key` method,\n            the latter of which will create the new keypair.\n\n        See `this GnuPG Manual section`__ for more details.\n\n        __ http://www.gnupg.org/documentation/manuals/gnupg-devel/Unattended-GPG-key-generation.html\n        \"\"\"\n        #: A boolean for determining whether to set subkey_type to 'default'\n        default_type = False\n\n        parms = {}\n\n        parms.setdefault(\"Key-Type\", \"default\")\n        log.debug(\n            \"GnuPG v{} detected: setting default key type to {}.\".format(\n                self.binary_version, parms[\"Key-Type\"]\n            )\n        )\n        parms.setdefault(\"Key-Length\", 4096)\n        parms.setdefault(\"Name-Real\", \"Autogenerated Key\")\n        parms.setdefault(\"Expire-Date\", _util._next_year())\n\n        name_email = kwargs.get(\"name_email\")\n        uidemail = _util.create_uid_email(name_email)\n        parms.setdefault(\"Name-Email\", uidemail)\n\n        if testing:\n            # This specific comment string is required by (some? all?)\n            # versions of GnuPG to use the insecure PRNG:\n            parms.setdefault(\"Name-Comment\", \"insecure!\")\n\n        for key, val in list(kwargs.items()):\n            key = key.replace(\"_\", \"-\").title()\n            # to set 'cert', 'Key-Usage' must be blank string\n            if key not in (\"Key-Usage\", \"Subkey-Usage\") and str(val).strip():\n                parms[key] = val\n\n        # if Key-Type is 'default', make Subkey-Type also be 'default'\n        if parms[\"Key-Type\"] == \"default\":\n            default_type = True\n            for field in (\n                \"Key-Usage\",\n                \"Subkey-Usage\",\n            ):\n                try:\n                    parms.pop(field)  # toss these out, handle manually\n                except KeyError:\n                    pass\n\n        # Key-Type must come first, followed by length\n        out = \"Key-Type: %s\\n\" % parms.pop(\"Key-Type\")\n        out += \"Key-Length: %d\\n\" % parms.pop(\"Key-Length\")\n        if \"Subkey-Type\" in parms:\n            out += \"Subkey-Type: %s\\n\" % parms.pop(\"Subkey-Type\")\n        elif default_type:\n            out += \"Subkey-Type: default\\n\"\n        if \"Subkey-Length\" in parms:\n            out += \"Subkey-Length: %s\\n\" % parms.pop(\"Subkey-Length\")\n\n        for key, val in list(parms.items()):\n            out += f\"{key}: {val}\\n\"\n\n        # There is a problem where, in the batch files, if the '%%pubring'\n        # and '%%secring' are given as any static string, i.e. 'pubring.gpg',\n        # that file will always get rewritten without confirmation, killing\n        # off any keys we had before. So in the case where we wish to\n        # generate a bunch of keys and then do stuff with them, we should not\n        # give 'pubring.gpg' as our keyring file, otherwise we will lose any\n        # keys we had previously.\n\n        if separate_keyring:\n            ring = str(uidemail + \"_\" + str(int(time.time())))\n            self.temp_keyring = os.path.join(self.homedir, ring + \".pubring\")\n            self.temp_secring = os.path.join(self.homedir, ring + \".secring\")\n            out += \"%%pubring %s\\n\" % self.temp_keyring\n            out += \"%%secring %s\\n\" % self.temp_secring\n\n        if testing:\n            # see TODO file, tag :compatibility:gen_key_input:\n            #\n            # Add version detection before the '%no-protection' flag.\n            out += \"%no-protection\\n\"\n            out += \"%transient-key\\n\"\n\n        out += \"%commit\\n\"\n\n        # if we've been asked to save a copy of the batch file:\n        if save_batchfile and parms[\"Name-Email\"] != uidemail:\n            asc_uid = encodings.normalize_encoding(parms[\"Name-Email\"])\n            filename = _fix_unsafe(asc_uid) + _util._now() + \".batch\"\n            save_as = os.path.join(self._batch_dir, filename)\n            readme = os.path.join(self._batch_dir, \"README\")\n\n            if not os.path.exists(self._batch_dir):\n                os.makedirs(self._batch_dir)\n\n                # the following pulls the link to GnuPG's online batchfile\n                # documentation from this function's docstring and sticks it\n                # in a README file in the batch directory:\n\n                if getattr(self.gen_key_input, \"__doc__\", None) is not None:\n                    docs = self.gen_key_input.__doc__\n                else:\n                    docs = \"\"  # docstring=None if run with \"python -OO\"\n                links = \"\\n\".join(x.strip() for x in docs.splitlines()[-2:])\n                explain = f\"\"\"\nThis directory was created by python-gnupg, on {_util.now()}, and\nit contains saved batch files, which can be given to GnuPG to automatically\ngenerate keys. Please see\n{links}\"\"\"  # sometimes python is awesome.\n\n                with open(readme, \"a+\") as fh:\n                    [fh.write(line) for line in explain]\n\n            with open(save_as, \"a+\") as batch_file:\n                [batch_file.write(line) for line in out]\n\n        return out\n\n    def encrypt(self, data, *recipients, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Encrypt the message contained in ``data`` to ``recipients``.\n\n        :param str data: The file or bytestream to encrypt.\n\n        :param str recipients: The recipients to encrypt to. Recipients must\n            be specified keyID/fingerprint. Care should be taken in Python2.x\n            to make sure that the given fingerprint is in fact a string and\n            not a unicode object.  Multiple recipients may be specified by\n            doing ``GPG.encrypt(data, fpr1, fpr2, fpr3)`` etc.\n\n        :param str default_key: The keyID/fingerprint of the key to use for\n            signing. If given, ``data`` will be encrypted and signed.\n\n        :param str passphrase: If given, and ``default_key`` is also given,\n            use this passphrase to unlock the secret portion of the\n            ``default_key`` to sign the encrypted ``data``. Otherwise, if\n            ``default_key`` is not given, but ``symmetric=True``, then use\n            this passphrase as the passphrase for symmetric\n            encryption. Signing and symmetric encryption should *not* be\n            combined when sending the ``data`` to other recipients, else the\n            passphrase to the secret key would be shared with them.\n\n        :param bool armor: If True, ascii armor the output; otherwise, the\n            output will be in binary format. (Default: True)\n\n        :param bool encrypt: If True, encrypt the ``data`` using the\n            ``recipients`` public keys. (Default: True)\n\n        :param bool symmetric: If True, encrypt the ``data`` to ``recipients``\n            using a symmetric key. See the ``passphrase`` parameter. Symmetric\n            encryption and public key encryption can be used simultaneously,\n            and will result in a ciphertext which is decryptable with either\n            the symmetric ``passphrase`` or one of the corresponding private\n            keys.\n\n        :param bool always_trust: If True, ignore trust warnings on recipient\n            keys. If False, display trust warnings.  (default: True)\n\n        :param str output: The output file to write to. If not specified, the\n            encrypted output is returned, and thus should be stored as an\n            object in Python. For example:\n\n        >>> import shutil\n        >>> import gnupg\n        >>> if os.path.exists(\"doctests\"):\n        ...     shutil.rmtree(\"doctests\")\n        >>> gpg = gnupg.GPG(homedir=\"doctests\")\n        >>> key_settings = gpg.gen_key_input(key_type='RSA',\n        ...     key_length=1024,\n        ...     key_usage='ESCA',\n        ...     passphrase='foo')\n        >>> key = gpg.gen_key(key_settings)\n        >>> message = \"The crow flies at midnight.\"\n        >>> encrypted = str(gpg.encrypt(message, key.fingerprint))\n        >>> assert encrypted != message\n        >>> assert not encrypted.isspace()\n        >>> decrypted = str(gpg.decrypt(encrypted, passphrase='foo'))\n        >>> assert not decrypted.isspace()\n        >>> decrypted\n        'The crow flies at midnight.'\n\n\n        :param bool throw_keyids: If True, make all **recipients** keyids be\n            zero'd out in packet information. This is the same as using\n            **hidden_recipients** for all **recipients**. (Default: False).\n\n        :param list hidden_recipients: A list of recipients that should have\n            their keyids zero'd out in packet information.\n\n        :param str cipher_algo: The cipher algorithm to use. To see available\n            algorithms with your version of GnuPG, do:\n            :command:`$ gpg --with-colons --list-config ciphername`.\n            The default ``cipher_algo``, if unspecified, is ``'AES256'``.\n\n        :param str digest_algo: The hash digest to use. Again, to see which\n            hashes your GnuPG is capable of using, do:\n            :command:`$ gpg --with-colons --list-config digestname`.\n            The default, if unspecified, is ``'SHA512'``.\n\n        :param str compress_algo: The compression algorithm to use. Can be one\n            of ``'ZLIB'``, ``'BZIP2'``, ``'ZIP'``, or ``'Uncompressed'``.\n\n        .. seealso:: :meth:`._encrypt`\n        \"\"\"\n        if _is_stream(data):\n            stream = data\n        else:\n            stream = _make_binary_stream(data, self._encoding)\n        result = self._encrypt(stream, recipients, **kwargs)\n        stream.close()\n        return result\n\n    def decrypt(self, message, **kwargs):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a string or file-like object ``message``.\n\n        :type message: file or str or :class:`io.BytesIO`\n        :param message: A string or file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        stream = _make_binary_stream(message, self._encoding) # Untested\n        result = self.decrypt_file(stream, **kwargs) # Untested\n        stream.close() # Untested\n        return result # Untested\n\n    def decrypt_file(self, filename, always_trust=False, passphrase=None, output=None):  # type: ignore[no-untyped-def]\n        \"\"\"Decrypt the contents of a file-like object ``filename`` .\n\n        :param str filename: A file-like object to decrypt.\n        :param bool always_trust: Instruct GnuPG to ignore trust checks.\n        :param str passphrase: The passphrase for the secret key used for decryption.\n        :param str output: A filename to write the decrypted output to.\n        \"\"\"\n        args = [\"--decrypt\"]\n        if output:  # write the output to a file with the specified name\n            if os.path.exists(output):\n                os.remove(output)  # to avoid overwrite confirmation message\n            args.append(\"--output %s\" % output)\n        if always_trust:\n            args.append(\"--always-trust\")\n        result = self._result_map[\"crypt\"](self)\n        self._handle_io(args, filename, result, passphrase, binary=True)\n        log.debug(\"decrypt result: %r\", result.data)\n        return result",
        "callGraphToTestedFunction": [
          "decrypt"
        ]
      },
      "unitTestFilePath": "tests/test_encryption.py"
    },
    {
      "functionName": "shred",
      "file": "rm.py",
      "callGraph": [
        {
          "file": "rm.py",
          "functionName": "shred",
          "lines": [
            {
              "startLine": 40,
              "endLine": 41
            },
            {
              "startLine": 43,
              "endLine": 49
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_rm.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "rm.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "shred",
          "filePath": "rm.py",
          "uncoveredLines": [
            {
              "startLine": 40,
              "endLine": 41
            },
            {
              "startLine": 43,
              "endLine": 49
            }
          ]
        },
        "uncoveredFnBody": "def shred(path: str, delete: bool = True) -> None:\n    \"\"\"\n    Run shred on the file at the given path.\n\n    Args:\n        path (str): The path to the file to shred.\n        delete (bool): Whether to unlink the file after shredding.\n\n    Returns:\n        None\n\n    Raises:\n        subprocess.CalledProcessError: If shred's return code is not zero.\n        EnvironmentError: If shred is not available.\n    \"\"\"\n\n    if not os.path.exists(path):\n        raise OSError(path)\n\n    if not os.path.isfile(path): # Untested\n        raise ValueError(\"The shred function only works on files.\") # Untested\n    cmd = [\"shred\", \"-z\", \"-n\", \"30\"] # Untested\n    if delete: # Untested\n        cmd.append(\"-u\") # Untested\n    cmd.append(path) # Untested\n    subprocess.check_call(cmd) # Untested",
        "callGraphToTestedFunction": [
          "shred"
        ]
      },
      "unitTestFilePath": "tests/test_rm.py"
    },
    {
      "functionName": "secure_delete",
      "file": "rm.py",
      "callGraph": [
        {
          "file": "rm.py",
          "functionName": "secure_delete",
          "lines": [
            {
              "startLine": 66,
              "endLine": 66
            },
            {
              "startLine": 68,
              "endLine": 71
            },
            {
              "startLine": 73,
              "endLine": 77
            },
            {
              "startLine": 79,
              "endLine": 80
            },
            {
              "startLine": 82,
              "endLine": 84
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_rm.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "rm.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "secure_delete",
          "filePath": "rm.py",
          "uncoveredLines": [
            {
              "startLine": 66,
              "endLine": 66
            },
            {
              "startLine": 68,
              "endLine": 71
            },
            {
              "startLine": 73,
              "endLine": 77
            },
            {
              "startLine": 79,
              "endLine": 80
            },
            {
              "startLine": 82,
              "endLine": 84
            }
          ]
        },
        "uncoveredFnBody": "def secure_delete(path: str) -> None:\n    \"\"\"\n    Securely deletes the file at ``path``.\n\n    Args:\n        path (str): The path to the file to delete.\n\n    Returns:\n        str: A string signaling success to rq.\n\n    Raises:\n        subprocess.CalledProcessError: If shred's return code is not zero.\n        EnvironmentError: If shred is not available.\n    \"\"\"\n    path = os.path.abspath(path)\n\n    directories = []\n    targets = []\n    if not os.path.isdir(path):\n        targets.append(path)\n    else:\n        for directory, subdirs, files in os.walk(path): # Untested\n            directories.append(directory) # Untested\n            directories.extend([os.path.abspath(os.path.join(directory, s)) for s in subdirs]) # Untested\n            for f in files: # Untested\n                targets.append(os.path.abspath(os.path.join(directory, f))) # Untested\n\n    for t in targets:\n        shred(t)\n\n    directories_to_remove = set(directories)\n    for d in reversed(sorted(directories_to_remove)):\n        os.rmdir(d)",
        "callGraphToTestedFunction": [
          "secure_delete"
        ]
      },
      "unitTestFilePath": "tests/test_rm.py"
    },
    {
      "functionName": "check_secure_delete_capability",
      "file": "rm.py",
      "callGraph": [
        {
          "file": "rm.py",
          "functionName": "check_secure_delete_capability",
          "lines": [
            {
              "startLine": 97,
              "endLine": 103
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_rm.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "rm.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "check_secure_delete_capability",
          "filePath": "rm.py",
          "uncoveredLines": [
            {
              "startLine": 97,
              "endLine": 103
            }
          ]
        },
        "uncoveredFnBody": "def check_secure_delete_capability() -> bool:\n    \"\"\"\n    Checks the availability of the program we use for secure deletion.\n\n    Returns:\n        bool: True if the program is available, otherwise False.\n    \"\"\"\n    try:\n        subprocess.check_output([\"shred\", \"--help\"])\n        return True\n    except OSError as e: # Untested\n        if e.errno != errno.ENOENT: # Untested\n            raise # Untested\n        logging.error(\"The shred utility is missing.\") # Untested\n    except subprocess.CalledProcessError as e: # Untested\n        logging.error(\"The shred utility is broken: %s %s\", e, e.output) # Untested\n    return False # Untested",
        "callGraphToTestedFunction": [
          "check_secure_delete_capability"
        ]
      },
      "unitTestFilePath": "tests/test_rm.py"
    },
    {
      "functionName": "_parse_config_from_file",
      "file": "sdconfig.py",
      "callGraph": [
        {
          "file": "sdconfig.py",
          "functionName": "_parse_config_from_file",
          "lines": [
            {
              "startLine": 112,
              "endLine": 112
            },
            {
              "startLine": 117,
              "endLine": 119
            },
            {
              "startLine": 121,
              "endLine": 121
            },
            {
              "startLine": 123,
              "endLine": 126
            },
            {
              "startLine": 128,
              "endLine": 128
            },
            {
              "startLine": 130,
              "endLine": 133
            },
            {
              "startLine": 135,
              "endLine": 138
            },
            {
              "startLine": 140,
              "endLine": 143
            },
            {
              "startLine": 145,
              "endLine": 148
            },
            {
              "startLine": 150,
              "endLine": 153
            },
            {
              "startLine": 155,
              "endLine": 158
            },
            {
              "startLine": 160,
              "endLine": 163
            },
            {
              "startLine": 165,
              "endLine": 168
            },
            {
              "startLine": 170,
              "endLine": 173
            },
            {
              "startLine": 175,
              "endLine": 178
            },
            {
              "startLine": 181,
              "endLine": 182
            },
            {
              "startLine": 191,
              "endLine": 192
            },
            {
              "startLine": 202,
              "endLine": 202
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_config.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "sdconfig.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "_parse_config_from_file",
          "filePath": "sdconfig.py",
          "uncoveredLines": [
            {
              "startLine": 112,
              "endLine": 112
            },
            {
              "startLine": 117,
              "endLine": 119
            },
            {
              "startLine": 121,
              "endLine": 121
            },
            {
              "startLine": 123,
              "endLine": 126
            },
            {
              "startLine": 128,
              "endLine": 128
            },
            {
              "startLine": 130,
              "endLine": 133
            },
            {
              "startLine": 135,
              "endLine": 138
            },
            {
              "startLine": 140,
              "endLine": 143
            },
            {
              "startLine": 145,
              "endLine": 148
            },
            {
              "startLine": 150,
              "endLine": 153
            },
            {
              "startLine": 155,
              "endLine": 158
            },
            {
              "startLine": 160,
              "endLine": 163
            },
            {
              "startLine": 165,
              "endLine": 168
            },
            {
              "startLine": 170,
              "endLine": 173
            },
            {
              "startLine": 175,
              "endLine": 178
            },
            {
              "startLine": 181,
              "endLine": 182
            },
            {
              "startLine": 191,
              "endLine": 192
            },
            {
              "startLine": 202,
              "endLine": 202
            }
          ]
        },
        "uncoveredFnBody": "def _parse_config_from_file(config_module_name: str) -> SecureDropConfig:\n    \"\"\"Parse the config from a config.py file.\"\"\"\n    config_from_local_file = import_module(config_module_name)\n\n    # Parse the local config; as there are SD instances with very old config files\n    # the parsing logic here has to assume some values might be missing, and hence\n    # set default values for such config entries\n    final_default_locale = getattr(config_from_local_file, \"DEFAULT_LOCALE\", FALLBACK_LOCALE)\n    final_supp_locales = getattr(config_from_local_file, \"SUPPORTED_LOCALES\", [FALLBACK_LOCALE])\n    final_sess_expiration_mins = getattr(config_from_local_file, \"SESSION_EXPIRATION_MINUTES\", 120)\n\n    final_worker_name = getattr(config_from_local_file, \"RQ_WORKER_NAME\", \"default\")\n\n    final_scrypt_params = getattr(config_from_local_file, \"SCRYPT_PARAMS\", dict(N=2**14, r=8, p=1))\n    final_redis_password = getattr(config_from_local_file, \"REDIS_PASSWORD\", None)\n    if final_redis_password is None:\n        raise RuntimeError(\"REDIS_PASSWORD must be set in config.py\")\n\n    env = getattr(config_from_local_file, \"env\", \"prod\")\n\n    try:\n        final_securedrop_root = Path(config_from_local_file.SECUREDROP_ROOT)\n    except AttributeError:\n        final_securedrop_root = DEFAULT_SECUREDROP_ROOT\n\n    try:\n        final_securedrop_data_root = Path(config_from_local_file.SECUREDROP_DATA_ROOT)\n    except AttributeError:\n        final_securedrop_data_root = Path(\"/var/lib/securedrop\")\n\n    try:\n        final_db_file = Path(config_from_local_file.DATABASE_FILE)\n    except AttributeError:\n        final_db_file = final_securedrop_data_root / \"db.sqlite\"\n\n    try:\n        final_gpg_key_dir = Path(config_from_local_file.GPG_KEY_DIR)\n    except AttributeError:\n        final_gpg_key_dir = final_securedrop_data_root / \"keys\"\n\n    try:\n        final_nouns = Path(config_from_local_file.NOUNS)\n    except AttributeError:\n        final_nouns = final_securedrop_root / \"dictionaries\" / \"nouns.txt\"\n\n    try:\n        final_adjectives = Path(config_from_local_file.ADJECTIVES)\n    except AttributeError:\n        final_adjectives = final_securedrop_root / \"dictionaries\" / \"adjectives.txt\"\n\n    try:\n        final_static_dir = Path(config_from_local_file.STATIC_DIR)  # type: ignore\n    except AttributeError:\n        final_static_dir = final_securedrop_root / \"static\"\n\n    try:\n        final_transl_dir = Path(config_from_local_file.TRANSLATION_DIRS)  # type: ignore\n    except AttributeError:\n        final_transl_dir = final_securedrop_root / \"translations\"\n\n    try:\n        final_source_tmpl_dir = Path(config_from_local_file.SOURCE_TEMPLATES_DIR)\n    except AttributeError:\n        final_source_tmpl_dir = final_securedrop_root / \"source_templates\"\n\n    try: # Untested\n        final_journ_tmpl_dir = Path(config_from_local_file.JOURNALIST_TEMPLATES_DIR) # Untested\n    except AttributeError: # Untested\n        final_journ_tmpl_dir = final_securedrop_root / \"journalist_templates\" # Untested\n\n    # Parse the Flask configurations\n    journ_flask_config = config_from_local_file.JournalistInterfaceFlaskConfig\n    parsed_journ_flask_config = JournalistInterfaceConfig(\n        SECRET_KEY=journ_flask_config.SECRET_KEY,\n        SESSION_COOKIE_NAME=getattr(journ_flask_config, \"SESSION_COOKIE_NAME\", \"js\"),\n        DEBUG=getattr(journ_flask_config, \"DEBUG\", False),\n        TESTING=getattr(journ_flask_config, \"TESTING\", False),\n        WTF_CSRF_ENABLED=getattr(journ_flask_config, \"WTF_CSRF_ENABLED\", True),\n        MAX_CONTENT_LENGTH=getattr(journ_flask_config, \"MAX_CONTENT_LENGTH\", 524288000),\n        USE_X_SENDFILE=getattr(journ_flask_config, \"USE_X_SENDFILE\", False),\n    )\n    source_flask_config = config_from_local_file.SourceInterfaceFlaskConfig\n    parsed_source_flask_config = SourceInterfaceConfig(\n        SECRET_KEY=source_flask_config.SECRET_KEY,\n        SESSION_COOKIE_NAME=getattr(journ_flask_config, \"SESSION_COOKIE_NAME\", \"ss\"),\n        DEBUG=getattr(journ_flask_config, \"DEBUG\", False),\n        TESTING=getattr(journ_flask_config, \"TESTING\", False),\n        WTF_CSRF_ENABLED=getattr(journ_flask_config, \"WTF_CSRF_ENABLED\", True),\n        MAX_CONTENT_LENGTH=getattr(journ_flask_config, \"MAX_CONTENT_LENGTH\", 524288000),\n        USE_X_SENDFILE=getattr(journ_flask_config, \"USE_X_SENDFILE\", False),\n    )\n\n    return SecureDropConfig(\n        env=env,\n        JOURNALIST_APP_FLASK_CONFIG_CLS=parsed_journ_flask_config,\n        SOURCE_APP_FLASK_CONFIG_CLS=parsed_source_flask_config,\n        GPG_KEY_DIR=final_gpg_key_dir,\n        JOURNALIST_KEY=config_from_local_file.JOURNALIST_KEY,\n        SCRYPT_GPG_PEPPER=config_from_local_file.SCRYPT_GPG_PEPPER,\n        SCRYPT_ID_PEPPER=config_from_local_file.SCRYPT_ID_PEPPER,\n        SCRYPT_PARAMS=final_scrypt_params,\n        SECUREDROP_DATA_ROOT=final_securedrop_data_root,\n        SECUREDROP_ROOT=final_securedrop_root,\n        DATABASE_FILE=final_db_file,\n        STATIC_DIR=final_static_dir,\n        TRANSLATION_DIRS=final_transl_dir,\n        SOURCE_TEMPLATES_DIR=final_source_tmpl_dir,\n        JOURNALIST_TEMPLATES_DIR=final_journ_tmpl_dir,\n        NOUNS=final_nouns,\n        ADJECTIVES=final_adjectives,\n        DEFAULT_LOCALE=final_default_locale,\n        SUPPORTED_LOCALES=final_supp_locales,\n        SESSION_EXPIRATION_MINUTES=final_sess_expiration_mins,\n        RQ_WORKER_NAME=final_worker_name,\n        REDIS_PASSWORD=final_redis_password,\n    )",
        "callGraphToTestedFunction": [
          "_parse_config_from_file"
        ]
      },
      "unitTestFilePath": "tests/test_config.py"
    },
    {
      "functionName": "write",
      "file": "secure_tempfile.py",
      "callGraph": [
        {
          "file": "secure_tempfile.py",
          "functionName": "write",
          "lines": [
            {
              "startLine": 84,
              "endLine": 84
            },
            {
              "startLine": 88,
              "endLine": 88
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_secure_tempfile.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "secure_tempfile.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "write",
          "filePath": "secure_tempfile.py",
          "uncoveredLines": [
            {
              "startLine": 84,
              "endLine": 84
            },
            {
              "startLine": 88,
              "endLine": 88
            }
          ]
        },
        "uncoveredFnBody": "class SecureTemporaryFile(_TemporaryFileWrapper):\n    \"\"\"Temporary file that provides on-the-fly encryption.\n\n    Buffering large submissions in memory as they come in requires too\n    much memory for too long a period. By writing the file to disk as it\n    comes in using a stream cipher, we are able to minimize memory usage\n    as submissions come in, while minimizing the chances of plaintext\n    recovery through forensic disk analysis. They key used to encrypt\n    each secure temporary file is also ephemeral, and is only stored in\n    memory only for as long as needed.\n\n    Adapted from Globaleaks' GLSecureTemporaryFile:\n    https://github.com/globaleaks/GlobaLeaks/blob/master/backend/globaleaks/security.py#L35\n\n    WARNING: you can't use this like a normal file object. It supports\n    being appended to however many times you wish (although content may not be\n    overwritten), and then it's contents may be read only once (although it may\n    be done in chunks) and only after it's been written to.\n    \"\"\"\n\n    AES_key_size = 256\n    AES_block_size = 128\n\n    def __init__(self, store_dir: str) -> None:\n        \"\"\"Generates an AES key and an initialization vector, and opens\n        a file in the `store_dir` directory with a\n        pseudorandomly-generated filename.\n\n        Args:\n            store_dir (str): the directory to create the secure\n                temporary file under.\n\n        Returns: self\n        \"\"\"\n        self.last_action = \"init\"\n        self.create_key()\n\n        data = base64.urlsafe_b64encode(os.urandom(32))\n        self.tmp_file_id = data.decode(\"utf-8\").strip(\"=\")\n\n        self.filepath = os.path.join(store_dir, f\"{self.tmp_file_id}.aes\")\n        self.file = open(self.filepath, \"w+b\")\n        super().__init__(self.file, self.filepath)\n\n    def create_key(self) -> None:\n        \"\"\"Generates a unique, pseudorandom AES key, stored ephemerally in\n        memory as an instance attribute. Its destruction is ensured by the\n        automatic nightly reboots of the SecureDrop application server combined\n        with the freed memory-overwriting PAX_MEMORY_SANITIZE feature of the\n        grsecurity-patched kernel it uses (for further details consult\n        https://github.com/freedomofpress/securedrop/pull/477#issuecomment-168445450).\n        \"\"\"\n        self.key = os.urandom(self.AES_key_size // 8)\n        self.iv = os.urandom(self.AES_block_size // 8)\n        self.initialize_cipher()\n\n    def initialize_cipher(self) -> None:\n        \"\"\"Creates the cipher-related objects needed for AES-CTR\n        encryption and decryption.\n        \"\"\"\n        self.cipher = Cipher(AES(self.key), CTR(self.iv), default_backend())\n        self.encryptor = self.cipher.encryptor()\n        self.decryptor = self.cipher.decryptor()\n\n    def write(self, data: Union[bytes, str]) -> int:\n        \"\"\"Write `data` to the secure temporary file. This method may be\n        called any number of times following instance initialization,\n        but after calling :meth:`read`, you cannot write to the file\n        again.\n        \"\"\"\n        if self.last_action == \"read\":\n            raise AssertionError(\"You cannot write after reading!\")\n        self.last_action = \"write\"\n\n        if isinstance(data, str):\n            data_as_bytes = data.encode(\"utf-8\") # Untested\n        else:\n            data_as_bytes = data\n\n        return self.file.write(self.encryptor.update(data_as_bytes))\n\n    def read(self, count: Optional[int] = None) -> bytes:\n        \"\"\"Read `data` from the secure temporary file. This method may\n        be called any number of times following instance initialization\n        and once :meth:`write has been called at least once, but not\n        before.\n\n        Before the first read operation, `seek(0, 0)` is called. So\n        while you can call this method any number of times, the full\n        contents of the file can only be read once. Additional calls to\n        read will return an empty str, which is desired behavior in that\n        it matches :class:`file` and because other modules depend on\n        this behavior to let them know they've reached the end of the\n        file.\n\n        Args:\n            count (int): the number of bytes to try to read from the\n                file from the current position.\n        \"\"\"\n        if self.last_action == \"init\":\n            raise AssertionError(\"You must write before reading!\")\n        if self.last_action == \"write\":\n            self.seek(0, 0)\n            self.last_action = \"read\"\n\n        if count:\n            return self.decryptor.update(self.file.read(count))\n        else:\n            return self.decryptor.update(self.file.read())\n\n    def close(self) -> None:\n        \"\"\"The __del__ method in tempfile._TemporaryFileWrapper (which\n        SecureTemporaryFile class inherits from) calls close() when the\n        temporary file is deleted.\n        \"\"\"\n        try:\n            self.decryptor.finalize()\n        except AlreadyFinalized:\n            pass\n\n        # Since tempfile._TemporaryFileWrapper.close() does other cleanup,\n        # (i.e. deleting the temp file on disk), we need to call it also.\n        super().close()",
        "callGraphToTestedFunction": [
          "write"
        ]
      },
      "unitTestFilePath": "tests/test_secure_tempfile.py"
    },
    {
      "functionName": "read",
      "file": "secure_tempfile.py",
      "callGraph": [
        {
          "file": "secure_tempfile.py",
          "functionName": "read",
          "lines": [
            {
              "startLine": 113,
              "endLine": 113
            },
            {
              "startLine": 121,
              "endLine": 121
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_secure_tempfile.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "secure_tempfile.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "read",
          "filePath": "secure_tempfile.py",
          "uncoveredLines": [
            {
              "startLine": 113,
              "endLine": 113
            },
            {
              "startLine": 121,
              "endLine": 121
            }
          ]
        },
        "uncoveredFnBody": "class SecureTemporaryFile(_TemporaryFileWrapper):\n    \"\"\"Temporary file that provides on-the-fly encryption.\n\n    Buffering large submissions in memory as they come in requires too\n    much memory for too long a period. By writing the file to disk as it\n    comes in using a stream cipher, we are able to minimize memory usage\n    as submissions come in, while minimizing the chances of plaintext\n    recovery through forensic disk analysis. They key used to encrypt\n    each secure temporary file is also ephemeral, and is only stored in\n    memory only for as long as needed.\n\n    Adapted from Globaleaks' GLSecureTemporaryFile:\n    https://github.com/globaleaks/GlobaLeaks/blob/master/backend/globaleaks/security.py#L35\n\n    WARNING: you can't use this like a normal file object. It supports\n    being appended to however many times you wish (although content may not be\n    overwritten), and then it's contents may be read only once (although it may\n    be done in chunks) and only after it's been written to.\n    \"\"\"\n\n    AES_key_size = 256\n    AES_block_size = 128\n\n    def __init__(self, store_dir: str) -> None:\n        \"\"\"Generates an AES key and an initialization vector, and opens\n        a file in the `store_dir` directory with a\n        pseudorandomly-generated filename.\n\n        Args:\n            store_dir (str): the directory to create the secure\n                temporary file under.\n\n        Returns: self\n        \"\"\"\n        self.last_action = \"init\"\n        self.create_key()\n\n        data = base64.urlsafe_b64encode(os.urandom(32))\n        self.tmp_file_id = data.decode(\"utf-8\").strip(\"=\")\n\n        self.filepath = os.path.join(store_dir, f\"{self.tmp_file_id}.aes\")\n        self.file = open(self.filepath, \"w+b\")\n        super().__init__(self.file, self.filepath)\n\n    def create_key(self) -> None:\n        \"\"\"Generates a unique, pseudorandom AES key, stored ephemerally in\n        memory as an instance attribute. Its destruction is ensured by the\n        automatic nightly reboots of the SecureDrop application server combined\n        with the freed memory-overwriting PAX_MEMORY_SANITIZE feature of the\n        grsecurity-patched kernel it uses (for further details consult\n        https://github.com/freedomofpress/securedrop/pull/477#issuecomment-168445450).\n        \"\"\"\n        self.key = os.urandom(self.AES_key_size // 8)\n        self.iv = os.urandom(self.AES_block_size // 8)\n        self.initialize_cipher()\n\n    def initialize_cipher(self) -> None:\n        \"\"\"Creates the cipher-related objects needed for AES-CTR\n        encryption and decryption.\n        \"\"\"\n        self.cipher = Cipher(AES(self.key), CTR(self.iv), default_backend())\n        self.encryptor = self.cipher.encryptor()\n        self.decryptor = self.cipher.decryptor()\n\n    def write(self, data: Union[bytes, str]) -> int:\n        \"\"\"Write `data` to the secure temporary file. This method may be\n        called any number of times following instance initialization,\n        but after calling :meth:`read`, you cannot write to the file\n        again.\n        \"\"\"\n        if self.last_action == \"read\":\n            raise AssertionError(\"You cannot write after reading!\")\n        self.last_action = \"write\"\n\n        if isinstance(data, str):\n            data_as_bytes = data.encode(\"utf-8\")\n        else:\n            data_as_bytes = data\n\n        return self.file.write(self.encryptor.update(data_as_bytes))\n\n    def read(self, count: Optional[int] = None) -> bytes:\n        \"\"\"Read `data` from the secure temporary file. This method may\n        be called any number of times following instance initialization\n        and once :meth:`write has been called at least once, but not\n        before.\n\n        Before the first read operation, `seek(0, 0)` is called. So\n        while you can call this method any number of times, the full\n        contents of the file can only be read once. Additional calls to\n        read will return an empty str, which is desired behavior in that\n        it matches :class:`file` and because other modules depend on\n        this behavior to let them know they've reached the end of the\n        file.\n\n        Args:\n            count (int): the number of bytes to try to read from the\n                file from the current position.\n        \"\"\"\n        if self.last_action == \"init\":\n            raise AssertionError(\"You must write before reading!\")\n        if self.last_action == \"write\":\n            self.seek(0, 0)\n            self.last_action = \"read\"\n\n        if count:\n            return self.decryptor.update(self.file.read(count))\n        else:\n            return self.decryptor.update(self.file.read()) # Untested\n\n    def close(self) -> None:\n        \"\"\"The __del__ method in tempfile._TemporaryFileWrapper (which\n        SecureTemporaryFile class inherits from) calls close() when the\n        temporary file is deleted.\n        \"\"\"\n        try:\n            self.decryptor.finalize()\n        except AlreadyFinalized:\n            pass\n\n        # Since tempfile._TemporaryFileWrapper.close() does other cleanup,\n        # (i.e. deleting the temp file on disk), we need to call it also.\n        super().close()",
        "callGraphToTestedFunction": [
          "read"
        ]
      },
      "unitTestFilePath": "tests/test_secure_tempfile.py"
    },
    {
      "functionName": "close",
      "file": "secure_tempfile.py",
      "callGraph": [
        {
          "file": "secure_tempfile.py",
          "functionName": "close",
          "lines": [
            {
              "startLine": 130,
              "endLine": 131
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_secure_tempfile.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "secure_tempfile.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "close",
          "filePath": "secure_tempfile.py",
          "uncoveredLines": [
            {
              "startLine": 130,
              "endLine": 131
            }
          ]
        },
        "uncoveredFnBody": "class SecureTemporaryFile(_TemporaryFileWrapper):\n    \"\"\"Temporary file that provides on-the-fly encryption.\n\n    Buffering large submissions in memory as they come in requires too\n    much memory for too long a period. By writing the file to disk as it\n    comes in using a stream cipher, we are able to minimize memory usage\n    as submissions come in, while minimizing the chances of plaintext\n    recovery through forensic disk analysis. They key used to encrypt\n    each secure temporary file is also ephemeral, and is only stored in\n    memory only for as long as needed.\n\n    Adapted from Globaleaks' GLSecureTemporaryFile:\n    https://github.com/globaleaks/GlobaLeaks/blob/master/backend/globaleaks/security.py#L35\n\n    WARNING: you can't use this like a normal file object. It supports\n    being appended to however many times you wish (although content may not be\n    overwritten), and then it's contents may be read only once (although it may\n    be done in chunks) and only after it's been written to.\n    \"\"\"\n\n    AES_key_size = 256\n    AES_block_size = 128\n\n    def __init__(self, store_dir: str) -> None:\n        \"\"\"Generates an AES key and an initialization vector, and opens\n        a file in the `store_dir` directory with a\n        pseudorandomly-generated filename.\n\n        Args:\n            store_dir (str): the directory to create the secure\n                temporary file under.\n\n        Returns: self\n        \"\"\"\n        self.last_action = \"init\"\n        self.create_key()\n\n        data = base64.urlsafe_b64encode(os.urandom(32))\n        self.tmp_file_id = data.decode(\"utf-8\").strip(\"=\")\n\n        self.filepath = os.path.join(store_dir, f\"{self.tmp_file_id}.aes\")\n        self.file = open(self.filepath, \"w+b\")\n        super().__init__(self.file, self.filepath)\n\n    def create_key(self) -> None:\n        \"\"\"Generates a unique, pseudorandom AES key, stored ephemerally in\n        memory as an instance attribute. Its destruction is ensured by the\n        automatic nightly reboots of the SecureDrop application server combined\n        with the freed memory-overwriting PAX_MEMORY_SANITIZE feature of the\n        grsecurity-patched kernel it uses (for further details consult\n        https://github.com/freedomofpress/securedrop/pull/477#issuecomment-168445450).\n        \"\"\"\n        self.key = os.urandom(self.AES_key_size // 8)\n        self.iv = os.urandom(self.AES_block_size // 8)\n        self.initialize_cipher()\n\n    def initialize_cipher(self) -> None:\n        \"\"\"Creates the cipher-related objects needed for AES-CTR\n        encryption and decryption.\n        \"\"\"\n        self.cipher = Cipher(AES(self.key), CTR(self.iv), default_backend())\n        self.encryptor = self.cipher.encryptor()\n        self.decryptor = self.cipher.decryptor()\n\n    def write(self, data: Union[bytes, str]) -> int:\n        \"\"\"Write `data` to the secure temporary file. This method may be\n        called any number of times following instance initialization,\n        but after calling :meth:`read`, you cannot write to the file\n        again.\n        \"\"\"\n        if self.last_action == \"read\":\n            raise AssertionError(\"You cannot write after reading!\")\n        self.last_action = \"write\"\n\n        if isinstance(data, str):\n            data_as_bytes = data.encode(\"utf-8\")\n        else:\n            data_as_bytes = data\n\n        return self.file.write(self.encryptor.update(data_as_bytes))\n\n    def read(self, count: Optional[int] = None) -> bytes:\n        \"\"\"Read `data` from the secure temporary file. This method may\n        be called any number of times following instance initialization\n        and once :meth:`write has been called at least once, but not\n        before.\n\n        Before the first read operation, `seek(0, 0)` is called. So\n        while you can call this method any number of times, the full\n        contents of the file can only be read once. Additional calls to\n        read will return an empty str, which is desired behavior in that\n        it matches :class:`file` and because other modules depend on\n        this behavior to let them know they've reached the end of the\n        file.\n\n        Args:\n            count (int): the number of bytes to try to read from the\n                file from the current position.\n        \"\"\"\n        if self.last_action == \"init\":\n            raise AssertionError(\"You must write before reading!\")\n        if self.last_action == \"write\":\n            self.seek(0, 0)\n            self.last_action = \"read\"\n\n        if count:\n            return self.decryptor.update(self.file.read(count))\n        else:\n            return self.decryptor.update(self.file.read())\n\n    def close(self) -> None:\n        \"\"\"The __del__ method in tempfile._TemporaryFileWrapper (which\n        SecureTemporaryFile class inherits from) calls close() when the\n        temporary file is deleted.\n        \"\"\"\n        try:\n            self.decryptor.finalize()\n        except AlreadyFinalized: # Untested\n            pass # Untested\n\n        # Since tempfile._TemporaryFileWrapper.close() does other cleanup,\n        # (i.e. deleting the temp file on disk), we need to call it also.\n        super().close()",
        "callGraphToTestedFunction": [
          "close"
        ]
      },
      "unitTestFilePath": "tests/test_secure_tempfile.py"
    },
    {
      "functionName": "get_logo_url",
      "file": "source_app/__init__.py",
      "callGraph": [
        {
          "file": "source_app/__init__.py",
          "functionName": "get_logo_url",
          "lines": [
            {
              "startLine": 25,
              "endLine": 25
            },
            {
              "startLine": 36,
              "endLine": 36
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_source.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "source_app/__init__.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_logo_url",
          "filePath": "source_app/__init__.py",
          "uncoveredLines": [
            {
              "startLine": 25,
              "endLine": 25
            },
            {
              "startLine": 36,
              "endLine": 36
            }
          ]
        },
        "uncoveredFnBody": "def get_logo_url(app: Flask) -> str:\n    if not app.static_folder:\n        raise FileNotFoundError\n\n    custom_logo_filename = \"i/custom_logo.png\"\n    default_logo_filename = \"i/logo.png\"\n    custom_logo_path = Path(app.static_folder) / custom_logo_filename\n    default_logo_path = Path(app.static_folder) / default_logo_filename\n    if custom_logo_path.is_file():\n        return url_for(\"static\", filename=custom_logo_filename)\n    elif default_logo_path.is_file():\n        return url_for(\"static\", filename=default_logo_filename)\n\n    raise FileNotFoundError # Untested",
        "callGraphToTestedFunction": [
          "get_logo_url"
        ]
      },
      "unitTestFilePath": "tests/test_source.py"
    },
    {
      "functionName": "create_app",
      "file": "source_app/__init__.py",
      "callGraph": [
        {
          "file": "source_app/__init__.py",
          "functionName": "create_app",
          "lines": [
            {
              "startLine": 101,
              "endLine": 102
            },
            {
              "startLine": 118,
              "endLine": 120
            },
            {
              "startLine": 129,
              "endLine": 129
            },
            {
              "startLine": 139,
              "endLine": 141
            },
            {
              "startLine": 143,
              "endLine": 143
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_alembic.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "source_app/__init__.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "create_app",
          "filePath": "source_app/__init__.py",
          "uncoveredLines": [
            {
              "startLine": 101,
              "endLine": 102
            },
            {
              "startLine": 118,
              "endLine": 120
            },
            {
              "startLine": 129,
              "endLine": 129
            },
            {
              "startLine": 139,
              "endLine": 141
            },
            {
              "startLine": 143,
              "endLine": 143
            }
          ]
        },
        "uncoveredFnBody": "def create_app(config: SecureDropConfig) -> Flask:\n    app = Flask(\n        __name__,\n        template_folder=str(config.SOURCE_TEMPLATES_DIR.absolute()),\n        static_folder=config.STATIC_DIR.absolute(),\n    )\n    app.request_class = RequestThatSecuresFileUploads\n    app.config.from_object(config.SOURCE_APP_FLASK_CONFIG_CLS)\n\n    i18n.configure(config, app)\n\n    @app.before_request\n    @ignore_static\n    def setup_i18n() -> None:\n        \"\"\"Store i18n-related values in Flask's special g object\"\"\"\n        i18n.set_locale(config)\n\n    # The default CSRF token expiration is 1 hour. Since large uploads can\n    # take longer than an hour over Tor, we increase the valid window to 24h.\n    app.config[\"WTF_CSRF_TIME_LIMIT\"] = 60 * 60 * 24\n    CSRFProtect(app)\n    app.config[\"SESSION_COOKIE_SAMESITE\"] = \"Strict\"\n\n    app.config[\"SQLALCHEMY_TRACK_MODIFICATIONS\"] = False\n    app.config[\"SQLALCHEMY_DATABASE_URI\"] = config.DATABASE_URI\n    db.init_app(app)\n\n    # Check if the Submission Key is valid; if not, we'll disable the UI\n    app.config[\"SUBMISSION_KEY_VALID\"] = validate_journalist_key()\n\n    @app.errorhandler(CSRFError)\n    def handle_csrf_error(e: CSRFError) -> werkzeug.Response:\n        return clear_session_and_redirect_to_logged_out_page(flask_session=session)\n\n    app.jinja_env.trim_blocks = True\n    app.jinja_env.lstrip_blocks = True\n    app.jinja_env.globals[\"version\"] = version.__version__\n    # Exported to source templates for being included in instructions\n    app.jinja_env.globals[\"submission_key_fpr\"] = config.JOURNALIST_KEY\n    app.jinja_env.filters[\"rel_datetime_format\"] = template_filters.rel_datetime_format\n    app.jinja_env.filters[\"nl2br\"] = template_filters.nl2br\n    app.jinja_env.filters[\"filesizeformat\"] = template_filters.filesizeformat\n    app.jinja_env.filters[\"html_datetime_format\"] = template_filters.html_datetime_format\n    app.jinja_env.add_extension(\"jinja2.ext.do\")\n\n    for module in [main, info, api]:\n        app.register_blueprint(module.make_blueprint(config))  # type: ignore\n\n    # before_request hooks are executed in order of declaration, so set up g object\n    # before the potential tor2web 403 response.\n    @app.before_request\n    @ignore_static\n    def setup_g() -> Optional[werkzeug.Response]:\n        if InstanceConfig.get_default(refresh=True).organization_name:\n            g.organization_name = (  # pylint: disable=assigning-non-slot\n                InstanceConfig.get_default().organization_name\n            )\n        else:\n            g.organization_name = gettext(\"SecureDrop\")  # pylint: disable=assigning-non-slot\n\n        try:\n            g.logo = get_logo_url(app)  # pylint: disable=assigning-non-slot\n        except FileNotFoundError:\n            app.logger.error(\"Site logo not found.\")\n\n        return None\n\n    @app.before_request\n    @ignore_static\n    def check_tor2web() -> Optional[werkzeug.Response]:\n        # TODO: expand header checking logic to catch modern tor2web proxies\n        if \"X-tor2web\" in request.headers and request.path != url_for(\"info.tor2web_warning\"):\n            return redirect(url_for(\"info.tor2web_warning\"))\n        return None\n\n    @app.before_request\n    @ignore_static\n    def check_submission_key() -> Optional[werkzeug.Response]:\n        if not app.config[\"SUBMISSION_KEY_VALID\"]:\n            session.clear()\n            g.show_offline_message = True\n            return make_response(render_template(\"offline.html\"), 503)\n        return None\n\n    @app.errorhandler(404)\n    def page_not_found(error: werkzeug.exceptions.HTTPException) -> Tuple[str, int]:\n        return render_template(\"notfound.html\"), 404\n\n    @app.errorhandler(500)\n    def internal_error(error: werkzeug.exceptions.HTTPException) -> Tuple[str, int]:\n        return render_template(\"error.html\"), 500\n\n    # Obscure the creation time of source private keys by touching them all\n    # on startup.\n    private_keys = config.GPG_KEY_DIR / \"private-keys-v1.d\"\n    # The folder may not exist yet in some dev/testing setups,\n    # and if it doesn't exist there's no mtime to obscure.\n    if private_keys.is_dir():\n        now = time.time()\n        for entry in os.scandir(private_keys):\n            if not entry.is_file() or not entry.name.endswith(\".key\"): # Untested\n                continue # Untested\n            os.utime(entry.path, times=(now, now)) # Untested\n            # So the ctime is also updated\n            os.chmod(entry.path, entry.stat().st_mode)\n\n    return app",
        "callGraphToTestedFunction": [
          "create_app"
        ]
      },
      "unitTestFilePath": "tests/test_alembic.py"
    },
    {
      "functionName": "check_url_file",
      "file": "source_app/utils.py",
      "callGraph": [
        {
          "file": "source_app/utils.py",
          "functionName": "check_url_file",
          "lines": [
            {
              "startLine": 98,
              "endLine": 101
            },
            {
              "startLine": 103,
              "endLine": 103
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_source_utils.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "source_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "check_url_file",
          "filePath": "source_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 98,
              "endLine": 101
            },
            {
              "startLine": 103,
              "endLine": 103
            }
          ]
        },
        "uncoveredFnBody": "def check_url_file(path: str, regexp: str) -> \"Optional[str]\":\n    \"\"\"\n    Check that a file exists at the path given and contains a single line\n    matching the regexp. Used for checking the source interface address\n    files in /var/lib/securedrop (as the Apache user can't read Tor config)\n    \"\"\"\n    try:\n        f = open(path)\n        contents = f.readline().strip() # Untested\n        f.close() # Untested\n        if re.match(regexp, contents): # Untested\n            return contents # Untested\n        else:\n            return None\n    except OSError:\n        return None",
        "callGraphToTestedFunction": [
          "check_url_file"
        ]
      },
      "unitTestFilePath": "tests/test_source_utils.py"
    },
    {
      "functionName": "fit_codenames_into_cookie",
      "file": "source_app/utils.py",
      "callGraph": [
        {
          "file": "source_app/utils.py",
          "functionName": "fit_codenames_into_cookie",
          "lines": [
            {
              "startLine": 121,
              "endLine": 122
            },
            {
              "startLine": 127,
              "endLine": 127
            },
            {
              "startLine": 129,
              "endLine": 129
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_source_utils.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "source_app/utils.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "fit_codenames_into_cookie",
          "filePath": "source_app/utils.py",
          "uncoveredLines": [
            {
              "startLine": 121,
              "endLine": 122
            },
            {
              "startLine": 127,
              "endLine": 127
            },
            {
              "startLine": 129,
              "endLine": 129
            }
          ]
        },
        "uncoveredFnBody": "def fit_codenames_into_cookie(codenames: dict) -> dict:\n    \"\"\"\n    If `codenames` will approach `werkzeug.Response.max_cookie_size` once\n    serialized, incrementally pop off the oldest codename until the remaining\n    (newer) ones will fit.\n    \"\"\"\n\n    serialized = json.dumps(codenames).encode()\n    if len(codenames) > 1 and len(serialized) > 4000:  # werkzeug.Response.max_cookie_size = 4093\n        if current_app: # Untested\n            current_app.logger.warn( # Untested\n                f\"Popping oldest of {len(codenames)} \"\n                f\"codenames ({len(serialized)} bytes) to \"\n                f\"fit within maximum cookie size\"\n            )\n        del codenames[list(codenames)[0]]  # FIFO\n\n        return fit_codenames_into_cookie(codenames)\n\n    return codenames",
        "callGraphToTestedFunction": [
          "fit_codenames_into_cookie"
        ]
      },
      "unitTestFilePath": "tests/test_source_utils.py"
    },
    {
      "functionName": "create_source_user",
      "file": "source_user.py",
      "callGraph": [
        {
          "file": "source_user.py",
          "functionName": "create_source_user",
          "lines": [
            {
              "startLine": 102,
              "endLine": 102
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_source_user.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "source_user.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "create_source_user",
          "filePath": "source_user.py",
          "uncoveredLines": [
            {
              "startLine": 102,
              "endLine": 102
            }
          ]
        },
        "uncoveredFnBody": "def create_source_user(\n    db_session: Session,\n    source_passphrase: \"DicewarePassphrase\",\n    source_app_storage: \"Storage\",\n) -> SourceUser:\n    # Derive the source's info from their passphrase\n    scrypt_manager = _SourceScryptManager.get_default()\n    filesystem_id = scrypt_manager.derive_source_filesystem_id(source_passphrase)\n    gpg_secret = scrypt_manager.derive_source_gpg_secret(source_passphrase)\n\n    # Create a unique journalist designation for the source\n    # TODO: Add unique=True to models.Source.journalist_designation to enforce uniqueness\n    #  as the logic below has a race condition (time we check VS time when we add to the DB)\n    designation_generation_attempts = 0\n    valid_designation = None\n    designation_generator = _DesignationGenerator.get_default()\n    while designation_generation_attempts < 50:\n        # Generate a designation\n        designation_generation_attempts += 1\n        new_designation = designation_generator.generate_journalist_designation()\n\n        # Check to see if it's already used by an existing source\n        existing_source_with_same_designation = (\n            db_session.query(models.Source)\n            .filter_by(journalist_designation=new_designation)\n            .one_or_none()\n        )\n        if not existing_source_with_same_designation:\n            # The designation is not already used - good to go\n            valid_designation = new_designation\n            break\n\n    if not valid_designation:\n        # Could not generate a designation that is not already used\n        raise SourceDesignationCollisionError() # Untested\n\n    # Generate PGP keys\n    public_key, secret_key, fingerprint = redwood.generate_source_key_pair(\n        gpg_secret, filesystem_id\n    )\n\n    # Store the source in the DB\n    source_db_record = models.Source(\n        filesystem_id=filesystem_id,\n        journalist_designation=valid_designation,\n        public_key=public_key,\n        secret_key=secret_key,\n        fingerprint=fingerprint,\n    )\n    db_session.add(source_db_record)\n    try:\n        db_session.commit()\n    except IntegrityError:\n        db_session.rollback()\n        raise SourcePassphraseCollisionError(\n            f\"Passphrase already used by another Source (filesystem_id {filesystem_id})\"\n        )\n\n    # Create the source's folder\n    os.mkdir(source_app_storage.path(filesystem_id))\n\n    # All done\n    return SourceUser(source_db_record, filesystem_id, gpg_secret)",
        "callGraphToTestedFunction": [
          "create_source_user"
        ]
      },
      "unitTestFilePath": "tests/test_source_user.py"
    },
    {
      "functionName": "validate_journalist_key",
      "file": "startup.py",
      "callGraph": [
        {
          "file": "startup.py",
          "functionName": "validate_journalist_key",
          "lines": [
            {
              "startLine": 16,
              "endLine": 20
            },
            {
              "startLine": 24,
              "endLine": 28
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_startup.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "startup.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "validate_journalist_key",
          "filePath": "startup.py",
          "uncoveredLines": [
            {
              "startLine": 16,
              "endLine": 20
            },
            {
              "startLine": 24,
              "endLine": 28
            }
          ]
        },
        "uncoveredFnBody": "def validate_journalist_key(app: Optional[Flask] = None) -> bool:\n    \"\"\"Verify the journalist PGP key is valid\"\"\"\n    encryption_mgr = EncryptionManager.get_default()\n    # First check that we can read it\n    try:\n        journalist_key = encryption_mgr.get_journalist_public_key()\n    except Exception as e:\n        if app:\n            print(f\"ERROR: Unable to read journalist public key: {e}\", file=sys.stderr)\n            app.logger.error(f\"ERROR: Unable to read journalist public key: {e}\")\n        return False\n    # And then what we read is valid\n    try:\n        redwood.is_valid_public_key(journalist_key)\n    except redwood.RedwoodError as e: # Untested\n        if app: # Untested\n            print(f\"ERROR: Journalist public key is not valid: {e}\", file=sys.stderr) # Untested\n            app.logger.error(f\"ERROR: Journalist public key is not valid: {e}\") # Untested\n        return False # Untested\n\n    return True",
        "callGraphToTestedFunction": [
          "validate_journalist_key"
        ]
      },
      "unitTestFilePath": "tests/test_startup.py"
    },
    {
      "functionName": "get_default",
      "file": "store.py",
      "callGraph": [
        {
          "file": "store.py",
          "functionName": "get_default",
          "lines": [
            {
              "startLine": 103,
              "endLine": 105
            },
            {
              "startLine": 107,
              "endLine": 107
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_integration.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "store.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_default",
          "filePath": "store.py",
          "uncoveredLines": [
            {
              "startLine": 103,
              "endLine": 105
            },
            {
              "startLine": 107,
              "endLine": 107
            }
          ]
        },
        "uncoveredFnBody": "class Storage:\n    def __init__(self, storage_path: str, temp_dir: str) -> None:\n        if not os.path.isabs(storage_path):\n            raise PathException(f\"storage_path {storage_path} is not absolute\")\n        self.__storage_path = storage_path\n\n        if not os.path.isabs(temp_dir):\n            raise PathException(f\"temp_dir {temp_dir} is not absolute\")\n        self.__temp_dir = temp_dir\n\n        # where files and directories are sent to be securely deleted\n        self.__shredder_path = os.path.abspath(os.path.join(self.__storage_path, \"../shredder\"))\n        os.makedirs(self.__shredder_path, mode=0o700, exist_ok=True)\n\n        # crash if we don't have a way to securely remove files\n        if not rm.check_secure_delete_capability():\n            raise AssertionError(\"Secure file deletion is not possible.\")\n\n    @classmethod\n    def get_default(cls) -> \"Storage\":\n        global _default_storage\n        if _default_storage is None: # Untested\n            config = SecureDropConfig.get_current() # Untested\n            _default_storage = cls(str(config.STORE_DIR), str(config.TEMP_DIR)) # Untested\n\n        return _default_storage\n\n    @property\n    def storage_path(self) -> str:\n        return self.__storage_path\n\n    @property\n    def shredder_path(self) -> str:\n        return self.__shredder_path\n\n    def shredder_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the shredder.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__shredder_path))\n        return common_path == self.__shredder_path\n\n    def store_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the store.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__storage_path))\n        return common_path == self.__storage_path\n\n    def verify(self, p: str) -> bool:\n        \"\"\"\n        Verify that a given path is valid for the store.\n        \"\"\"\n\n        if self.store_contains(p):\n            # verifying a hypothetical path\n            if not os.path.exists(p):\n                return True\n\n            # extant paths must be directories or correctly-named plain files\n            if os.path.isdir(p):\n                return True\n\n            if os.path.isfile(p) and VALIDATE_FILENAME(os.path.basename(p)):\n                return True\n\n        raise PathException(f\"Path not valid in store: {p}\")\n\n    def path(self, filesystem_id: str, filename: str = \"\") -> str:\n        \"\"\"\n        Returns the path resolved within `self.__storage_path`.\n\n        Raises PathException if `verify` doesn't like the path.\n        \"\"\"\n        joined = os.path.join(os.path.realpath(self.__storage_path), filesystem_id, filename)\n        absolute = os.path.realpath(joined)\n        if not self.verify(absolute):\n            raise PathException(\n                f'Could not resolve (\"{filesystem_id}\", \"{filename}\") to a path within '\n                \"the store.\"\n            )\n        return absolute\n\n    def path_without_filesystem_id(self, filename: str) -> str:\n        \"\"\"Get the normalized, absolute file path, within\n        `self.__storage_path` for a filename when the filesystem_id\n        is not known.\n        \"\"\"\n\n        joined_paths = []\n        for rootdir, _, files in os.walk(os.path.realpath(self.__storage_path)):\n            for file_ in files:\n                if file_ in filename:\n                    joined_paths.append(os.path.join(rootdir, file_))\n\n        if len(joined_paths) > 1:\n            raise TooManyFilesException(\"Found duplicate files!\")\n        elif len(joined_paths) == 0:\n            raise NoFileFoundException(f\"File not found: {filename}\")\n        else:\n            absolute = joined_paths[0]\n\n        if not self.verify(absolute):\n            raise PathException(f\"\"\"Could not resolve \"{filename}\" to a path within the store.\"\"\")\n        return absolute\n\n    def get_bulk_archive(\n        self, selected_submissions: \"List\", zip_directory: str = \"\"\n    ) -> \"_TemporaryFileWrapper\":\n        \"\"\"Generate a zip file from the selected submissions\"\"\"\n        zip_file = tempfile.NamedTemporaryFile(\n            prefix=\"tmp_securedrop_bulk_dl_\", dir=self.__temp_dir, delete=False\n        )\n        sources = {i.source.journalist_designation for i in selected_submissions}\n        # The below nested for-loops are there to create a more usable\n        # folder structure per #383\n        missing_files = False\n\n        with zipfile.ZipFile(zip_file, \"w\") as zip:\n            for source in sources:\n                fname = \"\"\n                submissions = [\n                    s for s in selected_submissions if s.source.journalist_designation == source\n                ]\n                for submission in submissions:\n                    filename = self.path(submission.source.filesystem_id, submission.filename)\n\n                    if os.path.exists(filename):\n                        document_number = submission.filename.split(\"-\")[0]\n                        if zip_directory == submission.source.journalist_filename:\n                            fname = zip_directory\n                        else:\n                            fname = os.path.join(zip_directory, source)\n                        zip.write(\n                            filename,\n                            arcname=os.path.join(\n                                fname,\n                                f\"{document_number}_{submission.source.last_updated.date()}\",\n                                os.path.basename(filename),\n                            ),\n                        )\n                    else:\n                        missing_files = True\n                        current_app.logger.error(f\"File {filename} not found\")\n\n        if missing_files:\n            raise FileNotFoundError\n        else:\n            return zip_file\n\n    def move_to_shredder(self, path: str) -> None:\n        \"\"\"\n        Moves content from the store to the shredder for secure deletion.\n\n        Python's safe_renames (and the underlying rename(2) calls) will\n        silently overwrite content, which could bypass secure\n        deletion, so we create a temporary directory under the\n        shredder directory and move the specified content there.\n\n        This function is intended to be atomic and quick, for use in\n        deletions via the UI and API. The actual secure deletion is\n        performed by an asynchronous process that monitors the\n        shredder directory.\n        \"\"\"\n        if not self.verify(path):\n            raise ValueError(f\"\"\"Path is not within the store: \"{path}\" \"\"\")\n\n        if not os.path.exists(path):\n            raise ValueError(f\"\"\"Path does not exist: \"{path}\" \"\"\")\n\n        relpath = os.path.relpath(path, start=self.storage_path)\n        dest = os.path.join(tempfile.mkdtemp(dir=self.__shredder_path), relpath)\n        current_app.logger.info(f\"Moving {path} to shredder: {dest}\")\n        safe_renames(path, dest)\n\n    def clear_shredder(self) -> None:\n        current_app.logger.info(\"Clearing shredder\")\n        directories = []\n        targets = []\n        for directory, subdirs, files in os.walk(self.shredder_path):\n            for subdir in subdirs:\n                real_subdir = os.path.realpath(os.path.join(directory, subdir))\n                if self.shredder_contains(real_subdir):\n                    directories.append(real_subdir)\n            for f in files:\n                abs_file = os.path.abspath(os.path.join(directory, f))\n                if os.path.islink(abs_file):\n                    # Somehow, a symbolic link was created in the\n                    # store. This shouldn't happen in normal\n                    # operations. Just remove the link; don't try to\n                    # shred its target. Note that we only have special\n                    # handling for symlinks. Hard links -- which\n                    # again, shouldn't occur in the store -- will\n                    # result in the file data being shredded once for\n                    # each link.\n                    current_app.logger.info(f\"Deleting link {abs_file} to {os.readlink(abs_file)}\")\n                    os.unlink(abs_file)\n                    continue\n                if self.shredder_contains(abs_file):\n                    targets.append(abs_file)\n\n        target_count = len(targets)\n        current_app.logger.info(f\"Files to delete: {target_count}\")\n        for i, t in enumerate(targets, 1):\n            current_app.logger.info(f\"Securely deleting file {i}/{target_count}: {t}\")\n            rm.secure_delete(t)\n            current_app.logger.info(f\"Securely deleted file {i}/{target_count}: {t}\")\n\n        directories_to_remove = set(directories)\n        dir_count = len(directories_to_remove)\n        for i, d in enumerate(reversed(sorted(directories_to_remove)), 1):\n            current_app.logger.debug(f\"Removing directory {i}/{dir_count}: {d}\")\n            os.rmdir(d)\n            current_app.logger.debug(f\"Removed directory {i}/{dir_count}: {d}\")\n\n    def save_file_submission(\n        self,\n        filesystem_id: str,\n        count: int,\n        journalist_filename: str,\n        filename: Optional[str],\n        stream: BinaryIO,\n    ) -> str:\n        if filename is not None:\n            sanitized_filename = secure_filename(filename)\n        else:\n            sanitized_filename = secure_filename(\"unknown.file\")\n\n        # We store file submissions in a .gz file for two reasons:\n        #\n        # 1. Downloading large files over Tor is very slow. If we can\n        # compress the file, we can speed up future downloads.\n        #\n        # 2. We want to record the original filename because it might be\n        # useful, either for context about the content of the submission\n        # or for figuring out which application should be used to open\n        # it. However, we'd like to encrypt that info and have the\n        # decrypted file automatically have the name of the original\n        # file. Given various usability constraints in GPG and Tails, this\n        # is the most user-friendly way we have found to do this.\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-doc.gz.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n        with SecureTemporaryFile(\"/tmp\") as stf:  # noqa: S108\n            with gzip.GzipFile(filename=sanitized_filename, mode=\"wb\", fileobj=stf, mtime=0) as gzf:\n                # Buffer the stream into the gzip file to avoid excessive\n                # memory consumption\n                while True:\n                    buf = stream.read(1024 * 8)\n                    if not buf:\n                        break\n                    gzf.write(buf)\n\n            EncryptionManager.get_default().encrypt_source_file(\n                file_in=stf,\n                encrypted_file_path_out=Path(encrypted_file_path),\n            )\n\n        return encrypted_file_name\n\n    def save_pre_encrypted_reply(\n        self, filesystem_id: str, count: int, journalist_filename: str, content: str\n    ) -> str:\n        if \"-----BEGIN PGP MESSAGE-----\" not in content.split(\"\\n\")[0]:\n            raise NotEncrypted\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-reply.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n\n        with open(encrypted_file_path, \"w\") as fh:\n            fh.write(content)\n\n        return encrypted_file_path\n\n    def save_message_submission(\n        self, filesystem_id: str, count: int, journalist_filename: str, message: str\n    ) -> str:\n        filename = f\"{count}-{journalist_filename}-msg.gpg\"\n        msg_loc = self.path(filesystem_id, filename)\n        EncryptionManager.get_default().encrypt_source_message(\n            message_in=message,\n            encrypted_message_path_out=Path(msg_loc),\n        )\n        return filename",
        "callGraphToTestedFunction": [
          "get_default"
        ]
      },
      "unitTestFilePath": "tests/test_integration.py"
    },
    {
      "functionName": "path",
      "file": "store.py",
      "callGraph": [
        {
          "file": "store.py",
          "functionName": "path",
          "lines": [
            {
              "startLine": 159,
              "endLine": 159
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_integration.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "store.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "path",
          "filePath": "store.py",
          "uncoveredLines": [
            {
              "startLine": 159,
              "endLine": 159
            }
          ]
        },
        "uncoveredFnBody": "class Storage:\n    def __init__(self, storage_path: str, temp_dir: str) -> None:\n        if not os.path.isabs(storage_path):\n            raise PathException(f\"storage_path {storage_path} is not absolute\")\n        self.__storage_path = storage_path\n\n        if not os.path.isabs(temp_dir):\n            raise PathException(f\"temp_dir {temp_dir} is not absolute\")\n        self.__temp_dir = temp_dir\n\n        # where files and directories are sent to be securely deleted\n        self.__shredder_path = os.path.abspath(os.path.join(self.__storage_path, \"../shredder\"))\n        os.makedirs(self.__shredder_path, mode=0o700, exist_ok=True)\n\n        # crash if we don't have a way to securely remove files\n        if not rm.check_secure_delete_capability():\n            raise AssertionError(\"Secure file deletion is not possible.\")\n\n    @classmethod\n    def get_default(cls) -> \"Storage\":\n        global _default_storage\n        if _default_storage is None:\n            config = SecureDropConfig.get_current()\n            _default_storage = cls(str(config.STORE_DIR), str(config.TEMP_DIR))\n\n        return _default_storage\n\n    @property\n    def storage_path(self) -> str:\n        return self.__storage_path\n\n    @property\n    def shredder_path(self) -> str:\n        return self.__shredder_path\n\n    def shredder_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the shredder.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__shredder_path))\n        return common_path == self.__shredder_path\n\n    def store_contains(self, path: str) -> bool:\n        \"\"\"\n        Returns True if the fully-resolved path lies within the store.\n        \"\"\"\n        common_path = os.path.commonpath((os.path.realpath(path), self.__storage_path))\n        return common_path == self.__storage_path\n\n    def verify(self, p: str) -> bool:\n        \"\"\"\n        Verify that a given path is valid for the store.\n        \"\"\"\n\n        if self.store_contains(p):\n            # verifying a hypothetical path\n            if not os.path.exists(p):\n                return True\n\n            # extant paths must be directories or correctly-named plain files\n            if os.path.isdir(p):\n                return True\n\n            if os.path.isfile(p) and VALIDATE_FILENAME(os.path.basename(p)):\n                return True\n\n        raise PathException(f\"Path not valid in store: {p}\")\n\n    def path(self, filesystem_id: str, filename: str = \"\") -> str:\n        \"\"\"\n        Returns the path resolved within `self.__storage_path`.\n\n        Raises PathException if `verify` doesn't like the path.\n        \"\"\"\n        joined = os.path.join(os.path.realpath(self.__storage_path), filesystem_id, filename)\n        absolute = os.path.realpath(joined)\n        if not self.verify(absolute):\n            raise PathException( # Untested\n                f'Could not resolve (\"{filesystem_id}\", \"{filename}\") to a path within '\n                \"the store.\"\n            )\n        return absolute\n\n    def path_without_filesystem_id(self, filename: str) -> str:\n        \"\"\"Get the normalized, absolute file path, within\n        `self.__storage_path` for a filename when the filesystem_id\n        is not known.\n        \"\"\"\n\n        joined_paths = []\n        for rootdir, _, files in os.walk(os.path.realpath(self.__storage_path)):\n            for file_ in files:\n                if file_ in filename:\n                    joined_paths.append(os.path.join(rootdir, file_))\n\n        if len(joined_paths) > 1:\n            raise TooManyFilesException(\"Found duplicate files!\")\n        elif len(joined_paths) == 0:\n            raise NoFileFoundException(f\"File not found: {filename}\")\n        else:\n            absolute = joined_paths[0]\n\n        if not self.verify(absolute):\n            raise PathException(f\"\"\"Could not resolve \"{filename}\" to a path within the store.\"\"\")\n        return absolute\n\n    def get_bulk_archive(\n        self, selected_submissions: \"List\", zip_directory: str = \"\"\n    ) -> \"_TemporaryFileWrapper\":\n        \"\"\"Generate a zip file from the selected submissions\"\"\"\n        zip_file = tempfile.NamedTemporaryFile(\n            prefix=\"tmp_securedrop_bulk_dl_\", dir=self.__temp_dir, delete=False\n        )\n        sources = {i.source.journalist_designation for i in selected_submissions}\n        # The below nested for-loops are there to create a more usable\n        # folder structure per #383\n        missing_files = False\n\n        with zipfile.ZipFile(zip_file, \"w\") as zip:\n            for source in sources:\n                fname = \"\"\n                submissions = [\n                    s for s in selected_submissions if s.source.journalist_designation == source\n                ]\n                for submission in submissions:\n                    filename = self.path(submission.source.filesystem_id, submission.filename)\n\n                    if os.path.exists(filename):\n                        document_number = submission.filename.split(\"-\")[0]\n                        if zip_directory == submission.source.journalist_filename:\n                            fname = zip_directory\n                        else:\n                            fname = os.path.join(zip_directory, source)\n                        zip.write(\n                            filename,\n                            arcname=os.path.join(\n                                fname,\n                                f\"{document_number}_{submission.source.last_updated.date()}\",\n                                os.path.basename(filename),\n                            ),\n                        )\n                    else:\n                        missing_files = True\n                        current_app.logger.error(f\"File {filename} not found\")\n\n        if missing_files:\n            raise FileNotFoundError\n        else:\n            return zip_file\n\n    def move_to_shredder(self, path: str) -> None:\n        \"\"\"\n        Moves content from the store to the shredder for secure deletion.\n\n        Python's safe_renames (and the underlying rename(2) calls) will\n        silently overwrite content, which could bypass secure\n        deletion, so we create a temporary directory under the\n        shredder directory and move the specified content there.\n\n        This function is intended to be atomic and quick, for use in\n        deletions via the UI and API. The actual secure deletion is\n        performed by an asynchronous process that monitors the\n        shredder directory.\n        \"\"\"\n        if not self.verify(path):\n            raise ValueError(f\"\"\"Path is not within the store: \"{path}\" \"\"\")\n\n        if not os.path.exists(path):\n            raise ValueError(f\"\"\"Path does not exist: \"{path}\" \"\"\")\n\n        relpath = os.path.relpath(path, start=self.storage_path)\n        dest = os.path.join(tempfile.mkdtemp(dir=self.__shredder_path), relpath)\n        current_app.logger.info(f\"Moving {path} to shredder: {dest}\")\n        safe_renames(path, dest)\n\n    def clear_shredder(self) -> None:\n        current_app.logger.info(\"Clearing shredder\")\n        directories = []\n        targets = []\n        for directory, subdirs, files in os.walk(self.shredder_path):\n            for subdir in subdirs:\n                real_subdir = os.path.realpath(os.path.join(directory, subdir))\n                if self.shredder_contains(real_subdir):\n                    directories.append(real_subdir)\n            for f in files:\n                abs_file = os.path.abspath(os.path.join(directory, f))\n                if os.path.islink(abs_file):\n                    # Somehow, a symbolic link was created in the\n                    # store. This shouldn't happen in normal\n                    # operations. Just remove the link; don't try to\n                    # shred its target. Note that we only have special\n                    # handling for symlinks. Hard links -- which\n                    # again, shouldn't occur in the store -- will\n                    # result in the file data being shredded once for\n                    # each link.\n                    current_app.logger.info(f\"Deleting link {abs_file} to {os.readlink(abs_file)}\")\n                    os.unlink(abs_file)\n                    continue\n                if self.shredder_contains(abs_file):\n                    targets.append(abs_file)\n\n        target_count = len(targets)\n        current_app.logger.info(f\"Files to delete: {target_count}\")\n        for i, t in enumerate(targets, 1):\n            current_app.logger.info(f\"Securely deleting file {i}/{target_count}: {t}\")\n            rm.secure_delete(t)\n            current_app.logger.info(f\"Securely deleted file {i}/{target_count}: {t}\")\n\n        directories_to_remove = set(directories)\n        dir_count = len(directories_to_remove)\n        for i, d in enumerate(reversed(sorted(directories_to_remove)), 1):\n            current_app.logger.debug(f\"Removing directory {i}/{dir_count}: {d}\")\n            os.rmdir(d)\n            current_app.logger.debug(f\"Removed directory {i}/{dir_count}: {d}\")\n\n    def save_file_submission(\n        self,\n        filesystem_id: str,\n        count: int,\n        journalist_filename: str,\n        filename: Optional[str],\n        stream: BinaryIO,\n    ) -> str:\n        if filename is not None:\n            sanitized_filename = secure_filename(filename)\n        else:\n            sanitized_filename = secure_filename(\"unknown.file\")\n\n        # We store file submissions in a .gz file for two reasons:\n        #\n        # 1. Downloading large files over Tor is very slow. If we can\n        # compress the file, we can speed up future downloads.\n        #\n        # 2. We want to record the original filename because it might be\n        # useful, either for context about the content of the submission\n        # or for figuring out which application should be used to open\n        # it. However, we'd like to encrypt that info and have the\n        # decrypted file automatically have the name of the original\n        # file. Given various usability constraints in GPG and Tails, this\n        # is the most user-friendly way we have found to do this.\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-doc.gz.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n        with SecureTemporaryFile(\"/tmp\") as stf:  # noqa: S108\n            with gzip.GzipFile(filename=sanitized_filename, mode=\"wb\", fileobj=stf, mtime=0) as gzf:\n                # Buffer the stream into the gzip file to avoid excessive\n                # memory consumption\n                while True:\n                    buf = stream.read(1024 * 8)\n                    if not buf:\n                        break\n                    gzf.write(buf)\n\n            EncryptionManager.get_default().encrypt_source_file(\n                file_in=stf,\n                encrypted_file_path_out=Path(encrypted_file_path),\n            )\n\n        return encrypted_file_name\n\n    def save_pre_encrypted_reply(\n        self, filesystem_id: str, count: int, journalist_filename: str, content: str\n    ) -> str:\n        if \"-----BEGIN PGP MESSAGE-----\" not in content.split(\"\\n\")[0]:\n            raise NotEncrypted\n\n        encrypted_file_name = f\"{count}-{journalist_filename}-reply.gpg\"\n        encrypted_file_path = self.path(filesystem_id, encrypted_file_name)\n\n        with open(encrypted_file_path, \"w\") as fh:\n            fh.write(content)\n\n        return encrypted_file_path\n\n    def save_message_submission(\n        self, filesystem_id: str, count: int, journalist_filename: str, message: str\n    ) -> str:\n        filename = f\"{count}-{journalist_filename}-msg.gpg\"\n        msg_loc = self.path(filesystem_id, filename)\n        EncryptionManager.get_default().encrypt_source_message(\n            message_in=message,\n            encrypted_message_path_out=Path(msg_loc),\n        )\n        return filename",
        "callGraphToTestedFunction": [
          "path"
        ]
      },
      "unitTestFilePath": "tests/test_integration.py"
    },
    {
      "functionName": "queued_add_checksum_for_file",
      "file": "store.py",
      "callGraph": [
        {
          "file": "store.py",
          "functionName": "queued_add_checksum_for_file",
          "lines": [
            {
              "startLine": 383,
              "endLine": 385
            },
            {
              "startLine": 387,
              "endLine": 387
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_store.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "store.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "queued_add_checksum_for_file",
          "filePath": "store.py",
          "uncoveredLines": [
            {
              "startLine": 383,
              "endLine": 385
            },
            {
              "startLine": 387,
              "endLine": 387
            }
          ]
        },
        "uncoveredFnBody": "def queued_add_checksum_for_file(\n    db_model: \"Union[Type[Submission], Type[Reply]]\", model_id: int, file_path: str, db_uri: str\n) -> str:\n    # we have to create our own DB session because there is no app context\n    session = sessionmaker(bind=create_engine(db_uri))() # Untested\n    db_obj = session.query(db_model).filter_by(id=model_id).one() # Untested\n    add_checksum_for_file(session, db_obj, file_path) # Untested\n    # We need to return a non-`None` value so the rq worker writes this back to Redis\n    return \"success\"",
        "callGraphToTestedFunction": [
          "queued_add_checksum_for_file"
        ]
      },
      "unitTestFilePath": "tests/test_store.py"
    },
    {
      "functionName": "generate",
      "file": "two_factor.py",
      "callGraph": [
        {
          "file": "two_factor.py",
          "functionName": "generate",
          "lines": [
            {
              "startLine": 128,
              "endLine": 128
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_two_factor_in_apps.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "two_factor.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "generate",
          "filePath": "two_factor.py",
          "uncoveredLines": [
            {
              "startLine": 128,
              "endLine": 128
            }
          ]
        },
        "uncoveredFnBody": "class TOTP:\n    # Current parameters for TOTP\n    _LENGTH = 6\n    _TIME_STEP = 30\n\n    # nosemgrep: python.cryptography.security.insecure-hash-algorithms.insecure-hash-algorithm-sha1\n    _ALGORITHM = SHA1()  # noqa: S303\n\n    # Minimum length for ascii-encoded OTP secrets - by default, secrets are now 160-bit (32 chars)\n    # but existing Journalist users may still have 80-bit (16-char) secrets\n    _SECRET_MIN_BASE32_LENGTH = 16  # 80 bits == 40 hex digits (== 16 ascii-encoded chars in db)\n\n    def __init__(self, secret_as_base32: str) -> None:\n        if len(secret_as_base32) < self._SECRET_MIN_BASE32_LENGTH:\n            raise OtpSecretInvalid(\"Invalid secret length\")\n\n        try:\n            otp_secret_as_bytes = base64.b32decode(\n                # Need casefold=True because the base32 secret we receive from the UI might be\n                # lowercase\n                secret_as_base32,\n                casefold=True,\n            )\n        except binascii.Error:\n            raise OtpSecretInvalid(\"Secret is not base32-encoded\")\n\n        self._totp = totp.TOTP(\n            key=otp_secret_as_bytes,\n            length=self._LENGTH,\n            algorithm=self._ALGORITHM,\n            time_step=self._TIME_STEP,\n            # Existing Journalist users may still have 80-bit (16-char) secrets\n            enforce_key_length=False,\n        )\n\n    def generate(self, time: datetime) -> str:\n        return self._totp.generate(time.timestamp()).decode(\"ascii\") # Untested\n\n    def now(self) -> str:\n        return self._totp.generate(datetime.utcnow().timestamp()).decode(\"ascii\")\n\n    def verify(self, token: str, time: datetime) -> None:\n        # Also check the given token against the previous and next valid tokens, to compensate\n        # for potential time skew between the client and the server. The total valid window is 1:30s\n        token_verification_succeeded = False\n        for index_for_time_skew in [-1, 0, 1]:\n            time_for_time_skew = int(time.timestamp()) + self._TIME_STEP * index_for_time_skew\n            try:\n                self._totp.verify(token.encode(\"ascii\"), time_for_time_skew)\n                token_verification_succeeded = True\n                break\n            except InvalidToken:\n                pass\n\n        if not token_verification_succeeded:\n            raise OtpTokenInvalid(\"Token verification failed\")\n\n    def get_provisioning_uri(self, account_name: str) -> str:\n        return self._totp.get_provisioning_uri(account_name=account_name, issuer=\"SecureDrop\")\n\n    def qrcode_svg(self, account_name: str) -> bytes:\n        uri = self.get_provisioning_uri(account_name)\n\n        qr = qrcode.QRCode(box_size=15, image_factory=qrcode.image.svg.SvgPathImage)\n        qr.add_data(uri)\n        img = qr.make_image()\n\n        svg_out = BytesIO()\n        img.save(svg_out)\n        return svg_out.getvalue()",
        "callGraphToTestedFunction": [
          "generate"
        ]
      },
      "unitTestFilePath": "tests/test_two_factor_in_apps.py"
    },
    {
      "functionName": "verify",
      "file": "two_factor.py",
      "callGraph": [
        {
          "file": "two_factor.py",
          "functionName": "verify",
          "lines": [
            {
              "startLine": 136,
              "endLine": 144
            },
            {
              "startLine": 146,
              "endLine": 147
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_two_factor.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "two_factor.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "verify",
          "filePath": "two_factor.py",
          "uncoveredLines": [
            {
              "startLine": 136,
              "endLine": 144
            },
            {
              "startLine": 146,
              "endLine": 147
            }
          ]
        },
        "uncoveredFnBody": "class TOTP:\n    # Current parameters for TOTP\n    _LENGTH = 6\n    _TIME_STEP = 30\n\n    # nosemgrep: python.cryptography.security.insecure-hash-algorithms.insecure-hash-algorithm-sha1\n    _ALGORITHM = SHA1()  # noqa: S303\n\n    # Minimum length for ascii-encoded OTP secrets - by default, secrets are now 160-bit (32 chars)\n    # but existing Journalist users may still have 80-bit (16-char) secrets\n    _SECRET_MIN_BASE32_LENGTH = 16  # 80 bits == 40 hex digits (== 16 ascii-encoded chars in db)\n\n    def __init__(self, secret_as_base32: str) -> None:\n        if len(secret_as_base32) < self._SECRET_MIN_BASE32_LENGTH:\n            raise OtpSecretInvalid(\"Invalid secret length\")\n\n        try:\n            otp_secret_as_bytes = base64.b32decode(\n                # Need casefold=True because the base32 secret we receive from the UI might be\n                # lowercase\n                secret_as_base32,\n                casefold=True,\n            )\n        except binascii.Error:\n            raise OtpSecretInvalid(\"Secret is not base32-encoded\")\n\n        self._totp = totp.TOTP(\n            key=otp_secret_as_bytes,\n            length=self._LENGTH,\n            algorithm=self._ALGORITHM,\n            time_step=self._TIME_STEP,\n            # Existing Journalist users may still have 80-bit (16-char) secrets\n            enforce_key_length=False,\n        )\n\n    def generate(self, time: datetime) -> str:\n        return self._totp.generate(time.timestamp()).decode(\"ascii\")\n\n    def now(self) -> str:\n        return self._totp.generate(datetime.utcnow().timestamp()).decode(\"ascii\")\n\n    def verify(self, token: str, time: datetime) -> None:\n        # Also check the given token against the previous and next valid tokens, to compensate\n        # for potential time skew between the client and the server. The total valid window is 1:30s\n        token_verification_succeeded = False # Untested\n        for index_for_time_skew in [-1, 0, 1]: # Untested\n            time_for_time_skew = int(time.timestamp()) + self._TIME_STEP * index_for_time_skew # Untested\n            try: # Untested\n                self._totp.verify(token.encode(\"ascii\"), time_for_time_skew) # Untested\n                token_verification_succeeded = True # Untested\n                break # Untested\n            except InvalidToken: # Untested\n                pass # Untested\n\n        if not token_verification_succeeded:\n            raise OtpTokenInvalid(\"Token verification failed\")\n\n    def get_provisioning_uri(self, account_name: str) -> str:\n        return self._totp.get_provisioning_uri(account_name=account_name, issuer=\"SecureDrop\")\n\n    def qrcode_svg(self, account_name: str) -> bytes:\n        uri = self.get_provisioning_uri(account_name)\n\n        qr = qrcode.QRCode(box_size=15, image_factory=qrcode.image.svg.SvgPathImage)\n        qr.add_data(uri)\n        img = qr.make_image()\n\n        svg_out = BytesIO()\n        img.save(svg_out)\n        return svg_out.getvalue()",
        "callGraphToTestedFunction": [
          "verify"
        ]
      },
      "unitTestFilePath": "tests/test_two_factor.py"
    },
    {
      "functionName": "now",
      "file": "two_factor.py",
      "callGraph": [
        {
          "file": "two_factor.py",
          "functionName": "now",
          "lines": [
            {
              "startLine": 131,
              "endLine": 131
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_two_factor_in_apps.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "two_factor.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "now",
          "filePath": "two_factor.py",
          "uncoveredLines": [
            {
              "startLine": 131,
              "endLine": 131
            }
          ]
        },
        "uncoveredFnBody": "class TOTP:\n    # Current parameters for TOTP\n    _LENGTH = 6\n    _TIME_STEP = 30\n\n    # nosemgrep: python.cryptography.security.insecure-hash-algorithms.insecure-hash-algorithm-sha1\n    _ALGORITHM = SHA1()  # noqa: S303\n\n    # Minimum length for ascii-encoded OTP secrets - by default, secrets are now 160-bit (32 chars)\n    # but existing Journalist users may still have 80-bit (16-char) secrets\n    _SECRET_MIN_BASE32_LENGTH = 16  # 80 bits == 40 hex digits (== 16 ascii-encoded chars in db)\n\n    def __init__(self, secret_as_base32: str) -> None:\n        if len(secret_as_base32) < self._SECRET_MIN_BASE32_LENGTH:\n            raise OtpSecretInvalid(\"Invalid secret length\")\n\n        try:\n            otp_secret_as_bytes = base64.b32decode(\n                # Need casefold=True because the base32 secret we receive from the UI might be\n                # lowercase\n                secret_as_base32,\n                casefold=True,\n            )\n        except binascii.Error:\n            raise OtpSecretInvalid(\"Secret is not base32-encoded\")\n\n        self._totp = totp.TOTP(\n            key=otp_secret_as_bytes,\n            length=self._LENGTH,\n            algorithm=self._ALGORITHM,\n            time_step=self._TIME_STEP,\n            # Existing Journalist users may still have 80-bit (16-char) secrets\n            enforce_key_length=False,\n        )\n\n    def generate(self, time: datetime) -> str:\n        return self._totp.generate(time.timestamp()).decode(\"ascii\")\n\n    def now(self) -> str:\n        return self._totp.generate(datetime.utcnow().timestamp()).decode(\"ascii\") # Untested\n\n    def verify(self, token: str, time: datetime) -> None:\n        # Also check the given token against the previous and next valid tokens, to compensate\n        # for potential time skew between the client and the server. The total valid window is 1:30s\n        token_verification_succeeded = False\n        for index_for_time_skew in [-1, 0, 1]:\n            time_for_time_skew = int(time.timestamp()) + self._TIME_STEP * index_for_time_skew\n            try:\n                self._totp.verify(token.encode(\"ascii\"), time_for_time_skew)\n                token_verification_succeeded = True\n                break\n            except InvalidToken:\n                pass\n\n        if not token_verification_succeeded:\n            raise OtpTokenInvalid(\"Token verification failed\")\n\n    def get_provisioning_uri(self, account_name: str) -> str:\n        return self._totp.get_provisioning_uri(account_name=account_name, issuer=\"SecureDrop\")\n\n    def qrcode_svg(self, account_name: str) -> bytes:\n        uri = self.get_provisioning_uri(account_name)\n\n        qr = qrcode.QRCode(box_size=15, image_factory=qrcode.image.svg.SvgPathImage)\n        qr.add_data(uri)\n        img = qr.make_image()\n\n        svg_out = BytesIO()\n        img.save(svg_out)\n        return svg_out.getvalue()",
        "callGraphToTestedFunction": [
          "now"
        ]
      },
      "unitTestFilePath": "tests/test_two_factor_in_apps.py"
    },
    {
      "functionName": "get_provisioning_uri",
      "file": "two_factor.py",
      "callGraph": [
        {
          "file": "two_factor.py",
          "functionName": "get_provisioning_uri",
          "lines": [
            {
              "startLine": 150,
              "endLine": 150
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_two_factor.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "two_factor.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "get_provisioning_uri",
          "filePath": "two_factor.py",
          "uncoveredLines": [
            {
              "startLine": 150,
              "endLine": 150
            }
          ]
        },
        "uncoveredFnBody": "class TOTP:\n    # Current parameters for TOTP\n    _LENGTH = 6\n    _TIME_STEP = 30\n\n    # nosemgrep: python.cryptography.security.insecure-hash-algorithms.insecure-hash-algorithm-sha1\n    _ALGORITHM = SHA1()  # noqa: S303\n\n    # Minimum length for ascii-encoded OTP secrets - by default, secrets are now 160-bit (32 chars)\n    # but existing Journalist users may still have 80-bit (16-char) secrets\n    _SECRET_MIN_BASE32_LENGTH = 16  # 80 bits == 40 hex digits (== 16 ascii-encoded chars in db)\n\n    def __init__(self, secret_as_base32: str) -> None:\n        if len(secret_as_base32) < self._SECRET_MIN_BASE32_LENGTH:\n            raise OtpSecretInvalid(\"Invalid secret length\")\n\n        try:\n            otp_secret_as_bytes = base64.b32decode(\n                # Need casefold=True because the base32 secret we receive from the UI might be\n                # lowercase\n                secret_as_base32,\n                casefold=True,\n            )\n        except binascii.Error:\n            raise OtpSecretInvalid(\"Secret is not base32-encoded\")\n\n        self._totp = totp.TOTP(\n            key=otp_secret_as_bytes,\n            length=self._LENGTH,\n            algorithm=self._ALGORITHM,\n            time_step=self._TIME_STEP,\n            # Existing Journalist users may still have 80-bit (16-char) secrets\n            enforce_key_length=False,\n        )\n\n    def generate(self, time: datetime) -> str:\n        return self._totp.generate(time.timestamp()).decode(\"ascii\")\n\n    def now(self) -> str:\n        return self._totp.generate(datetime.utcnow().timestamp()).decode(\"ascii\")\n\n    def verify(self, token: str, time: datetime) -> None:\n        # Also check the given token against the previous and next valid tokens, to compensate\n        # for potential time skew between the client and the server. The total valid window is 1:30s\n        token_verification_succeeded = False\n        for index_for_time_skew in [-1, 0, 1]:\n            time_for_time_skew = int(time.timestamp()) + self._TIME_STEP * index_for_time_skew\n            try:\n                self._totp.verify(token.encode(\"ascii\"), time_for_time_skew)\n                token_verification_succeeded = True\n                break\n            except InvalidToken:\n                pass\n\n        if not token_verification_succeeded:\n            raise OtpTokenInvalid(\"Token verification failed\")\n\n    def get_provisioning_uri(self, account_name: str) -> str:\n        return self._totp.get_provisioning_uri(account_name=account_name, issuer=\"SecureDrop\") # Untested\n\n    def qrcode_svg(self, account_name: str) -> bytes:\n        uri = self.get_provisioning_uri(account_name)\n\n        qr = qrcode.QRCode(box_size=15, image_factory=qrcode.image.svg.SvgPathImage)\n        qr.add_data(uri)\n        img = qr.make_image()\n\n        svg_out = BytesIO()\n        img.save(svg_out)\n        return svg_out.getvalue()",
        "callGraphToTestedFunction": [
          "get_provisioning_uri"
        ]
      },
      "unitTestFilePath": "tests/test_two_factor.py"
    },
    {
      "functionName": "rq_workers",
      "file": "worker.py",
      "callGraph": [
        {
          "file": "worker.py",
          "functionName": "rq_workers",
          "lines": [
            {
              "startLine": 28,
              "endLine": 29
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_worker.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "worker.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "rq_workers",
          "filePath": "worker.py",
          "uncoveredLines": [
            {
              "startLine": 28,
              "endLine": 29
            }
          ]
        },
        "uncoveredFnBody": "def rq_workers(queue: Queue = None) -> List[Worker]:\n    \"\"\"\n    Returns the list of current rq ``Worker``s.\n    \"\"\"\n\n    config = SecureDropConfig.get_current() # Untested\n    return Worker.all(connection=Redis(**config.REDIS_KWARGS), queue=queue) # Untested",
        "callGraphToTestedFunction": [
          "rq_workers"
        ]
      },
      "unitTestFilePath": "tests/test_worker.py"
    },
    {
      "functionName": "worker_for_job",
      "file": "worker.py",
      "callGraph": [
        {
          "file": "worker.py",
          "functionName": "worker_for_job",
          "lines": [
            {
              "startLine": 36,
              "endLine": 36
            },
            {
              "startLine": 42,
              "endLine": 45
            },
            {
              "startLine": 48,
              "endLine": 50
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_worker.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "worker.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "worker_for_job",
          "filePath": "worker.py",
          "uncoveredLines": [
            {
              "startLine": 36,
              "endLine": 36
            },
            {
              "startLine": 42,
              "endLine": 45
            },
            {
              "startLine": 48,
              "endLine": 50
            }
          ]
        },
        "uncoveredFnBody": "def worker_for_job(job_id: str) -> Optional[Worker]:\n    \"\"\"\n    If the job is being run, return its ``Worker``.\n    \"\"\"\n    for worker in rq_workers():\n        # If the worker process no longer exists, skip it. From \"man 2\n        # kill\": \"If sig is 0, then no signal is sent, but existence\n        # and permission checks are still performed; this can be used\n        # to check for the existence of a process ID or process group\n        # ID that the caller is permitted to signal.\"\n        try: # Untested\n            os.kill(worker.pid, 0) # Untested\n        except OSError: # Untested\n            continue # Untested\n\n        # If it's running and working on the given job, return it.\n        if worker.state == WorkerStatus.BUSY and job_id == worker.get_current_job_id():\n            return worker\n    return None",
        "callGraphToTestedFunction": [
          "worker_for_job"
        ]
      },
      "unitTestFilePath": "tests/test_worker.py"
    },
    {
      "functionName": "requeue_interrupted_jobs",
      "file": "worker.py",
      "callGraph": [
        {
          "file": "worker.py",
          "functionName": "requeue_interrupted_jobs",
          "lines": [
            {
              "startLine": 74,
              "endLine": 75
            },
            {
              "startLine": 77,
              "endLine": 82
            },
            {
              "startLine": 84,
              "endLine": 85
            },
            {
              "startLine": 87,
              "endLine": 93
            },
            {
              "startLine": 95,
              "endLine": 95
            },
            {
              "startLine": 99,
              "endLine": 101
            },
            {
              "startLine": 104,
              "endLine": 104
            },
            {
              "startLine": 106,
              "endLine": 106
            },
            {
              "startLine": 108,
              "endLine": 112
            },
            {
              "startLine": 114,
              "endLine": 119
            }
          ],
          "replayTestFileNames": []
        }
      ],
      "existingTestFile": "tests/test_worker.py",
      "replayTestFileNames": [],
      "replayTestFilePaths": [],
      "filePath": "worker.py",
      "uncoveredTarget": {
        "uncoveredFile": {
          "functionName": "requeue_interrupted_jobs",
          "filePath": "worker.py",
          "uncoveredLines": [
            {
              "startLine": 74,
              "endLine": 75
            },
            {
              "startLine": 77,
              "endLine": 82
            },
            {
              "startLine": 84,
              "endLine": 85
            },
            {
              "startLine": 87,
              "endLine": 93
            },
            {
              "startLine": 95,
              "endLine": 95
            },
            {
              "startLine": 99,
              "endLine": 101
            },
            {
              "startLine": 104,
              "endLine": 104
            },
            {
              "startLine": 106,
              "endLine": 106
            },
            {
              "startLine": 108,
              "endLine": 112
            },
            {
              "startLine": 114,
              "endLine": 119
            }
          ]
        },
        "uncoveredFnBody": "def requeue_interrupted_jobs(queue_name: str) -> None:\n    \"\"\"\n    Requeues jobs found in the given queue's started job registry.\n\n    Only restarts those that aren't already queued or being run.\n\n    When rq starts a job, it records it in the queue's started job\n    registry. If the server is rebooted before the job completes, the\n    job is not automatically restarted from the information in the\n    registry. For tasks like secure deletion of files, this means that\n    information thought to be deleted is still present in the case of\n    seizure or compromise. We have manage.py tasks to clean such files\n    up, but this utility attempts to reduce the need for manual\n    intervention by automatically resuming interrupted jobs.\n\n    This function is predicated on a risky assumption: that all jobs\n    are idempotent. At time of writing, we use rq for securely\n    deleting submission files and hashing submissions for the ETag\n    header. Both of these can be safely repeated. If we add rq tasks\n    that cannot, this function should be improved to omit those.\n    \"\"\"\n    queue = create_queue(queue_name)\n    started_job_registry = StartedJobRegistry(queue=queue)\n\n    queued_job_ids = queue.get_job_ids()\n    logging.debug(f\"queued jobs: {queued_job_ids}\")\n    started_job_ids = started_job_registry.get_job_ids()\n    logging.debug(f\"started jobs: {started_job_ids}\")\n    job_ids = [j for j in started_job_ids if j not in queued_job_ids]\n    logging.debug(f\"candidate job ids: {job_ids}\")\n\n    if not job_ids:\n        logging.debug(\"No interrupted jobs found in started job registry.\")\n\n    for job_id in job_ids: # Untested\n        logging.debug(\"Considering job %s\", job_id) # Untested\n        try: # Untested\n            job = started_job_registry.job_class.fetch(job_id, started_job_registry.connection) # Untested\n        except NoSuchJobError as e: # Untested\n            logging.error(\"Could not find details for job %s: %s\", job_id, e) # Untested\n            continue # Untested\n\n        logging.debug(\n            \"Job %s enqueued at %s, started at %s\", job_id, job.enqueued_at, job.started_at\n        )\n\n        worker = worker_for_job(job_id)\n        if worker:\n            logging.info(\n                \"Skipping job %s, which is already being run by worker %s\", job_id, worker.key\n            )\n            continue\n\n        logging.info(\"Requeuing job %s\", job)\n\n        try:\n            started_job_registry.remove(job)\n        except InvalidJobOperation as e:\n            logging.error(\"Could not remove job %s from started job registry: %s\", job, e)\n            continue\n\n        try:\n            queue.enqueue_job(job)\n            logging.debug(\"Job now enqueued at %s, started at %s\", job.enqueued_at, job.started_at)\n        except Exception as e:\n            logging.error(\"Could not requeue job %s: %s\", job, e)\n            continue",
        "callGraphToTestedFunction": [
          "requeue_interrupted_jobs"
        ]
      },
      "unitTestFilePath": "tests/test_worker.py"
    }
  ]
}